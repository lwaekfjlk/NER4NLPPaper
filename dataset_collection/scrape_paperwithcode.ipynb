{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://paperswithcode.com/area/natural-language-processing')\n",
    "soup = BeautifulSoup(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = []\n",
    "table = soup.find_all('div', 'infinite-container featured-task')[0]\n",
    "\n",
    "for i in table.find_all('div', 'col-md-12'):\n",
    "    tasks.append(i.h2.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Language Modelling',\n",
       " '2D Classification',\n",
       " 'Question Answering',\n",
       " 'Machine Translation',\n",
       " 'Data Augmentation',\n",
       " '2D object detection',\n",
       " 'Text Classification',\n",
       " 'Text Generation',\n",
       " 'Sentiment Analysis',\n",
       " 'Named Entity Recognition',\n",
       " 'Contrastive Learning',\n",
       " 'Word Embeddings',\n",
       " 'Text Summarization',\n",
       " 'Optical Character Recognition',\n",
       " 'Relation Extraction',\n",
       " 'Information Retrieval',\n",
       " 'Visual Question Answering',\n",
       " 'Natural Language Inference',\n",
       " 'Reading Comprehension',\n",
       " 'Link Prediction',\n",
       " 'Active Learning',\n",
       " 'Emotion Recognition',\n",
       " 'Natural Language Understanding',\n",
       " 'Semantic Textual Similarity',\n",
       " 'Event Extraction',\n",
       " 'Dialogue',\n",
       " 'Image Captioning',\n",
       " 'Semantic Parsing',\n",
       " 'Dependency Parsing',\n",
       " 'Pretrained Language Models',\n",
       " 'Sentence Pair Modeling',\n",
       " 'Sentence Embeddings',\n",
       " 'Trajectory Prediction',\n",
       " 'Chatbot',\n",
       " '',\n",
       " 'Information Extraction',\n",
       " 'Cross-Lingual',\n",
       " 'Coreference Resolution',\n",
       " 'Part-Of-Speech Tagging',\n",
       " 'Topic Models',\n",
       " 'Entity Linking',\n",
       " 'Response Generation',\n",
       " 'Common Sense Reasoning',\n",
       " 'Question Generation',\n",
       " 'Abuse Detection',\n",
       " 'Semantic Role Labeling',\n",
       " 'Open Information Extraction',\n",
       " 'Relation Classification',\n",
       " 'Word Sense Disambiguation',\n",
       " 'Open-Domain Question Answering',\n",
       " 'Data Mining',\n",
       " 'Relational Reasoning',\n",
       " 'Hate Speech Detection',\n",
       " '2D Semantic Segmentation',\n",
       " 'Language Identification',\n",
       " 'Fake News Detection',\n",
       " 'Word Similarity',\n",
       " 'Slot Filling',\n",
       " 'Bias Detection',\n",
       " 'Code Generation',\n",
       " 'Grammatical Error Correction',\n",
       " 'Document Text Classification',\n",
       " 'Intent Detection',\n",
       " 'Dialogue Understanding',\n",
       " 'Deep Clustering',\n",
       " 'Constituency Parsing',\n",
       " 'Text Matching',\n",
       " 'Language Acquisition',\n",
       " 'Ad-Hoc Information Retrieval',\n",
       " 'Text Simplification',\n",
       " 'Entity Alignment',\n",
       " 'Open-Domain Dialog',\n",
       " 'Stance Detection',\n",
       " 'Entity Typing',\n",
       " 'Text-To-Speech Synthesis',\n",
       " 'Intent Classification',\n",
       " 'Self-Learning',\n",
       " 'Word Alignment',\n",
       " 'Cross-Lingual Transfer',\n",
       " 'Paraphrase Identification',\n",
       " 'Chunking',\n",
       " 'Shallow Syntax',\n",
       " 'Morphological Analysis',\n",
       " 'Multi-Label Text Classification',\n",
       " 'Discourse Parsing',\n",
       " 'Lemmatization',\n",
       " 'Chinese',\n",
       " 'Fact Verification',\n",
       " 'Document Ranking',\n",
       " 'Entity Disambiguation',\n",
       " 'Sarcasm Detection',\n",
       " 'De-identification',\n",
       " 'Source Code Summarization',\n",
       " 'Aspect-Based Sentiment Analysis',\n",
       " 'Abusive Language',\n",
       " 'Multimodal Deep Learning',\n",
       " 'Dialogue Evaluation',\n",
       " 'AMR Parsing',\n",
       " 'Keyphrase Extraction',\n",
       " 'Speech-to-Text Translation',\n",
       " 'Deep Attention',\n",
       " 'Entity Resolution',\n",
       " 'Table annotation',\n",
       " 'Text Clustering',\n",
       " 'Linguistic Acceptability',\n",
       " 'Data-to-Text Generation',\n",
       " 'Few-Shot Text Classification',\n",
       " 'Cross-Lingual Word Embeddings',\n",
       " 'Morphological Inflection',\n",
       " 'Term Extraction',\n",
       " 'Conversational Response Selection',\n",
       " 'Knowledge Base Population',\n",
       " 'Spam detection',\n",
       " 'Conversational Search',\n",
       " 'Protein Folding',\n",
       " 'Word Translation',\n",
       " 'Natural Language Transduction',\n",
       " 'Graph-to-Sequence',\n",
       " 'Cloze Test',\n",
       " 'Prompt Engineering',\n",
       " 'Explanation Generation',\n",
       " 'Mathematical Reasoning',\n",
       " 'Sentence Summarization',\n",
       " 'Entity Extraction using GAN',\n",
       " 'Passage Ranking',\n",
       " 'Phrase Grounding',\n",
       " 'Keyword Extraction',\n",
       " 'Morphological Tagging',\n",
       " 'Biomedical Information Retrieval',\n",
       " 'Multilingual NLP',\n",
       " 'Temporal Processing',\n",
       " 'Rumour Detection',\n",
       " 'Subjectivity Analysis',\n",
       " 'Token Classification',\n",
       " 'Authorship Verification',\n",
       " 'Negation Detection',\n",
       " 'Cross-Lingual Document Classification',\n",
       " 'Semantic Composition',\n",
       " 'Sentence Ordering',\n",
       " 'Word Sense Induction',\n",
       " 'Argument Mining',\n",
       " 'Question Similarity',\n",
       " 'Summarization',\n",
       " 'Conversational Response Generation',\n",
       " 'Lexical Analysis',\n",
       " 'Taxonomy Learning',\n",
       " 'Reverse Dictionary',\n",
       " 'Weakly Supervised Classification',\n",
       " 'Automated Essay Scoring',\n",
       " 'Emotion Cause Pair Extraction',\n",
       " 'Extreme Summarization',\n",
       " 'Humor Detection',\n",
       " 'KG-to-Text Generation',\n",
       " 'Lexical Normalization',\n",
       " 'Lexical Simplification',\n",
       " 'Diachronic Word Embeddings',\n",
       " 'Passage Re-Ranking',\n",
       " 'Persian Sentiment Analysis',\n",
       " 'Punctuation Restoration',\n",
       " 'Review Generation',\n",
       " 'Propaganda detection',\n",
       " 'Clinical Concept Extraction',\n",
       " 'Text-to-Image Generation',\n",
       " 'Conversational Question Answering',\n",
       " 'Meme Classification',\n",
       " 'Nested Mention Recognition',\n",
       " 'Decipherment',\n",
       " 'Meeting Summarization',\n",
       " 'Relationship Extraction (Distant Supervised)',\n",
       " 'Table-based Fact Verification',\n",
       " 'Aspect Category Detection',\n",
       " 'CCG Supertagging',\n",
       " 'Dialog Act Classification',\n",
       " 'Intent Discovery',\n",
       " 'Semantic Retrieval',\n",
       " 'Multimodal Machine Translation',\n",
       " 'Recognizing Emotion Cause in Conversations',\n",
       " 'Arabic Text Diacritization',\n",
       " 'Attribute Value Extraction',\n",
       " 'Hypernym Discovery',\n",
       " 'Pretrained Multilingual Language Models',\n",
       " 'Suggestion mining',\n",
       " 'Thai Word Segmentation',\n",
       " 'Vietnamese Datasets',\n",
       " 'Abstractive Text Summarization',\n",
       " 'Speculation Detection',\n",
       " 'Aggression Identification',\n",
       " 'Arabic Sentiment Analysis',\n",
       " 'Clickbait Detection',\n",
       " 'Cross-Lingual Bitext Mining',\n",
       " 'Morphological Disambiguation',\n",
       " 'Text Attribute Transfer',\n",
       " 'Toponym Resolution',\n",
       " 'Vietnamese Word Segmentation',\n",
       " 'Abstract Argumentation',\n",
       " 'Commonsense Causal Reasoning',\n",
       " 'Complex Word Identification',\n",
       " 'Dialogue Rewriting',\n",
       " 'Document AI',\n",
       " 'Gender Bias Detection',\n",
       " 'Open Intent Discovery',\n",
       " 'Sign Language Production',\n",
       " 'Text Compression',\n",
       " 'Anaphora Resolution',\n",
       " 'Hope Speech Detection',\n",
       " 'Stock Prediction',\n",
       " 'Cognate Prediction',\n",
       " 'Fact Selection',\n",
       " 'Memex Question Answering',\n",
       " 'Probing Language Models',\n",
       " 'Sentence Compression',\n",
       " 'Table-to-Text Generation',\n",
       " 'Temporal Relation Extraction',\n",
       " 'Emotional Intelligence',\n",
       " 'Aspect Extraction',\n",
       " 'Action Parsing',\n",
       " 'Aspect Category Polarity',\n",
       " 'Author Attribution',\n",
       " 'Chinese Spell Checking',\n",
       " 'Croatian Text Diacritization',\n",
       " 'Czech Text Diacritization',\n",
       " 'Definition Modelling',\n",
       " 'Domain Labelling',\n",
       " 'French Text Diacritization',\n",
       " 'Hate Speech Normalization',\n",
       " 'Hungarian Text Diacritization',\n",
       " 'Irish Text Diacritization',\n",
       " 'Latvian Text Diacritization',\n",
       " 'Misogynistic Aggression Identification',\n",
       " 'Multimodal Text and Image Classification',\n",
       " 'Negation and Speculation Cue Detection',\n",
       " 'Negation and Speculation Scope resolution',\n",
       " 'News Annotation',\n",
       " 'Polyphone disambiguation',\n",
       " 'Record linking',\n",
       " 'Role-filler Entity Extraction',\n",
       " 'Romanian Text Diacritization',\n",
       " 'Slovak Text Diacritization',\n",
       " 'Spanish Text Diacritization',\n",
       " 'Temporal Information Extraction',\n",
       " 'Text Anonymization',\n",
       " 'Text-to-video search',\n",
       " 'Turkish Text Diacritization',\n",
       " 'Turning Point Identification',\n",
       " 'Twitter Event Detection',\n",
       " 'Vietnamese Text Diacritization',\n",
       " 'Chemical Indexing',\n",
       " 'Chinese Spelling Error Correction',\n",
       " 'Clinical Assertion Status Detection',\n",
       " 'Commonsense Reasoning for RL',\n",
       " 'Context Query Reformulation',\n",
       " 'Cross-Lingual Entity Linking',\n",
       " 'Crowdsourced Text Aggregation',\n",
       " 'Dialogue Generation',\n",
       " 'Document Summarization',\n",
       " 'Emergent communications on relations',\n",
       " 'Extractive Tags Summarization',\n",
       " 'Hate Intensity Prediction',\n",
       " 'Hate Span Identification',\n",
       " 'Job Prediction',\n",
       " 'Joint Entity and Relation Extraction on Scientific Data',\n",
       " 'Joint NER and Classification',\n",
       " 'Literature Mining',\n",
       " 'Logical Reasoning Reading Comprehension',\n",
       " 'Math Information Retrieval',\n",
       " 'Morpheme Segmentaiton',\n",
       " 'Multi-Grained Named Entity Recognition',\n",
       " 'Multi-agent Integration',\n",
       " 'Multilingual Machine Comprehension in English Hindi',\n",
       " 'Multimodal Text Prediction',\n",
       " 'Overlapping Mention Recognition',\n",
       " 'Personality Recognition in Conversation',\n",
       " 'Phrase Ranking',\n",
       " 'Phrase Tagging',\n",
       " 'Phrase Vector Embedding',\n",
       " 'Poem meters classification',\n",
       " 'Query Wellformedness',\n",
       " 'Question-Answer categorization',\n",
       " 'Reliable Intelligence Identification',\n",
       " 'Sentence Completion',\n",
       " 'Stereotypical Bias Analysis',\n",
       " 'Syntax Representation',\n",
       " 'Task-Oriented Dialogue Systems',\n",
       " 'Text Effects Transfer',\n",
       " 'Text Style Transfer',\n",
       " 'Vietnamese Aspect-Based Sentiment Analysis',\n",
       " 'Web Page Tagging',\n",
       " 'Zero-Shot Machine Translation',\n",
       " 'incongruity detection',\n",
       " 'multi-word expression embedding',\n",
       " 'multi-word expression sememe prediction',\n",
       " 'ARQMath2',\n",
       " 'Automated Writing Evaluation',\n",
       " 'Automatic Writing',\n",
       " 'Complaint Comment Classification',\n",
       " 'Counterspeech Detection',\n",
       " 'Document Classification',\n",
       " 'Extractive Text Summarization',\n",
       " 'Face Selection',\n",
       " 'Job classification',\n",
       " 'Meme Captioning',\n",
       " 'Multlingual Neural Machine Translation',\n",
       " 'Question to Declarative Sentence',\n",
       " 'Relation Mention Extraction',\n",
       " 'Twitter Sentiment Analysis',\n",
       " 'Vietnamese Parsing']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_path = 'data/nlp_tasks.txt'\n",
    "with open(tasks_path, 'w') as f:\n",
    "    for t in tasks:\n",
    "        f.write(t)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:30<00:00,  1.26it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "num_pages = 38\n",
    "\n",
    "datasets = []\n",
    "for i in tqdm(range(1, num_pages+1)):\n",
    "    r = requests.get(f'https://paperswithcode.com/datasets?mod=texts&page={i}')\n",
    "    soup = BeautifulSoup(r.content)\n",
    "    names = soup.find_all('span', 'name')\n",
    "    for tag in names:\n",
    "        if tag.span is None:\n",
    "            name = tag.text.strip()\n",
    "            datasets.append(name)\n",
    "        else:\n",
    "            abbrev = tag.contents[0].strip()\n",
    "            full_name = tag.span.text.strip().strip('()')\n",
    "            datasets.append(abbrev)\n",
    "            datasets.append(full_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2422"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GLUE',\n",
       " 'General Language Understanding Evaluation benchmark',\n",
       " 'SQuAD',\n",
       " 'Stanford Question Answering Dataset',\n",
       " 'SST',\n",
       " 'Stanford Sentiment Treebank',\n",
       " 'Penn Treebank',\n",
       " 'MultiNLI',\n",
       " 'Multi-Genre Natural Language Inference',\n",
       " 'IMDb Movie Reviews',\n",
       " 'Visual Question Answering',\n",
       " 'VQA',\n",
       " 'SNLI',\n",
       " 'Stanford Natural Language Inference',\n",
       " 'Visual Genome',\n",
       " 'QNLI',\n",
       " 'Question-answering NLI',\n",
       " 'ConceptNet',\n",
       " 'Natural Questions',\n",
       " 'WikiText-2',\n",
       " 'MS MARCO',\n",
       " 'Microsoft Machine Reading Comprehension Dataset',\n",
       " 'Flickr30k',\n",
       " 'Universal Dependencies',\n",
       " 'CoNLL-2003',\n",
       " 'DBpedia',\n",
       " 'MRPC',\n",
       " 'Microsoft Research Paraphrase Corpus',\n",
       " 'CLEVR',\n",
       " 'Compositional Language and Elementary Visual Reasoning',\n",
       " 'SuperGLUE',\n",
       " 'AG News',\n",
       " 'AG’s News Corpus',\n",
       " 'CoLA',\n",
       " 'Corpus of Linguistic Acceptability',\n",
       " 'CNN/Daily Mail',\n",
       " 'TriviaQA',\n",
       " 'WikiText-103',\n",
       " 'VoxCeleb2',\n",
       " 'RCV1',\n",
       " 'Reuters Corpus Volume 1',\n",
       " 'MSR-VTT',\n",
       " 'HotpotQA',\n",
       " 'MPQA Opinion Corpus',\n",
       " 'Multi-Perspective Question Answering',\n",
       " 'FEVER',\n",
       " 'Fact Extraction and VERification',\n",
       " 'DailyDialog',\n",
       " 'Visual Question Answering v2.0',\n",
       " 'VQA v2.0',\n",
       " 'RACE',\n",
       " 'ReAding Comprehension dataset from Examinations',\n",
       " 'MultiWOZ',\n",
       " 'Multi-domain Wizard-of-Oz',\n",
       " 'XNLI',\n",
       " 'Cross-lingual Natural Language Inference',\n",
       " 'VCTK',\n",
       " 'CSTR VCTK Corpus',\n",
       " 'WMT 2014',\n",
       " 'C4',\n",
       " 'Colossal Clean Crawled Corpus',\n",
       " 'ICDAR 2013',\n",
       " 'NewsQA',\n",
       " 'ATIS',\n",
       " 'Airline Travel Information Systems',\n",
       " 'WSC',\n",
       " 'Winograd Schema Challenge',\n",
       " 'Conceptual Captions',\n",
       " 'SICK',\n",
       " 'Sentences Involving Compositional Knowledge',\n",
       " 'DROP',\n",
       " 'Discrete Reasoning Over Paragraphs',\n",
       " 'MSVD',\n",
       " 'Microsoft Research Video Description Corpus',\n",
       " 'SNIPS',\n",
       " 'SNIPS Natural Language Understanding benchmark',\n",
       " 'GQA',\n",
       " 'CommonsenseQA',\n",
       " 'CoQA',\n",
       " 'Conversational Question Answering Challenge',\n",
       " 'WebText',\n",
       " 'WikiQA',\n",
       " 'Wikipedia open-domain Question Answering',\n",
       " 'LJSpeech',\n",
       " 'The LJ Speech Dataset',\n",
       " 'WikiSQL',\n",
       " 'RefCOCO',\n",
       " 'WebQuestions',\n",
       " 'HowTo100M',\n",
       " 'BoolQ',\n",
       " 'Boolean Questions',\n",
       " 'COPA',\n",
       " 'Choice of Plausible Alternatives',\n",
       " 'ROCStories',\n",
       " 'ActivityNet Captions',\n",
       " 'MuST-C',\n",
       " 'IAM',\n",
       " 'IAM Handwriting',\n",
       " 'NELL',\n",
       " 'Never Ending Language Learning',\n",
       " 'VRD',\n",
       " 'Visual Relationship Detection dataset',\n",
       " 'CORD-19',\n",
       " 'FCE',\n",
       " 'First Certificate in English',\n",
       " 'QuAC',\n",
       " 'Question Answering in Context',\n",
       " 'WMT 2016',\n",
       " 'Billion Word Benchmark',\n",
       " 'CodeSearchNet',\n",
       " 'LRW',\n",
       " 'Lip Reading in the Wild',\n",
       " 'SentEval',\n",
       " 'ANLI',\n",
       " 'Adversarial NLI',\n",
       " 'BC5CDR',\n",
       " 'BioCreative V CDR corpus',\n",
       " 'BioASQ',\n",
       " 'Biomedical Semantic Indexing and Question Answering',\n",
       " 'SearchQA',\n",
       " 'COCO Captions',\n",
       " 'Charades-STA',\n",
       " 'SWAG',\n",
       " 'Situations With Adversarial Generations',\n",
       " 'VisDial',\n",
       " 'Visual Dialog',\n",
       " 'Wizard of Wikipedia',\n",
       " 'XQuAD',\n",
       " 'MLQA',\n",
       " 'MultiLingual Question Answering',\n",
       " 'ATOMIC',\n",
       " 'TACRED',\n",
       " 'The TAC Relation Extraction Dataset',\n",
       " 'WebNLG',\n",
       " 'FewRel',\n",
       " 'Few-Shot Relation Classification Dataset',\n",
       " 'MELD',\n",
       " 'Multimodal EmotionLines Dataset',\n",
       " 'OLID',\n",
       " 'Offensive Language Identification Dataset',\n",
       " 'SimpleQuestions',\n",
       " 'SGD',\n",
       " 'Schema-Guided Dialogue',\n",
       " 'TVSum',\n",
       " 'Title-based Video Summarization Dataset',\n",
       " 'Hate Speech',\n",
       " 'SCAN',\n",
       " 'Simplified versions of the CommAI Navigation tasks',\n",
       " 'ARC',\n",
       " 'AI2 Reasoning Challenge',\n",
       " 'Flickr30K Entities',\n",
       " 'YouCook2',\n",
       " 'Word Sense Disambiguation: a Unified Evaluation Framework and Empirical Comparison',\n",
       " 'CMU-MOSEI',\n",
       " 'MultiRC',\n",
       " 'Multi-Sentence Reading Comprehension',\n",
       " 'NarrativeQA',\n",
       " 'Yahoo! Answers',\n",
       " 'DocRED',\n",
       " 'GENIA',\n",
       " 'MCTest',\n",
       " 'NCBI Disease',\n",
       " 'VCR',\n",
       " 'Visual Commonsense Reasoning',\n",
       " 'WinoGrande',\n",
       " 'Microsoft Academic Graph',\n",
       " 'Jester',\n",
       " 'Jester dataset',\n",
       " 'PAWS-X',\n",
       " 'TyDi QA',\n",
       " 'Typologically Diverse Question Answering',\n",
       " 'WiC',\n",
       " 'Words in Context',\n",
       " 'FIGER',\n",
       " 'Fine-Grained Entity Recognition',\n",
       " 'SHAPES',\n",
       " 'Swarm Heuristics based Adaptive and Penalized Estimation of Splines',\n",
       " 'TVQA',\n",
       " 'CBT',\n",
       " 'Children’s Book Test',\n",
       " 'DiDeMo',\n",
       " 'Distinct Describable Moments',\n",
       " 'NEWSROOM',\n",
       " 'CORNELL NEWSROOM',\n",
       " 'PAWS',\n",
       " 'Paraphrase Adversaries from Word Scrambling',\n",
       " 'R2R',\n",
       " 'Room-to-Room',\n",
       " 'LibriTTS',\n",
       " 'BLUE',\n",
       " 'Biomedical Language Understanding Evaluation',\n",
       " 'ASPEC',\n",
       " 'Asian Scientific Paper Excerpt Corpus',\n",
       " 'MRQA',\n",
       " 'PIQA',\n",
       " 'Physical Interaction: Question Answering',\n",
       " 'OpenBookQA',\n",
       " 'CoNLL-2012',\n",
       " 'LAMBADA',\n",
       " 'GYAFC',\n",
       " 'Grammarly’s Yahoo Answers Formality Corpus',\n",
       " 'SPIDER',\n",
       " 'Hateful Memes',\n",
       " 'LRA',\n",
       " 'Long-Range Arena',\n",
       " 'ReCoRD',\n",
       " 'Douban',\n",
       " 'Douban Conversation Corpus',\n",
       " 'LSMDC',\n",
       " 'Large Scale Movie Description Challenge',\n",
       " 'SciERC',\n",
       " 'GAP Coreference Dataset',\n",
       " 'LIAR',\n",
       " 'e-SNLI',\n",
       " 'CoNLL-2014 Shared Task: Grammatical Error Correction',\n",
       " 'MovieQA',\n",
       " 'Visual7W',\n",
       " 'WikiMatrix',\n",
       " 'MIND',\n",
       " 'MIcrosoft News Dataset',\n",
       " 'OK-VQA',\n",
       " 'Outside Knowledge Visual Question Answering',\n",
       " 'TrecQA',\n",
       " 'Text Retrieval Conference Question Answering',\n",
       " 'JFLEG',\n",
       " 'JHU FLuency-Extended GUG corpus',\n",
       " 'S2ORC',\n",
       " 'WNUT 2017',\n",
       " 'WNUT 2017 Emerging and Rare entity recognition',\n",
       " 'ConvAI2',\n",
       " 'Conversational Intelligence Challenge 2',\n",
       " 'FUNSD',\n",
       " 'Form Understanding in Noisy Scanned Documents',\n",
       " 'ALFRED',\n",
       " 'Action Learning From Realistic Environments and Directives',\n",
       " 'EPIC-KITCHENS-100',\n",
       " 'GuessWhat?!',\n",
       " 'CoNLL 2002',\n",
       " 'SAMSum Corpus',\n",
       " 'KP20k',\n",
       " 'WinoBias',\n",
       " 'LRS2',\n",
       " 'Lip Reading Sentences 2',\n",
       " 'WikiHow',\n",
       " 'COCO-Text',\n",
       " 'ECB+',\n",
       " 'extension to the EventCorefBank',\n",
       " 'VIST',\n",
       " 'Visual Storytelling',\n",
       " 'CLUE',\n",
       " 'Chinese Language Understanding Evaluation Benchmark',\n",
       " 'Multi-News',\n",
       " 'QASC',\n",
       " 'Question Answering via Sentence Composition',\n",
       " 'SNLI-VE',\n",
       " 'VQG',\n",
       " 'Visual Question Generation',\n",
       " 'Referring Expressions for DAVIS 2016 & 2017',\n",
       " 'UMLS',\n",
       " 'CosmosQA',\n",
       " 'Math23K',\n",
       " 'Math23K for Math Word Problem Solving',\n",
       " 'WikiBio',\n",
       " 'Wikipedia Biography Dataset',\n",
       " 'ReferItGame',\n",
       " 'Semantic Scholar',\n",
       " 'CodeXGLUE',\n",
       " 'Hate Speech and Offensive Language',\n",
       " 'MIMIC-CXR',\n",
       " 'TextVQA',\n",
       " 'WikiHop',\n",
       " 'WritingPrompts',\n",
       " 'OntoNotes 5.0',\n",
       " 'AIDA CoNLL-YAGO',\n",
       " 'CC100',\n",
       " 'CELEX',\n",
       " 'KILT',\n",
       " 'KILT Benchmark',\n",
       " 'ListOps',\n",
       " 'Sentence Compression',\n",
       " 'ReDial',\n",
       " 'VizWiz',\n",
       " 'VizWiz-VQA',\n",
       " 'ACE 2005',\n",
       " 'ACE 2005 Multilingual Training Corpus',\n",
       " 'DuReader',\n",
       " 'MINC',\n",
       " 'Materials in Context Database',\n",
       " 'NLVR',\n",
       " 'Natural Language Visual Reasoningnatural language for visual reasoning',\n",
       " 'mC4',\n",
       " 'CMRC',\n",
       " 'Chinese Machine Reading Comprehension 2018',\n",
       " 'NomBank',\n",
       " 'E2E',\n",
       " 'End-to-End NLG Challenge',\n",
       " 'LCSTS',\n",
       " 'Quora Question Pairs',\n",
       " 'BEIR',\n",
       " 'Benchmarking IR',\n",
       " 'DEMAND',\n",
       " 'Diverse Environments Multi-channel Acoustic Noise Database',\n",
       " 'MTNT',\n",
       " 'RAVEN',\n",
       " 'CLINC150',\n",
       " 'GoEmotions',\n",
       " 'How2',\n",
       " 'OpenWebText',\n",
       " 'QUASAR-T',\n",
       " 'QUestion Answering by Search And Reading – Trivia',\n",
       " 'RealNews',\n",
       " 'TabFact',\n",
       " 'WikiLarge',\n",
       " 'ELI5',\n",
       " 'New York Times Annotated Corpus',\n",
       " 'VATEX',\n",
       " 'Video And TEXt',\n",
       " 'DREAM',\n",
       " 'MetaQA',\n",
       " 'MoviE Text Audio QA',\n",
       " 'The Pile',\n",
       " 'WikiSum',\n",
       " 'Bio',\n",
       " 'Bio AMR Corpus',\n",
       " 'DAQUAR',\n",
       " 'DRCD',\n",
       " 'Delta Reading Comprehension Dataset',\n",
       " 'Recipe1M+',\n",
       " 'RotoWire',\n",
       " 'UDC',\n",
       " 'Ubuntu Dialogue Corpus',\n",
       " 'CommonGen',\n",
       " 'EmoContext',\n",
       " 'MLDoc',\n",
       " 'Multilingual Document Classification Corpus',\n",
       " 'ComplexWebQuestions',\n",
       " 'ParaCrawl',\n",
       " 'Weibo NER',\n",
       " 'ACE 2004',\n",
       " 'ACE 2004 Multilingual Training Corpus',\n",
       " 'TGIF-QA',\n",
       " 'CUHK-PEDES',\n",
       " 'English Web Treebank',\n",
       " 'WikiTableQuestions',\n",
       " 'MathQA',\n",
       " 'QA-SRL',\n",
       " 'QUASAR',\n",
       " 'QUestion Answering by Search And Reading',\n",
       " 'TVQA+',\n",
       " 'WikiMovies',\n",
       " 'CANARD',\n",
       " 'A Dataset for Question-in-Context Rewriting',\n",
       " 'CMRC 2018',\n",
       " 'Chinese Machine Reading Comprehension 2018',\n",
       " 'CoNaLa',\n",
       " 'CMU CoNaLa, the Code/Natural Language Challenge',\n",
       " 'EmotionLines',\n",
       " 'InsuranceQA',\n",
       " 'emrQA',\n",
       " 'DuoRC',\n",
       " 'ISEAR',\n",
       " 'International Survey on Emotion Antecedents and Reactions',\n",
       " 'EmpatheticDialogues',\n",
       " 'MemeTracker',\n",
       " 'OSCAR',\n",
       " 'ReClor',\n",
       " 'ShARC',\n",
       " 'Shaping Answers with Rules through Conversation',\n",
       " 'WebQuestionsSP',\n",
       " 'WebQuestions Semantic Parses Dataset',\n",
       " 'XTREME',\n",
       " 'Cross-Lingual Transfer Evaluation of Multilingual Encoders',\n",
       " 'CARER',\n",
       " 'Contextualized Affect Representations for Emotion Recognition',\n",
       " 'E-commerce',\n",
       " 'MATH',\n",
       " 'PubMedQA',\n",
       " 'Quoref',\n",
       " 'WMT 2018',\n",
       " 'DDI',\n",
       " 'ETHICS',\n",
       " 'FLORES-101',\n",
       " 'HumanEval',\n",
       " 'RTE',\n",
       " 'Recognizing Textual Entailment',\n",
       " 'SemEval-2018 Task 9: Hypernym Discovery',\n",
       " 'TurkCorpus',\n",
       " 'MedMentions',\n",
       " 'MuTual',\n",
       " 'ST-VQA',\n",
       " 'WMT 2015',\n",
       " 'CCNet',\n",
       " 'Localized Narratives',\n",
       " 'MAMS',\n",
       " 'Multi Aspect Multi-Sentiment',\n",
       " 'MultiCoNER',\n",
       " 'PAQ',\n",
       " 'Probably Asked Questions',\n",
       " 'Panlex',\n",
       " 'SemEval-2013 Task 2',\n",
       " 'WOS',\n",
       " 'Web of Science Dataset',\n",
       " 'Xia and Ding, 2019',\n",
       " 'ASSET',\n",
       " 'BLiMP',\n",
       " 'Benchmark of Linguistic Minimal Pairs',\n",
       " 'DeepFix',\n",
       " 'IPM NEL',\n",
       " 'Derczynski IPM Named Entity Linking',\n",
       " 'Reddit TIFU',\n",
       " 'TGIF',\n",
       " 'Tumblr GIF',\n",
       " 'WebVid',\n",
       " 'BUCC',\n",
       " 'Building and Using Comparable Corpora',\n",
       " 'CC12M',\n",
       " 'Conceptual 12M',\n",
       " 'Dialogue State Tracking Challenge',\n",
       " 'Multi-Domain Sentiment Dataset v2.0',\n",
       " 'SParC',\n",
       " 'Semantic Parsing in Context',\n",
       " 'Tatoeba',\n",
       " 'WMT 2020',\n",
       " 'Worldtree',\n",
       " 'CrossTask',\n",
       " 'DocVQA',\n",
       " 'EmoryNLP',\n",
       " 'GEM',\n",
       " 'Generation, Evaluation, and Metrics',\n",
       " 'LogiQA',\n",
       " 'SCUT-CTW1500',\n",
       " 'ToTTo',\n",
       " 'Wizard-of-Oz',\n",
       " 'CoS-E',\n",
       " 'Commonsense Explanations Dataset',\n",
       " 'EVALution',\n",
       " 'Open Entity',\n",
       " 'SentiMix',\n",
       " 'decaNLP',\n",
       " 'Natural Language Decathlon Benchmark',\n",
       " 'A2D Sentences',\n",
       " 'Sentences for the Actor-Action Dataset (A2D',\n",
       " 'CSQA',\n",
       " 'CoSQL',\n",
       " 'Conversational Text-to-SQL Challenge',\n",
       " 'DialogRE',\n",
       " 'FigureQA',\n",
       " 'Holl-E',\n",
       " 'LDC2017T10',\n",
       " 'Abstract Meaning Representation (AMR) Annotation Release 2.0',\n",
       " 'Learning to Rank Challenge',\n",
       " 'Yahoo! Learning to Rank Challenge',\n",
       " 'MR',\n",
       " 'MR Movie Reviews',\n",
       " 'STS 2014',\n",
       " 'SciCite',\n",
       " 'WikiReading',\n",
       " 'Amazon Product Data',\n",
       " 'MLSUM',\n",
       " 'MultiLingual SUMmarization',\n",
       " 'OCNLI',\n",
       " 'Original Chinese Natural Language Inference',\n",
       " 'PeerRead',\n",
       " 'ProPara',\n",
       " 'TQA',\n",
       " 'Textbook Question Answering',\n",
       " 'BREAK',\n",
       " 'BookTest',\n",
       " 'Doc2Dial',\n",
       " 'Doc2Dial: Document-grounded Dialogue',\n",
       " 'GLUCOSE',\n",
       " 'LAION-400M',\n",
       " 'MQ2008',\n",
       " 'MULTEXT-East',\n",
       " 'SQA',\n",
       " 'SequentialQA',\n",
       " 'TIMIT',\n",
       " 'TIMIT Acoustic-Phonetic Continuous Speech Corpus',\n",
       " 'AMR Bank',\n",
       " 'Abstract Meaning Representation',\n",
       " 'ActivityNet-QA',\n",
       " 'BIOSSES',\n",
       " 'Biomedical Semantic Similarity Estimation System',\n",
       " 'CCAligned',\n",
       " 'Douban Conversation Corpus',\n",
       " 'FakeNewsNet',\n",
       " 'Few-NERD',\n",
       " 'Paralex',\n",
       " 'RecipeQA',\n",
       " 'RxR',\n",
       " 'Room-across-Room',\n",
       " 'Samanantar',\n",
       " 'TextCaps',\n",
       " 'TweetEval',\n",
       " 'WIT',\n",
       " 'Wikipedia-based Image Text',\n",
       " 'doc2dial',\n",
       " '20 Newsgroups',\n",
       " 'BillSum',\n",
       " 'ChID',\n",
       " 'Chinese IDiom dataset',\n",
       " 'DART',\n",
       " 'ImageNet-P',\n",
       " 'MCScript',\n",
       " 'MKQA',\n",
       " 'Multilingual Knowledge Questions and Answers',\n",
       " 'MOROCO',\n",
       " 'MOldavian and ROmanian Dialectal COrpus',\n",
       " 'MasakhaNER',\n",
       " 'PIT',\n",
       " 'Paraphrase and Semantic Similarity in Twitter',\n",
       " 'PMIndia',\n",
       " 'Re-TACRED',\n",
       " 'Revised-TACRED',\n",
       " 'SVAMP',\n",
       " 'Simple Variations on Arithmetic Math word Problems',\n",
       " 'ShapeWorld',\n",
       " 'WMT 2016 News',\n",
       " 'WMT 2016 News Translation Task',\n",
       " 'WikiLingua',\n",
       " 'XCOPA',\n",
       " 'XSum',\n",
       " 'C3',\n",
       " 'CoVoST',\n",
       " 'Event2Mind',\n",
       " 'Resume NER',\n",
       " 'SciREX',\n",
       " 'iSarcasmEval',\n",
       " 'DIRHA',\n",
       " 'Distant-speech Interaction for Robust Home Applications',\n",
       " 'Fashion-Gen',\n",
       " 'GovReport',\n",
       " 'HELP',\n",
       " 'Image Paragraph Captioning',\n",
       " 'ProofWriter',\n",
       " 'RoboCup',\n",
       " 'WI-LOCNESS',\n",
       " 'Cambridge English Write & Improve & LOCNESS',\n",
       " 'AISHELL-3',\n",
       " 'Django',\n",
       " 'EXTREME CLASSIFICATION',\n",
       " 'Extreme Multi-label Classification',\n",
       " 'GSM8K',\n",
       " 'GenericsKB',\n",
       " 'MMLU',\n",
       " 'Massive Multitask Language Understanding',\n",
       " 'ReferIt3D',\n",
       " 'SUBJ',\n",
       " 'Subjectivity dataset',\n",
       " 'Senseval-2',\n",
       " 'SentiCap',\n",
       " 'Snopes',\n",
       " 'Spot-the-diff',\n",
       " 'Text8',\n",
       " 'WIQA',\n",
       " 'What-If Question Answering',\n",
       " '2010 i2b2/VA',\n",
       " 'CLEVR-Humans',\n",
       " 'CrossWOZ',\n",
       " 'DVQA',\n",
       " 'Data Visualizations via Question Answering',\n",
       " 'Evidence Inference',\n",
       " 'FQuAD',\n",
       " 'French Question Answering Dataset',\n",
       " 'HOC',\n",
       " 'Hallmarks of Cancer',\n",
       " 'ICDAR 2017',\n",
       " 'IndicCorp',\n",
       " 'MIR-1K',\n",
       " 'Natural Stories',\n",
       " 'QReCC',\n",
       " 'ROPES',\n",
       " 'Reasoning Over Paragraph Effects in Situations',\n",
       " 'TAT-QA',\n",
       " 'TempEval-3',\n",
       " 'TempEval-3: events, times, and temporal relations',\n",
       " 'WikiSplit',\n",
       " 'CODAH',\n",
       " 'COmmonsense Dataset Adversarially-authored by Humans',\n",
       " 'ChemProt',\n",
       " 'CliCR',\n",
       " 'ECHR',\n",
       " 'EURLEX57K',\n",
       " 'George Washington',\n",
       " 'Inspired',\n",
       " 'JESC',\n",
       " 'Japanese-English Subtitle Corpus',\n",
       " 'MeQSum',\n",
       " 'MedQuAD',\n",
       " 'Medical Question Answering Dataset',\n",
       " 'QAMR',\n",
       " 'Question-Answer Meaning Representation Dataset',\n",
       " 'SIMMC',\n",
       " 'Situated and Interactive Multimodal Conversations',\n",
       " 'SciDocs',\n",
       " 'Shifts',\n",
       " 'StockNet',\n",
       " 'United Nations Parallel Corpus',\n",
       " 'ASTE-Data-V2',\n",
       " 'AdversarialQA',\n",
       " 'DuRecDial',\n",
       " 'FNC-1',\n",
       " 'Fake News Challenge Stage 1',\n",
       " 'KVQA',\n",
       " 'Knowledge-aware VQA',\n",
       " 'LABR',\n",
       " 'Large-Scale Arabic Book Reviews',\n",
       " 'MLQE-PE',\n",
       " 'Multilingual Quality Estimation and Automatic Post-editing Dataset',\n",
       " 'MTL-AQA',\n",
       " 'Mathematics Dataset',\n",
       " 'Pushshift Reddit',\n",
       " 'QASPER',\n",
       " 'ScisummNet',\n",
       " 'Taskmaster-1',\n",
       " 'UR-FUNNY',\n",
       " 'Who-did-What',\n",
       " 'Who did What',\n",
       " 'XGLUE',\n",
       " 'ZESHEL',\n",
       " 'ArSarcasm-v2',\n",
       " 'CLOTH',\n",
       " 'CLOze test by TeacHers',\n",
       " 'CMU DoG',\n",
       " 'CMU Document Grounded Conversations Dataset',\n",
       " 'CovidQA',\n",
       " 'CrisisMMD',\n",
       " 'DEFT Corpus',\n",
       " 'DUC 2004',\n",
       " 'FlickrStyle10K',\n",
       " 'Humicroedit',\n",
       " 'KELM',\n",
       " 'KdConv',\n",
       " 'Knowledge-driven Conversation',\n",
       " 'KorNLI',\n",
       " 'MedHop',\n",
       " 'Multi-Modal CelebA-HQ',\n",
       " 'MultiFC',\n",
       " 'OTT-QA',\n",
       " 'OntoNotes 4.0',\n",
       " 'OntoNotes Release 4.0',\n",
       " 'Opusparcus',\n",
       " 'PubMed RCT',\n",
       " 'PubMed 200k RCT',\n",
       " 'Qulac',\n",
       " 'RCTW-17',\n",
       " 'Reading Chinese Text in the Wild',\n",
       " 'SciQ',\n",
       " 'VALUE',\n",
       " 'Video-And-Language Understanding Evaluation',\n",
       " 'VQA-CP',\n",
       " 'WCEP',\n",
       " 'Wikipedia Current Events Portal',\n",
       " 'iSarcasm',\n",
       " 'APPS',\n",
       " 'Automated Programming Progress Standard',\n",
       " 'AVSD',\n",
       " 'Audio-Visual Scene-Aware Dialog',\n",
       " 'ArtEmis',\n",
       " 'BIG-bench',\n",
       " 'Beyond the Imitation Game Benchmark',\n",
       " 'CLEVR-Ref+',\n",
       " 'CPED',\n",
       " 'Chinese Personalized and Emotional Dialogue',\n",
       " 'How2QA',\n",
       " 'How2Sign',\n",
       " 'A Large-scale Multimodal Dataset for Continuous American Sign Language',\n",
       " 'Hutter Prize',\n",
       " 'JNLPBA',\n",
       " 'KPTimes',\n",
       " 'MMD',\n",
       " 'Multimodal Dialogs',\n",
       " 'Multilingual Reuters',\n",
       " 'Multilingual Reuters Collection',\n",
       " 'QuaRTz',\n",
       " 'QuaRTz Dataset',\n",
       " 'SIQA',\n",
       " 'Social Interaction QA',\n",
       " 'SMHD',\n",
       " 'Self-reported Mental Health Diagnoses',\n",
       " 'TOPv2',\n",
       " 'Task Oriented Parsing v2',\n",
       " 'TextComplexityDE',\n",
       " 'Touchdown Dataset',\n",
       " 'TweetQA',\n",
       " 'BLURB',\n",
       " 'Biomedical Language Understanding and Reasoning Benchmark',\n",
       " 'Broad Twitter Corpus',\n",
       " 'DialoGLUE',\n",
       " 'EntailmentBank',\n",
       " 'FEVEROUS',\n",
       " 'Fact Extraction and VERification Over Unstructured and Structured information',\n",
       " 'Funcom',\n",
       " 'KLUE',\n",
       " 'Korean Language Understanding Evaluation',\n",
       " 'Ohsumed',\n",
       " 'PreCo',\n",
       " 'QuaRel',\n",
       " 'ReCAM',\n",
       " 'SemEval-2021 Task 4: Reading Comprehension of Abstract Meaning',\n",
       " 'Refer-YouTube-VOS',\n",
       " 'Semantic Textual Similarity (2012 - 2016)',\n",
       " 'STS',\n",
       " 'StrategyQA',\n",
       " 'Visual Madlibs',\n",
       " 'AmazonQA',\n",
       " 'ArSarcasm',\n",
       " 'ChaosNLI',\n",
       " 'ConvQuestions',\n",
       " 'CxC',\n",
       " 'Crisscrossed Captions',\n",
       " 'DSTC7 Task 1',\n",
       " 'Dialog System Technology Challenges Task 1',\n",
       " 'FLUE',\n",
       " 'French Language Understanding Evaluation',\n",
       " 'FinQA',\n",
       " 'GLGE',\n",
       " 'General Language Generation Evaluation',\n",
       " 'HeadQA',\n",
       " 'KorSTS',\n",
       " 'LitBank',\n",
       " 'MED',\n",
       " 'Monotonicity Entailment Dataset',\n",
       " 'MultiDoc2Dial',\n",
       " 'MultiDoc2Dial: Modeling Dialogues Grounded in Multiple Documents',\n",
       " 'Natural Instructions',\n",
       " 'NetHack Learning Environment',\n",
       " 'PARANMT-50M',\n",
       " 'PUBHEALTH',\n",
       " 'ParCorFull',\n",
       " 'Parallel Corpus Annotated with Full Coreference',\n",
       " 'Quasimodo',\n",
       " 'ReQA',\n",
       " 'Retrieval Question-Answering',\n",
       " 'Torque',\n",
       " 'Violin',\n",
       " 'VIdeO-and-Language INference',\n",
       " 'XL-Sum',\n",
       " 'e-SNLI-VE',\n",
       " 'AKCES-GEC',\n",
       " 'AQUA-RAT',\n",
       " 'Algebra Question Answering with Rationales',\n",
       " 'CAS-VSR-W1k (LRW-1000)',\n",
       " 'CHALET',\n",
       " 'Cornell House Agent Learning Environment',\n",
       " 'CONAN',\n",
       " 'COunter NArratives through Nichesourcing',\n",
       " 'COVID-19 Fake News Dataset',\n",
       " 'COVID19 Fake News Detection in English',\n",
       " 'DWIE',\n",
       " 'Deutsche Welle corpus for Information Extraction',\n",
       " 'FM-IQA',\n",
       " 'Freestyle Multilingual Image Question Answering',\n",
       " 'GeoS',\n",
       " 'HappyDB',\n",
       " 'IIRC',\n",
       " 'Incomplete Information Reading Comprehension',\n",
       " 'Implicit Hate',\n",
       " 'MedQA-USMLE',\n",
       " 'QMSum',\n",
       " 'SciTail',\n",
       " 'SemArt',\n",
       " 'TG-ReDial',\n",
       " 'TRIPOD',\n",
       " 'TuRnIng POint Dataset',\n",
       " 'Talk the Walk',\n",
       " 'TechQA',\n",
       " 'The TechQA Dataset',\n",
       " 'TextOCR',\n",
       " 'WiC-TSV',\n",
       " 'Words-in-Context: Target Sense Verification',\n",
       " 'WikiEvents',\n",
       " 'arXiv Summarization Dataset',\n",
       " 'ANTIQUE',\n",
       " 'Arabic Text Diacritization',\n",
       " 'BIOMRC',\n",
       " 'BookSum',\n",
       " 'CMU Movie Summary Corpus',\n",
       " 'ChFinAnn',\n",
       " 'CoDraw',\n",
       " 'CoSQA',\n",
       " 'Code Search and Question Answering',\n",
       " 'Dakshina',\n",
       " 'DialogSum',\n",
       " 'Duolingo STAPLE Shared Task',\n",
       " 'ECtHR',\n",
       " 'European Court of Human Rights Cases',\n",
       " 'EntityQuestions',\n",
       " 'FewCLUE',\n",
       " 'FreebaseQA',\n",
       " 'HOList',\n",
       " 'How2R',\n",
       " 'MEDIQA-AnS',\n",
       " 'MEDIQA-Answer Summarization',\n",
       " 'NoReC',\n",
       " 'Norwegian Review Corpus',\n",
       " 'PhraseCut',\n",
       " 'Project CodeNet',\n",
       " 'RRS',\n",
       " 'Restoration-200k for Response Selection',\n",
       " 'SCROLLS',\n",
       " 'Standardized CompaRison Over Long Language Sequences',\n",
       " 'Terms of Service',\n",
       " 'VQA-E',\n",
       " 'WikiConv',\n",
       " 'eQASC',\n",
       " '28 Ghz wireless channel dataset',\n",
       " 'A-OKVQA',\n",
       " 'ART Dataset',\n",
       " 'Abductive Reasoning in narrative Text',\n",
       " 'ASAP',\n",
       " 'Automated Student Assessment Prize',\n",
       " 'Acronym Identification',\n",
       " 'BiRD',\n",
       " 'Bigram Relatedness Dataset',\n",
       " 'BiasBios',\n",
       " 'Bias in Bios',\n",
       " 'CH-SIMS',\n",
       " 'CLEVR-Dialog',\n",
       " 'CQASUMM',\n",
       " 'ClaimBuster',\n",
       " 'DiscoFuse',\n",
       " 'Enron Email Dataset',\n",
       " 'FM2',\n",
       " 'FoolMeTwice',\n",
       " 'GRIT',\n",
       " 'General Robust Image Task Benchmark',\n",
       " 'GUM',\n",
       " 'Georgetown University Multilayer corpus',\n",
       " 'Global Voices',\n",
       " 'GrailQA',\n",
       " 'Strongly Generalizable Question Answering',\n",
       " 'Griddly',\n",
       " 'HINT3',\n",
       " 'IGLUE',\n",
       " 'Image-Grounded Language Understanding Evaluation',\n",
       " 'IQUAD',\n",
       " 'Interactive Question Answering Dataset',\n",
       " 'KLEJ',\n",
       " 'Kleister NDA',\n",
       " 'KnowIT VQA',\n",
       " 'LDC2020T02',\n",
       " 'Abstract Meaning Representation (AMR) Annotation Release 3.0',\n",
       " 'LectureBank',\n",
       " 'MixSNIPs',\n",
       " 'Moral Stories',\n",
       " 'MuSe-CaR',\n",
       " 'Multimodal Sentiment Analysis in Car Reviews',\n",
       " 'PersonalDialog',\n",
       " 'RUSSE',\n",
       " 'Russian Words in Context (based on RUSSE',\n",
       " 'Reddit Corpus',\n",
       " 'SUTD-TrafficQA',\n",
       " 'SelQA',\n",
       " 'TVC',\n",
       " 'TV show Captions',\n",
       " 'TaxiNLI',\n",
       " 'WikiAtomicEdits',\n",
       " 'AQUAINT',\n",
       " 'ArSentD-LEV',\n",
       " 'Ascent KB',\n",
       " 'BC2GM',\n",
       " 'Business Scene Dialogue',\n",
       " 'CDCP',\n",
       " 'Cornell eRulemaking Corpus',\n",
       " 'CITE',\n",
       " 'CJRC',\n",
       " 'Chinese judicial reading comprehension',\n",
       " 'CMRC 2019',\n",
       " 'Chinese Machine Reading Comprehension 2019',\n",
       " 'CUAD',\n",
       " 'Contract Understanding Atticus Dataset',\n",
       " 'ConditionalQA',\n",
       " 'DaNetQA',\n",
       " 'Yes/no Question Answering Dataset for the Russian',\n",
       " 'ETHOS',\n",
       " 'multi-labEl haTe speecH detectiOn dataSet',\n",
       " 'FairytaleQA',\n",
       " 'FarsTail',\n",
       " 'French Timebank',\n",
       " 'HONEST',\n",
       " 'Hurtful Sentence Completion in English Language Models',\n",
       " 'IBM-Rank-30k',\n",
       " 'IBM-ArgQ-Rank-30kArgs',\n",
       " 'ILDC',\n",
       " 'Indian Legal Documents Corpus',\n",
       " 'InfoTabS',\n",
       " 'KIT Motion-Language',\n",
       " 'LCQMC',\n",
       " 'Large-scale Chinese Question Matching Corpus',\n",
       " 'Lani',\n",
       " 'MATRES',\n",
       " 'Multi-Axis Temporal RElations for Start-points',\n",
       " 'MOD',\n",
       " 'Meme incorporated Open-domain Dialogue',\n",
       " 'MedNLI',\n",
       " 'Medical Natural Language Inference',\n",
       " 'Memotion Analysis',\n",
       " 'SemEval-2020 Task 8: Memotion Analysis -- The Visuo-Lingual Metaphor!',\n",
       " 'Mr. TYDI',\n",
       " 'MutualFriends',\n",
       " 'NELA-GT-2018',\n",
       " 'OMICS',\n",
       " 'Open Mind Indoor Common Sense',\n",
       " 'OrangeSum',\n",
       " 'PEYMA',\n",
       " 'PhotoBook',\n",
       " 'PlotQA',\n",
       " 'QA2D',\n",
       " 'Question to Declarative Sentence (QA2D) Dataset',\n",
       " 'QUASAR-S',\n",
       " 'QUestion Answering by Search And Reading – Stack Overflow',\n",
       " 'RAVEN-FAIR',\n",
       " 'RECCON',\n",
       " 'RIMES',\n",
       " 'Reconnaissance & Indexation de données Manuscrites et de fac similÉS / Recognition & Indexing of handwritten documents & faxes',\n",
       " 'Rainbow',\n",
       " 'ReINTEL',\n",
       " 'RefSeer',\n",
       " 'RicoSCA',\n",
       " 'SPoC',\n",
       " 'Pseudocode-to-Code',\n",
       " 'StylePTB',\n",
       " 'TEMPO',\n",
       " 'Localizing Moments in Video with Temporal Language',\n",
       " 'TableBank',\n",
       " 'TutorialBank',\n",
       " 'ViGGO',\n",
       " 'VisualMRC',\n",
       " 'VisualMRC: Machine Reading Comprehension on Document Images',\n",
       " 'VizWiz-Captions',\n",
       " 'WMT 2018 News',\n",
       " 'WMT 2018 News Translation Task',\n",
       " 'WNLaMPro',\n",
       " 'WordNet Language Model Probing',\n",
       " 'WeChat',\n",
       " 'WebQA',\n",
       " 'Wiki-ZSL',\n",
       " 'XFORMAL',\n",
       " 'XQA',\n",
       " 'iVQA',\n",
       " 'Instructional Video Question Answering',\n",
       " 'xSID',\n",
       " 'Cross-lingual Slot and Intent Detection',\n",
       " 'BBQ',\n",
       " 'Bias Benchmark for QA',\n",
       " 'BIMCV COVID-19',\n",
       " 'BMELD',\n",
       " 'CIRR',\n",
       " 'Compose Image Retrieval on Real-life images',\n",
       " 'COVID-Fact',\n",
       " 'CaseHOLD',\n",
       " 'Case Holdings On Legal Decisions',\n",
       " 'ClariQ',\n",
       " 'CoDa',\n",
       " 'The Color Dataset',\n",
       " 'ComQA',\n",
       " 'ContractNLI',\n",
       " 'ContractNLI: A Dataset for Document-level Natural Language Inference for Contracts',\n",
       " 'DaNE',\n",
       " 'Danish Dependency Treebank',\n",
       " 'FaVIQ',\n",
       " 'Fact Verification from Information-seeking Questions',\n",
       " 'Fakeddit',\n",
       " 'French Wikipedia',\n",
       " 'Gumar Corpus',\n",
       " 'Hindi Visual Genome',\n",
       " 'HowMany-QA',\n",
       " 'HumanML3D',\n",
       " 'IS-A',\n",
       " 'JuICe',\n",
       " 'JuICe Dataset',\n",
       " 'KnowledgeNet',\n",
       " 'MEDIA',\n",
       " 'MLQE',\n",
       " 'MultiLingual Quality Estimation',\n",
       " 'MM-COVID',\n",
       " 'Multilingual and Multidimensional COVID-19 Fake News Data Repository',\n",
       " 'MaRVL',\n",
       " 'Multicultural Reasoning over Vision and Language',\n",
       " 'MassiveText',\n",
       " 'MedVidQA',\n",
       " 'Medical Video Question Answering',\n",
       " 'MemexQA',\n",
       " 'MiniF2F',\n",
       " 'MovieFIB',\n",
       " 'Movie Fill-in-the-Blank',\n",
       " 'Multi-XScience',\n",
       " 'OntoGUM',\n",
       " 'OpoSum',\n",
       " 'Overruling',\n",
       " 'PARus',\n",
       " 'Choice of Plausible Alternatives for Russian language',\n",
       " 'PFN-PIC',\n",
       " 'PFN Picking Instructions for Commodities Dataset',\n",
       " 'PathVQA',\n",
       " 'PixelHelp',\n",
       " 'ProtoQA',\n",
       " 'QA-SRL Bank 2.0',\n",
       " 'RELX',\n",
       " ...]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'data/nlp_datasets.txt'\n",
    "with open(dataset_path, 'w') as f:\n",
    "    for d in datasets:\n",
    "        f.write(d)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
