For -X- _ O
the -X- _ O
visual -X- _ O
data, -X- _ O
we -X- _ O
extract -X- _ O
35 -X- _ O
facial -X- _ O
action -X- _ O
units -X- _ O
(FAUs) -X- _ O
using -X- _ O
the -X- _ O
OpenFace -X- _ B-MethodName
library -X- _ O
5 -X- _ O
(Baltrušaitis -X- _ O
et -X- _ O
al, -X- _ O
2015;Baltrusaitis -X- _ O
et -X- _ O
al, -X- _ O
2018) -X- _ O
for -X- _ O
the -X- _ O
image -X- _ O
frames -X- _ O
in -X- _ O
the -X- _ O
video, -X- _ O
which -X- _ O
capture -X- _ O
the -X- _ O
movement -X- _ O
of -X- _ O
facial -X- _ O
muscles -X- _ O
(Ekman -X- _ O
et -X- _ O
al, -X- _ O
1980 -X- _ O
Table -X- _ O
4: -X- _ O
The -X- _ O
results -X- _ O
on -X- _ O
the -X- _ B-DatasetName
CMU-MOSEI -X- _ I-DatasetName
dataset. -X- _ O

We -X- _ O
decode -X- _ O
programs -X- _ O
using -X- _ O
beam -X- _ B-MethodName
search -X- _ I-MethodName
with -X- _ O
a -X- _ O
beam -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
5. -X- _ B-HyperparameterValue

Specifically, -X- _ O
DeepW-MaxSAT -X- _ B-MethodName
consists -X- _ O
of -X- _ O
1) -X- _ O
a -X- _ B-HyperparameterValue
DNN -X- _ B-HyperparameterName
layer -X- _ I-HyperparameterName
that -X- _ O
transforms -X- _ O
an -X- _ O
input -X- _ O
embedding -X- _ O
to -X- _ O
a -X- _ O
high-level -X- _ O
feature -X- _ O
representation; -X- _ O
2) -X- _ O
a -X- _ B-HyperparameterValue
weighted -X- _ B-HyperparameterName
MaxSAT -X- _ I-HyperparameterName
layer -X- _ I-HyperparameterName
that -X- _ O
takes -X- _ O
DNN -X- _ O
outputs -X- _ O
as -X- _ O
the -X- _ O
initial -X- _ O
probabilistic -X- _ O
evaluations -X- _ O
on -X- _ O
the -X- _ O
logic -X- _ O
variables -X- _ O
and -X- _ O
produces -X- _ O
the -X- _ O
values -X- _ O
for -X- _ O
the -X- _ O
output -X- _ O
logic -X- _ O
variables -X- _ O
corresponding -X- _ O
to -X- _ O
the -X- _ O
head -X- _ O
atoms -X- _ O
of -X- _ O
selected -X- _ O
logic -X- _ O
rules; -X- _ O
3) -X- _ O
a -X- _ B-HyperparameterValue
conditional -X- _ B-HyperparameterName
random -X- _ I-HyperparameterName
field -X- _ I-HyperparameterName
(CRF) -X- _ B-HyperparameterName
(Lafferty -X- _ O
et -X- _ O
al, -X- _ O
2001) -X- _ O
layer -X- _ O
that -X- _ O
generates -X- _ O
structured -X- _ O
outputs -X- _ O
(label -X- _ O
sequences) -X- _ O
considering -X- _ O
linear -X- _ O
context -X- _ O
interactions -X- _ O
among -X- _ O
the -X- _ O
tokens -X- _ O
in -X- _ O
a -X- _ O
sequence. -X- _ O

In -X- _ O
terms -X- _ O
of -X- _ O
the -X- _ O
live -X- _ O
evaluation, -X- _ O
competitions -X- _ O
such -X- _ O
as -X- _ B-DatasetName
ConvAI2 -X- _ I-DatasetName
report -X- _ O
such -X- _ O
evaluations -X- _ O
as -X- _ O
highly -X- _ O
challenging, -X- _ O
with -X- _ O
many -X- _ O
of -X- _ O
the -X- _ O
resulting -X- _ O
dialogues -X- _ O
reported -X- _ O
to -X- _ O
be -X- _ O
senseless, -X- _ O
offensive, -X- _ O
or -X- _ O
simply -X- _ O
not -X- _ O
in -X- _ O
line -X- _ O
with -X- _ O
instructions -X- _ O
and -X- _ O
ultimately -X- _ O
live -X- _ O
evaluation -X- _ O
results -X- _ O
have -X- _ O
been -X- _ O
discarded. -X- _ O

Inspired -X- _ O
by -X- _ O
siamese -X- _ O
network -X- _ O
structure -X- _ O
(Bromley -X- _ O
et -X- _ O
al, -X- _ O
1994), -X- _ O
we -X- _ O
construct -X- _ O
a -X- _ O
Siamese-BERT -X- _ B-MethodName
architecture -X- _ O
to -X- _ O
match -X- _ O
the -X- _ O
document -X- _ O
D -X- _ O
and -X- _ O
the -X- _ O
candidate -X- _ O
summary -X- _ O
C. -X- _ O
Our -X- _ O
Siamese-BERT -X- _ B-MethodName
consists -X- _ O
of -X- _ O
two -X- _ O
BERTs -X- _ B-MethodName
with -X- _ O
tied-weights -X- _ O
and -X- _ O
a -X- _ O
cosine-similarity -X- _ O
layer -X- _ O
during -X- _ O
the -X- _ O
inference -X- _ O
phase. -X- _ O

We -X- _ O
conduct -X- _ O
an -X- _ O
ablation -X- _ O
study -X- _ O
of -X- _ O
the -X- _ O
multi-cross -X- _ O
(n=3) -X- _ B-HyperparameterName
model -X- _ O
on -X- _ O
RR-Submission-v1 -X- _ B-DatasetName
dataset -X- _ O
from -X- _ O
three -X- _ O
perspectives, -X- _ O
as -X- _ O
presented -X- _ O
in -X- _ O
Table -X- _ O
3. -X- _ O
Firstly, -X- _ O
we -X- _ O
evaluate -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
sharing -X- _ O
the -X- _ O
biLSTM -X- _ B-MethodName
layer -X- _ O
(the -X- _ O
light -X- _ O
yellow -X- _ O
modules -X- _ O
in -X- _ O
Figure -X- _ O
2) -X- _ O
and -X- _ O
the -X- _ O
CRF -X- _ B-MethodName
layer. -X- _ O

The -X- _ O
inflating -X- _ O
operation -X- _ O
plugs -X- _ O
several -X- _ O
codes -X- _ O
in -X- _ O
the -X- _ O
input -X- _ O
of -X- _ O
the -X- _ O
encoder -X- _ O
to -X- _ O
exploit -X- _ O
the -X- _ O
text-image -X- _ O
interactions -X- _ O
more -X- _ O
thoroughly -X- _ O
for -X- _ O
higher -X- _ O
retrieval -X- _ O
accuracy. -X- _ B-MetricName

CMU-MOSEI -X- _ B-DatasetName
(Zadeh -X- _ O
et -X- _ O
al, -X- _ O
2018b) -X- _ O
sample -X- _ O
in -X- _ B-DatasetName
CMU-MOSEI -X- _ I-DatasetName
consists -X- _ O
of -X- _ O
three -X- _ O
modalities: -X- _ O
audio -X- _ O
data -X- _ O
with -X- _ O
a -X- _ O
sampling -X- _ O
rate -X- _ O
of -X- _ O
44.1 -X- _ O
kHz, -X- _ O
a -X- _ O
text -X- _ O
transcript, -X- _ O
and -X- _ O
image -X- _ O
frames -X- _ O
sampled -X- _ O
from -X- _ O
the -X- _ O
video -X- _ O
at -X- _ O
30 -X- _ O
Hz. -X- _ O

We -X- _ O
use -X- _ O
two -X- _ O
initial -X- _ O
pre-trained -X- _ O
models, -X- _ O
BST2.7 -X- _ B-MethodName
and -X- _ O
DialoGPT. -X- _ B-MethodName

Therefore, -X- _ O
we -X- _ O
train -X- _ O
a -X- _ O
BiLSTM -X- _ B-MethodName
encoder -X- _ O
15 -X- _ O
to -X- _ O
build -X- _ O
event -X- _ O
phrase -X- _ O
embeddings, -X- _ O
using -X- _ O
the -X- _ O
knowledge -X- _ O
representation -X- _ O
learning -X- _ O
model -X- _ O
TransE -X- _ B-MethodName
(Bordes -X- _ O
et -X- _ O
al, -X- _ O
2013) -X- _ O
16 -X- _ O
such -X- _ O
that -X- _ O
p -X- _ O
+ -X- _ O
r -X- _ O
⇡ -X- _ O
c -X- _ O
given -X- _ O
a -X- _ O
parent-child -X- _ O
event -X- _ O
pair -X- _ O
(p, -X- _ O
c) -X- _ O
having -X- _ O
the -X- _ O
subevent -X- _ O
relation -X- _ O
r. -X- _ O
We -X- _ O
will -X- _ O
use -X- _ O
the -X- _ O
trained -X- _ O
BiL-STM -X- _ B-MethodName
encoder -X- _ O
to -X- _ O
obtain -X- _ O
an -X- _ O
embedding -X- _ O
for -X- _ O
an -X- _ O
event -X- _ O
phrase -X- _ O
in -X- _ O
the -X- _ O
RED -X- _ B-DatasetName
or -X- _ O
HiEve -X- _ B-DatasetName
dataset. -X- _ O

The -X- _ O
results -X- _ O
of -X- _ O
XL-AMR -X- _ B-MethodName
significantly -X- _ O
surpass -X- _ O
those -X- _ O
previously -X- _ O
reported -X- _ O
in -X- _ O
Chinese, -X- _ O
German, -X- _ O
Italian -X- _ O
and -X- _ O
Spanish. -X- _ O

This -X- _ O
can -X- _ O
be -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
produced -X- _ O
data -X- _ O
and -X- _ O
does -X- _ O
not -X- _ O
rely -X- _ O
on -X- _ O
AMR -X- _ B-MethodName
aligners -X- _ I-MethodName
or -X- _ O
source-copy -X- _ O
mechanisms -X- _ O
as -X- _ O
is -X- _ O
commonly -X- _ O
the -X- _ O
case -X- _ O
in -X- _ O
English -X- _ B-TaskName
AMR -X- _ I-TaskName
parsing. -X- _ I-TaskName

Positional -X- _ O
Encoding -X- _ O
In -X- _ O
Table -X- _ O
8, -X- _ O
moving -X- _ O
positional -X- _ O
embeddings -X- _ O
from -X- _ O
input -X- _ O
to -X- _ O
per-head -X- _ O
improves -X- _ O
average -X- _ O
score -X- _ O
for -X- _ O
both -X- _ O
DIET-REL -X- _ B-MethodName
(+0.1%) -X- _ B-MetricValue
and -X- _ O
DIET-ABS -X- _ B-MethodName
(+0.2%). -X- _ B-MetricValue

Surprisingly, -X- _ O
for -X- _ O
hate -X- _ O
speech, -X- _ O
a -X- _ O
higher -X- _ O
FPR -X- _ B-MetricName
does -X- _ O
not -X- _ O
translate -X- _ O
to -X- _ O
higher -X- _ O
F1, -X- _ B-MetricName
indicating -X- _ O
that -X- _ O
a -X- _ O
combination -X- _ O
of -X- _ O
different -X- _ O
types -X- _ O
of -X- _ O
CAD -X- _ O
(CF_mix) -X- _ O
reduces -X- _ O
unintended -X- _ O
bias -X- _ O
without -X- _ O
sacrificing -X- _ O
F1 -X- _ B-MetricName
score. -X- _ O

We -X- _ O
benchmark -X- _ O
several -X- _ O
state-of-the-art -X- _ O
OIE -X- _ B-TaskName
systems -X- _ O
using -X- _ B-DatasetName
BenchIE -X- _ I-DatasetName
and -X- _ O
demonstrate -X- _ O
that -X- _ O
these -X- _ O
systems -X- _ O
are -X- _ O
significantly -X- _ O
less -X- _ O
effective -X- _ O
than -X- _ O
indicated -X- _ O
by -X- _ O
existing -X- _ O
OIE -X- _ O
benchmarks. -X- _ B-TaskName

We -X- _ O
use -X- _ O
Grid -X- _ O
search -X- _ O
to -X- _ O
explore: -X- _ O
Hidden -X- _ B-HyperparameterName
dimension -X- _ I-HyperparameterName
H -X- _ O
d -X- _ O
∈ -X- _ O
{128, -X- _ B-HyperparameterValue
256, -X- _ B-HyperparameterValue
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
1024}, -X- _ B-HyperparameterValue
Dropout -X- _ B-HyperparameterName
δ -X- _ O
∈ -X- _ O
{0.0, -X- _ B-HyperparameterValue
0.1, -X- _ B-HyperparameterValue
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
0.7}. -X- _ B-HyperparameterValue
For -X- _ O
the -X- _ O
HEAT: -X- _ O
β -X- _ B-HyperparameterName
∈ -X- _ O
{1e -X- _ B-HyperparameterValue
−3 -X- _ I-HyperparameterValue
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
1e -X- _ B-HyperparameterValue
−1 -X- _ I-HyperparameterValue
} -X- _ O
and -X- _ O
∈ -X- _ O
{1e -X- _ B-HyperparameterValue
−3 -X- _ I-HyperparameterValue
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
1e -X- _ B-HyperparameterValue
−1 -X- _ I-HyperparameterValue
}. -X- _ O

We -X- _ O
could -X- _ O
make -X- _ O
the -X- _ O
following -X- _ O
observations: -X- _ O
• -X- _ O
Overall, -X- _ O
i) -X- _ O
our -X- _ O
model -X- _ O
achieves -X- _ O
state-of-the-art -X- _ O
performance, -X- _ O
i.e., -X- _ O
the -X- _ O
F -X- _ B-MetricName
1 -X- _ I-MetricName
score -X- _ I-MetricName
and -X- _ O
accuracy -X- _ B-MetricName
are -X- _ O
51.24% -X- _ B-MetricValue
and -X- _ O
59.94% -X- _ B-MetricValue
on -X- _ O
the -X- _ O
4-way -X- _ B-TaskName
classification, -X- _ I-TaskName
respectively; -X- _ O
ii) -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
binary -X- _ B-TaskName
classification -X- _ I-TaskName
are -X- _ O
keeping -X- _ O
a -X- _ O
similar -X- _ O
tendency -X- _ O
with -X- _ O
the -X- _ O
4-way -X- _ B-TaskName
classification. -X- _ I-TaskName

We -X- _ O
first -X- _ O
note -X- _ O
the -X- _ O
strong -X- _ O
correlation -X- _ O
(negative) -X- _ O
between -X- _ O
a -X- _ O
model's -X- _ O
perplexity -X- _ B-MetricName
on -X- _ B-DatasetName
WikiText-2 -X- _ I-DatasetName
and -X- _ O
its -X- _ O
StereoSet -X- _ B-MetricName
language -X- _ I-MetricName
modeling -X- _ I-MetricName
score. -X- _ I-MetricName

We -X- _ O
visualize -X- _ O
the -X- _ O
learned -X- _ O
representation -X- _ O
space -X- _ O
of -X- _ O
DGP -X- _ B-MethodName
and -X- _ O
IGP -X- _ B-MethodName
for -X- _ B-DatasetName
DBpedia, -X- _ I-DatasetName
using -X- _ O
t-SNE -X- _ B-MethodName
(van -X- _ O
der -X- _ O
Maaten -X- _ O
and -X- _ O
Hinton, -X- _ O
2008), -X- _ O
in -X- _ O
Figure -X- _ O
3 -X- _ O
(bottom). -X- _ O

Our -X- _ O
contributions -X- _ O
are: -X- _ O
(1) -X- _ O
We -X- _ O
suggest -X- _ O
a -X- _ O
simple, -X- _ O
yet -X- _ O
effective -X- _ O
KG -X- _ O
modularization -X- _ O
strategy -X- _ O
for -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
multiple -X- _ O
KGs -X- _ O
in -X- _ O
commonsense -X- _ O
reasoning. -X- _ O
(2) -X- _ O
We -X- _ O
then -X- _ O
explore -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
AdapterFusion -X- _ O
(Pfeiffer -X- _ O
et -X- _ O
al, -X- _ O
2021) -X- _ O
for -X- _ O
better -X- _ O
knowledge -X- _ O
aggregation -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
KG -X- _ O
modularization -X- _ O
in -X- _ O
zero-shot -X- _ O
setting. -X- _ O

Our -X- _ O
adversarial -X- _ O
learning -X- _ O
algorithm -X- _ O
can -X- _ O
be -X- _ O
interpreted -X- _ O
as -X- _ O
a -X- _ B-TaskName
data -X- _ I-TaskName
augmentation -X- _ I-TaskName
algorithm, -X- _ O
but -X- _ O
instead -X- _ O
of -X- _ O
a -X- _ O
heuristic -X- _ O
approach -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
principled -X- _ O
end-to-end -X- _ O
differentiable -X- _ O
augmentation -X- _ O
method -X- _ O
based -X- _ O
on -X- _ O
adversarial -X- _ O
learning. -X- _ O

We -X- _ O
also -X- _ O
optimized -X- _ O
the -X- _ O
conditioning -X- _ B-HyperparameterName
strength -X- _ I-HyperparameterName
λ -X- _ B-HyperparameterName
WDEC -X- _ I-HyperparameterName
for -X- _ O
the -X- _ O
WDEC -X- _ B-MethodName
baseline -X- _ O
on -X- _ O
the -X- _ O
same -X- _ O
fantasy -X- _ O
bag -X- _ O
of -X- _ O
words, -X- _ O
considering -X- _ O
values -X- _ O
ranging -X- _ O
from -X- _ O
1 -X- _ B-HyperparameterValue
to -X- _ O
32. -X- _ B-HyperparameterValue

The -X- _ B-DatasetName
TVQA -X- _ I-DatasetName
context -X- _ O
features -X- _ O
are -X- _ O
dialogues -X- _ O
or -X- _ O
video -X- _ O
subtitles; -X- _ O
hence -X- _ B-TaskName
data -X- _ I-TaskName
augmentation -X- _ I-TaskName
on -X- _ O
this -X- _ O
dataset -X- _ O
should -X- _ O
consider -X- _ O
an -X- _ O
additional -X- _ O
frame-level -X- _ O
dimension. -X- _ O

All -X- _ O
BERT -X- _ B-MethodName
or -X- _ O
RoBERTa -X- _ B-MethodName
layers -X- _ O
are -X- _ O
debiased -X- _ O
at -X- _ O
the -X- _ O
token -X- _ O
level, -X- _ O
and -X- _ O
the -X- _ O
debiasing -X- _ B-HyperparameterName
loss -X- _ I-HyperparameterName
weight -X- _ I-HyperparameterName
is -X- _ O
set -X- _ O
to -X- _ O
0.8. -X- _ B-HyperparameterValue

We -X- _ O
first -X- _ O
produce -X- _ O
a -X- _ O
new -X- _ O
dataset, -X- _ O
BASIL, -X- _ B-MethodName
of -X- _ O
300 -X- _ O
news -X- _ O
articles -X- _ O
annotated -X- _ O
with -X- _ O
1,727 -X- _ O
bias -X- _ O
spans -X- _ O
1 -X- _ O
and -X- _ O
find -X- _ O
evidence -X- _ O
that -X- _ O
informational -X- _ O
bias -X- _ O
appears -X- _ O
in -X- _ O
news -X- _ O
articles -X- _ O
more -X- _ O
frequently -X- _ O
than -X- _ O
lexical -X- _ O
bias. -X- _ O

We -X- _ O
employ -X- _ O
wikitext-103 -X- _ B-DatasetName
corpus -X- _ O
to -X- _ O
train -X- _ O
a -X- _ O
5-gram -X- _ O
English -X- _ O
LM -X- _ O
for -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
access -X- _ O
to -X- _ O
external -X- _ O
data. -X- _ O

Empirical -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
method -X- _ O
achieves -X- _ O
56.93%, -X- _ B-MetricValue
60.73%, -X- _ B-MetricValue
and -X- _ O
58.04% -X- _ B-MetricValue
joint -X- _ O
accuracy -X- _ B-MetricName
on -X- _ O
MultiWOZ -X- _ B-DatasetName
2.0, -X- _ I-DatasetName
MultiWOZ -X- _ B-DatasetName
2.1, -X- _ I-DatasetName
and -X- _ O
Multi-WOZ -X- _ B-DatasetName
2.2 -X- _ I-DatasetName
datasets -X- _ O
respectively -X- _ O
and -X- _ O
achieves -X- _ O
a -X- _ O
new -X- _ O
state-of-the-art -X- _ O
performance -X- _ O
with -X- _ O
significant -X- _ O
improvements. -X- _ O

Experiments -X- _ O
on -X- _ O
multiple -X- _ O
realworld -X- _ O
datasets -X- _ O
across -X- _ O
various -X- _ O
domains -X- _ O
show -X- _ O
the -X- _ O
superiority -X- _ O
and -X- _ O
robustness -X- _ O
of -X- _ O
our -X- _ O
model, -X- _ O
significantly -X- _ O
outperforming -X- _ O
previous -X- _ O
state-ofthe-art -X- _ O
cross-domain -X- _ O
CWS -X- _ B-MethodName
methods. -X- _ O

Specifically, -X- _ O
with -X- _ O
a -X- _ O
top-p -X- _ B-HyperparameterName
of -X- _ O
0.5, -X- _ B-HyperparameterValue
the -X- _ O
MESM -X- _ B-MethodName
can -X- _ O
achieve -X- _ O
comparable -X- _ O
performance -X- _ O
to -X- _ O
the -X- _ O
FE2E -X- _ B-MethodName
model -X- _ O
with -X- _ O
around -X- _ O
half -X- _ O
of -X- _ O
the -X- _ O
FLOPs -X- _ O
in -X- _ O
the -X- _ O
feature -X- _ B-TaskName
extraction. -X- _ I-TaskName

We -X- _ O
observe -X- _ O
a -X- _ O
major -X- _ O
improvements -X- _ O
across -X- _ O
all -X- _ O
evaluation -X- _ O
sets -X- _ O
after -X- _ O
the -X- _ O
projection: -X- _ O
between -X- _ O
0.044 -X- _ B-MetricValue
to -X- _ O
0.116 -X- _ B-MetricValue
points. -X- _ O

These -X- _ O
questions, -X- _ O
which -X- _ O
have -X- _ O
a -X- _ O
phrase -X- _ O
specifying -X- _ O
the -X- _ O
geographical -X- _ O
context, -X- _ O
comprise -X- _ O
about -X- _ O
4.4% -X- _ B-MetricValue
of -X- _ O
NQ-Open. -X- _ B-DatasetName

However, -X- _ O
when -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
sentences -X- _ I-HyperparameterName
increases -X- _ O
to -X- _ O
two -X- _ B-HyperparameterValue
and -X- _ O
summary-level -X- _ B-TaskName
semantics -X- _ I-TaskName
need -X- _ O
to -X- _ O
be -X- _ O
taken -X- _ O
into -X- _ O
account, -X- _ O
MATCHSUM -X- _ B-MethodName
can -X- _ O
obtain -X- _ O
a -X- _ O
more -X- _ O
re- -X- _ O
markable -X- _ O
improvement -X- _ O
(compared -X- _ O
to -X- _ O
BERTEXT -X- _ B-MethodName
(Num -X- _ B-HyperparameterName
= -X- _ O
2), -X- _ B-MetricValue
1.04 -X- _ B-MetricValue
∆R-1 -X- _ I-MetricValue
on -X- _ O
Reddit, -X- _ B-DatasetName
1.62 -X- _ B-MetricValue
∆R-1 -X- _ I-MetricValue
on -X- _ O
XSum). -X- _ B-DatasetName

For -X- _ O
each -X- _ O
type -X- _ O
description -X- _ O
d -X- _ O
c -X- _ O
, -X- _ O
the -X- _ O
cross-attention -X- _ B-MethodName
encoder -X- _ I-MethodName
(X-ENC) -X- _ B-MethodName
generates -X- _ O
a -X- _ O
vector -X- _ O
representation -X- _ O
v -X- _ O
t,c -X- _ O
∈ -X- _ O
R -X- _ O
h -X- _ O
for -X- _ O
a -X- _ O
token -X- _ O
w -X- _ O
t -X- _ O
in -X- _ O
the -X- _ O
sentence -X- _ O
s: -X- _ O
v -X- _ O
1,c -X- _ O
, -X- _ O
..., -X- _ O
v -X- _ O
n,c -X- _ O
= -X- _ O
X-ENC(s, -X- _ O
d -X- _ O
c -X- _ O
). -X- _ O

MSCOCO -X- _ B-DatasetName
consists -X- _ O
of -X- _ O
123, -X- _ O
287 -X- _ O
images, -X- _ O
and -X- _ O
each -X- _ O
image -X- _ O
contains -X- _ O
5 -X- _ O
ground-truth -X- _ O
captions. -X- _ O

Inspired -X- _ O
by -X- _ O
the -X- _ O
recent -X- _ O
success -X- _ O
of -X- _ O
Variational -X- _ B-MethodName
Auto-Encoder -X- _ I-MethodName
(VAE) -X- _ B-MethodName
based -X- _ O
post-hoc -X- _ O
conditional -X- _ O
image -X- _ O
generation -X- _ O
strategy -X- _ O
(Engel -X- _ O
et -X- _ O
al, -X- _ O
2018), -X- _ O
we -X- _ O
provide -X- _ O
a -X- _ O
new -X- _ O
perspective -X- _ O
for -X- _ O
flexible -X- _ O
conditional -X- _ B-TaskName
text -X- _ I-TaskName
generation. -X- _ I-TaskName

The -X- _ O
SVR-RF-R -X- _ B-MethodName
model -X- _ O
used -X- _ O
a -X- _ O
total -X- _ O
of -X- _ O
2855 -X- _ B-HyperparameterValue
features. -X- _ B-HyperparameterName

For -X- _ O
the -X- _ O
sentences -X- _ O
in -X- _ O
the -X- _ O
foreign -X- _ O
language, -X- _ O
we -X- _ O
learn -X- _ O
the -X- _ O
BPE -X- _ O
from -X- _ O
the -X- _ O
training -X- _ O
data, -X- _ O
while -X- _ O
for -X- _ O
English -X- _ O
sentences -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
already -X- _ O
available -X- _ O
GPT2-BPE -X- _ B-MethodName
dictionary -X- _ O
to -X- _ O
exploit -X- _ O
English -X- _ O
language -X- _ O
prior. -X- _ O

Koppel -X- _ O
and -X- _ O
Schler -X- _ O
(2004) -X- _ O
and -X- _ O
Luyckx -X- _ O
and -X- _ O
Daelemans -X- _ O
(2008) -X- _ O
explore -X- _ O
methods -X- _ O
for -X- _ B-TaskName
authorship -X- _ I-TaskName
verification -X- _ I-TaskName
for -X- _ O
larger -X- _ O
documents -X- _ O
such -X- _ O
as -X- _ O
essays -X- _ O
and -X- _ O
novels. -X- _ O

IMDB -X- _ B-DatasetName
(Maas -X- _ O
et -X- _ O
al, -X- _ O
2011) -X- _ O
consists -X- _ O
of -X- _ O
50k -X- _ O
informal -X- _ O
movie -X- _ O
reviews -X- _ O
from -X- _ O
the -X- _ O
Internet -X- _ O
Movie -X- _ O
Database. -X- _ O

A -X- _ O
logistic -X- _ O
classifier -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
English -X- _ O
training -X- _ O
set -X- _ O
and -X- _ O
then -X- _ O
evaluated -X- _ O
on -X- _ O
English, -X- _ O
French, -X- _ O
German -X- _ O
and -X- _ O
Japanese -X- _ O
test -X- _ O
sets -X- _ O
(each -X- _ O
has -X- _ O
6000 -X- _ O
examples) -X- _ O
using -X- _ O
the -X- _ O
same -X- _ O
trained -X- _ O
model, -X- _ O
i.e. -X- _ O
the -X- _ O
evaluation -X- _ O
is -X- _ O
zeroshot. -X- _ O

Some -X- _ O
previous -X- _ O
approaches -X- _ O
for -X- _ B-DatasetName
SCAN -X- _ I-DatasetName
require -X- _ O
task-specific -X- _ O
information -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
mapping -X- _ O
of -X- _ O
atoms -X- _ O
Gordon -X- _ O
et -X- _ O
al, -X- _ O
2019) -X- _ O
or -X- _ O
a -X- _ O
grammar -X- _ O
mimicking -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
(Nye -X- _ O
et -X- _ O
al, -X- _ O
2020), -X- _ O
and -X- _ O
as -X- _ O
such -X- _ O
are -X- _ O
difficult -X- _ O
to -X- _ O
adapt -X- _ O
to -X- _ O
non-synthetic -X- _ O
datasets. -X- _ O

Despite -X- _ O
having -X- _ O
no -X- _ O
access -X- _ O
to -X- _ O
text, -X- _ O
the -X- _ O
SAT-FT -X- _ B-MethodName
speech -X- _ O
captioning -X- _ O
model -X- _ O
trained -X- _ O
on -X- _ O
VQ3 -X- _ B-MethodName
units -X- _ O
achieves -X- _ O
a -X- _ O
BLEU-4 -X- _ B-MetricName
score -X- _ O
of -X- _ O
.233 -X- _ B-MetricName
with -X- _ O
beam -X- _ B-MethodName
search -X- _ I-MethodName
decoding -X- _ I-MethodName
on -X- _ O
MSCOCO. -X- _ B-DatasetName

Compared -X- _ O
to -X- _ O
the -X- _ O
baselines, -X- _ O
the -X- _ O
fully -X- _ O
endto-end -X- _ O
(FE2E) -X- _ B-MethodName
model -X- _ O
surpasses -X- _ O
them -X- _ O
by -X- _ O
a -X- _ O
large -X- _ O
margin -X- _ O
on -X- _ O
all -X- _ O
the -X- _ O
evaluation -X- _ O
metrics. -X- _ O

Next, -X- _ O
we -X- _ O
collect -X- _ O
a -X- _ O
list -X- _ O
of -X- _ O
sentences -X- _ O
S -X- _ O
from -X- _ O
the -X- _ O
parameters -X- _ O
for -X- _ O
various -X- _ O
training -X- _ O
configurations -X- _ O
on -X- _ O
a -X- _ O
small -X- _ O
set -X- _ O
(10 -X- _ B-DatasetName
documents) -X- _ O
of -X- _ O
the -X- _ O
ISNotes -X- _ B-DatasetName
corpus -X- _ O
and -X- _ O
the -X- _ O
BASHI -X- _ B-DatasetName
corpus, -X- _ O
respectively. -X- _ O

We -X- _ O
introduce -X- _ O
a -X- _ O
novel -X- _ O
approach -X- _ O
(DISTDR) -X- _ B-MethodName
that -X- _ O
iteratively -X- _ O
improves -X- _ O
over -X- _ O
a -X- _ O
weak -X- _ O
retriever -X- _ O
by -X- _ O
alternately -X- _ O
finding -X- _ O
evidence -X- _ O
from -X- _ O
the -X- _ O
up-to-date -X- _ O
model -X- _ O
and -X- _ O
encouraging -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
most -X- _ O
likely -X- _ O
evidence. -X- _ O

Under -X- _ O
certain -X- _ O
conditions, -X- _ O
this -X- _ O
method -X- _ O
can -X- _ O
provably -X- _ O
debias -X- _ B-TaskName
skipgram -X- _ B-MethodName
and -X- _ O
GloVe -X- _ B-MethodName
word -X- _ I-MethodName
embeddings -X- _ I-MethodName
(Ethayarajh -X- _ O
et -X- _ O
al, -X- _ O
2019b), -X- _ O
but -X- _ O
in -X- _ O
practice, -X- _ O
these -X- _ O
conditions -X- _ O
are -X- _ O
typically -X- _ O
not -X- _ O
satisfied -X- _ O
and -X- _ O
gender -X- _ O
associations -X- _ O
can -X- _ O
still -X- _ O
be -X- _ O
recovered -X- _ O
from -X- _ O
the -X- _ O
embedding -X- _ O
space -X- _ O
(Gonen -X- _ O
and -X- _ O
Goldberg, -X- _ O
2019). -X- _ O

Reading -X- _ O
comprehension -X- _ O
models -X- _ O
are -X- _ O
biased -X- _ O
in -X- _ O
many -X- _ O
ways: -X- _ O
they -X- _ O
often -X- _ O
expect -X- _ O
lexical -X- _ O
overlap -X- _ O
between -X- _ O
answer -X- _ O
and -X- _ O
question -X- _ O
(Schlegel -X- _ O
et -X- _ O
al, -X- _ O
2020), -X- _ O
expect -X- _ O
the -X- _ O
answers -X- _ O
to -X- _ O
occur -X- _ O
in -X- _ O
specific -X- _ O
positions -X- _ O
(Jia -X- _ O
and -X- _ O
Liang, -X- _ O
2017), -X- _ O
or -X- _ O
expect -X- _ O
answers -X- _ O
to -X- _ O
be -X- _ O
named -X- _ O
entities -X- _ O
(Rondeau -X- _ O
and -X- _ O
Hazen, -X- _ O
2018). -X- _ O

Instead -X- _ O
of -X- _ O
selecting -X- _ O
the -X- _ O
top -X- _ O
program -X- _ O
based -X- _ O
on -X- _ O
Eq. -X- _ O
2, -X- _ O
we -X- _ O
also -X- _ O
tried -X- _ O
the -X- _ O
exploration -X- _ O
strategy -X- _ O
proposed -X- _ O
in -X- _ O
(Guu -X- _ O
et -X- _ O
al, -X- _ O
2017) -X- _ O
to -X- _ O
sample -X- _ O
a -X- _ O
non-top -X- _ O
label-consistent -X- _ O
program -X- _ O
with -X- _ O
a -X- _ O
small -X- _ O
probability. -X- _ O

Considering -X- _ O
that -X- _ O
these -X- _ O
domains -X- _ O
have -X- _ O
no -X- _ O
priority -X- _ O
to -X- _ O
each -X- _ O
other, -X- _ O
so -X- _ O
we -X- _ O
set -X- _ O
α -X- _ B-MetricName
= -X- _ O
0.999 -X- _ B-HyperparameterValue
(approximate -X- _ O
1) -X- _ O
in -X- _ O
Eq. -X- _ O
3. -X- _ O

The -X- _ O
proposed -X- _ O
models -X- _ O
are -X- _ O
optimized -X- _ O
using -X- _ O
AdamW -X- _ B-MethodName
(Loshchilov -X- _ O
and -X- _ O
Hutter, -X- _ O
2019) -X- _ O
with -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
5e-5 -X- _ B-HyperparameterValue
and -X- _ O
weight -X- _ B-HyperparameterName
decay -X- _ I-HyperparameterName
1e-5. -X- _ B-HyperparameterValue

The -X- _ O
table -X- _ O
shows -X- _ O
less -X- _ O
promising -X- _ O
results, -X- _ O
where -X- _ O
the -X- _ O
best -X- _ O
model, -X- _ O
CHIMencoder, -X- _ B-MethodName
achieves -X- _ O
a -X- _ O
decrease -X- _ O
of -X- _ O
0.88 -X- _ B-MetricValue
points -X- _ O
in -X- _ O
perplexity -X- _ B-MetricName
from -X- _ O
the -X- _ O
random -X- _ O
encodings. -X- _ O

Recently, -X- _ B-TaskName
contrastive -X- _ I-TaskName
learning -X- _ I-TaskName
has -X- _ O
shown -X- _ O
strong -X- _ O
power -X- _ O
in -X- _ O
learning -X- _ O
and -X- _ O
distinguishing -X- _ O
significant -X- _ O
knowledge -X- _ O
by -X- _ O
concentrating -X- _ O
positive -X- _ O
samples -X- _ O
and -X- _ O
contrasting -X- _ O
with -X- _ O
negative -X- _ O
samples, -X- _ O
and -X- _ O
brought -X- _ O
significant -X- _ O
improvements -X- _ O
in -X- _ O
many -X- _ O
tasks, -X- _ O
such -X- _ O
as -X- _ O
improving -X- _ O
the -X- _ O
faithfulness -X- _ O
of -X- _ O
summarization -X- _ O
and -X- _ O
discriminating -X- _ O
vital -X- _ O
information -X- _ O
to -X- _ O
enhance -X- _ O
repre-sentation -X- _ O
Zeng -X- _ O
et -X- _ O
al, -X- _ O
2021). -X- _ O

We -X- _ O
split -X- _ O
the -X- _ O
text -X- _ O
sequence -X- _ O
to -X- _ O
fit -X- _ O
the -X- _ O
max -X- _ O
input -X- _ O
length -X- _ O
by -X- _ O
sliding -X- _ O
a -X- _ O
window -X- _ O
with -X- _ O
a -X- _ O
stride -X- _ B-HyperparameterName
of -X- _ O
128 -X- _ B-HyperparameterValue
tokens. -X- _ I-HyperparameterValue

After -X- _ O
going -X- _ O
through -X- _ O
an -X- _ O
L-layer -X- _ B-HyperparameterName
GAT, -X- _ B-MethodName
the -X- _ O
output -X- _ O
embedding -X- _ O
in -X- _ O
the -X- _ O
final -X- _ O
layer -X- _ O
is -X- _ O
calculated -X- _ O
using -X- _ O
averaging, -X- _ O
instead -X- _ O
of -X- _ O
the -X- _ O
concatenation -X- _ O
operation: -X- _ O
h -X- _ O
(L) -X- _ O
x -X- _ O
i -X- _ O
= -X- _ O
ReLU -X- _ O
( -X- _ O
1 -X- _ O
K -X- _ O
K -X- _ O
k=1 -X- _ O
j∈N -X- _ O
i -X- _ O
α -X- _ O
(l -X- _ O
,k) -X- _ O
i,j -X- _ O
W -X- _ O
(l -X- _ O
) -X- _ O
k -X- _ O
h -X- _ O
(l -X- _ O
) -X- _ O
x -X- _ O
j -X- _ O
) -X- _ O
(4) -X- _ O
where -X- _ O
l -X- _ O
= -X- _ O
L−1, -X- _ O
h -X- _ O
x -X- _ O
i -X- _ O
is -X- _ O
the -X- _ O
refined -X- _ O
node -X- _ O
representation -X- _ O
of -X- _ O
x -X- _ O
i -X- _ O
after -X- _ O
aggregating -X- _ O
information -X- _ O
from -X- _ O
the -X- _ O
other -X- _ O
informative -X- _ O
tweets. -X- _ O

Automatic -X- _ O
Evaluation -X- _ O
The -X- _ O
automatic -X- _ O
evaluation -X- _ O
metrics -X- _ O
are -X- _ O
BLEU3, -X- _ B-MetricName
BLEU4 -X- _ B-MetricName
(Papineni -X- _ O
et -X- _ O
al, -X- _ O
2002), -X- _ O
METEOR -X- _ B-MetricName
(Lavie -X- _ O
and -X- _ O
Agarwal, -X- _ O
2007), -X- _ O
and -X- _ O
CIDEr -X- _ B-MetricName
(Vedantam -X- _ O
et -X- _ O
al, -X- _ O
2015), -X- _ O
which -X- _ O
measure -X- _ O
the -X- _ O
similarity -X- _ O
between -X- _ O
the -X- _ O
generation -X- _ O
results -X- _ O
and -X- _ O
the -X- _ O
reference -X- _ O
questions -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
n-grams. -X- _ O

Yet -X- _ O
generation, -X- _ O
especially, -X- _ O
abstractive -X- _ B-TaskName
summarization -X- _ I-TaskName
systems -X- _ O
have -X- _ O
so -X- _ O
far -X- _ O
focused -X- _ O
heavily -X- _ O
on -X- _ O
paraphrasing -X- _ O
and -X- _ O
simplifying -X- _ O
the -X- _ O
source -X- _ O
content, -X- _ O
to -X- _ O
the -X- _ O
exclusion -X- _ O
of -X- _ O
such -X- _ O
semantic -X- _ O
abstraction -X- _ O
capabilities. -X- _ O

This -X- _ O
paper -X- _ O
proposes -X- _ O
contextual -X- _ B-MethodName
quantization -X- _ I-MethodName
of -X- _ I-MethodName
token -X- _ I-MethodName
embeddings -X- _ I-MethodName
by -X- _ O
decoupling -X- _ O
document-specific -X- _ O
and -X- _ O
document-independent -X- _ O
ranking -X- _ O
contributions -X- _ O
during -X- _ O
codebook-based -X- _ O
compression. -X- _ O

The -X- _ O
Pointer-Gen -X- _ B-MethodName
baseline -X- _ O
model -X- _ O
achieves -X- _ O
a -X- _ O
42.6% -X- _ B-MetricValue
sensationalism -X- _ B-MetricName
score, -X- _ I-MetricName
which -X- _ O
is -X- _ O
the -X- _ O
minimum -X- _ O
that -X- _ O
a -X- _ O
typical -X- _ O
summarization -X- _ O
model -X- _ O
achieves. -X- _ O

Our -X- _ O
format -X- _ O
locally -X- _ O
tags -X- _ O
words -X- _ O
within -X- _ O
the -X- _ O
sentence -X- _ O
(Figure -X- _ O
1) -X- _ O
and -X- _ O
is -X- _ O
easily -X- _ O
extensible -X- _ O
to -X- _ O
sentence-level -X- _ O
classification -X- _ O
tasks, -X- _ O
such -X- _ O
as -X- _ B-TaskName
intent -X- _ I-TaskName
classification -X- _ I-TaskName
(IC). -X- _ B-TaskName

Besides -X- _ O
mining -X- _ O
knowledge -X- _ O
from -X- _ O
the -X- _ O
language -X- _ O
model, -X- _ O
PET -X- _ B-MethodName
work -X- _ O
(Schick -X- _ O
and -X- _ O
Schütze, -X- _ O
2021a,b) -X- _ O
presents -X- _ O
a -X- _ O
semi-supervised -X- _ O
prompting -X- _ O
method -X- _ O
for -X- _ O
improving -X- _ O
few-shot -X- _ O
language -X- _ O
understanding -X- _ O
performance. -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
(2), -X- _ O
the -X- _ O
MaxSAT -X- _ B-MethodName
problem -X- _ O
can -X- _ O
be -X- _ O
relaxed -X- _ O
with -X- _ O
the -X- _ O
converted -X- _ O
sign -X- _ O
matrix -X- _ O
S -X- _ O
and -X- _ O
atom -X- _ O
value -X- _ O
matrix -X- _ O
V. -X- _ O
Here -X- _ O
S -X- _ O
is -X- _ O
computed -X- _ O
from -X- _ O
the -X- _ O
given -X- _ O
clauses -X- _ O
as -X- _ O
our -X- _ O
prior -X- _ O
knowledge -X- _ O
and -X- _ O
kept -X- _ O
fixed -X- _ O
during -X- _ O
training. -X- _ O

More -X- _ O
importantly, -X- _ O
even -X- _ O
when -X- _ O
the -X- _ O
ratio -X- _ B-HyperparameterName
is -X- _ O
only -X- _ O
moderately -X- _ O
low -X- _ O
(at -X- _ O
0.6), -X- _ B-MetricValue
models -X- _ O
trained -X- _ O
on -X- _ O
our -X- _ O
perturbed -X- _ O
datasets -X- _ O
exhibit -X- _ O
desirable -X- _ O
advantages: -X- _ O
They -X- _ O
are -X- _ O
9% -X- _ B-MetricValue
more -X- _ O
robust -X- _ O
to -X- _ O
minor -X- _ O
changes -X- _ O
and -X- _ O
generalize -X- _ O
4.5% -X- _ B-MetricValue
better -X- _ O
across -X- _ O
datasets -X- _ O
than -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
BOOLQ. -X- _ B-DatasetName

Comprehensive -X- _ O
experiments -X- _ O
on -X- _ O
IWSLT -X- _ B-DatasetName
and -X- _ O
WMT -X- _ B-DatasetName
datasets -X- _ O
with -X- _ O
various -X- _ O
Transformer -X- _ O
architectures -X- _ O
show -X- _ O
that -X- _ O
LaSS -X- _ B-MethodName
obtains -X- _ O
gains -X- _ O
on -X- _ O
36 -X- _ O
language -X- _ O
pairs -X- _ O
by -X- _ O
up -X- _ O
to -X- _ O
1.2 -X- _ B-MetricValue
BLEU. -X- _ B-MetricName

We -X- _ O
first -X- _ O
compare -X- _ O
the -X- _ O
proposed -X- _ O
attention -X- _ O
networks -X- _ O
(SentiBERT -X- _ B-MethodName
w/o -X- _ O
BERT) -X- _ B-MethodName
with -X- _ O
the -X- _ O
following -X- _ O
baseline -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
SST-phrase -X- _ B-DatasetName
corpus -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
architecture -X- _ O
design: -X- _ O
1) -X- _ O
Recursive -X- _ B-MethodName
NN -X- _ I-MethodName
(Socher -X- _ O
et -X- _ O
al, -X- _ O
2013); -X- _ O
2) -X- _ O
GCN -X- _ B-MethodName
(Kipf -X- _ O
and -X- _ O
Welling, -X- _ O
2017); -X- _ O
3) -X- _ O
Tree-LSTM -X- _ B-MethodName
(Tai -X- _ O
et -X- _ O
al, -X- _ O
2015); -X- _ O
4) -X- _ O
BiLSTM -X- _ B-MethodName
(Hochreiter -X- _ O
and -X- _ O
Schmidhuber, -X- _ O
1997) -X- _ O
w/ -X- _ O
Tree-LSTM. -X- _ O

We -X- _ O
evaluate -X- _ O
our -X- _ O
dataset -X- _ O
in -X- _ O
various -X- _ O
classification -X- _ O
settings, -X- _ O
then -X- _ O
we -X- _ O
discuss -X- _ O
how -X- _ O
to -X- _ O
leverage -X- _ O
our -X- _ O
annotations -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
improve -X- _ B-TaskName
hate -X- _ I-TaskName
speech -X- _ I-TaskName
detection -X- _ I-TaskName
and -X- _ O
classification -X- _ O
in -X- _ O
general. -X- _ O

As -X- _ O
an -X- _ O
alternative -X- _ O
to -X- _ O
attention-based -X- _ O
meta-embeddings, -X- _ O
we -X- _ O
propose -X- _ O
feature-based -X- _ B-MethodName
adversarial -X- _ I-MethodName
meta-embeddings -X- _ I-MethodName
(FAME) -X- _ B-MethodName
with -X- _ O
an -X- _ O
attention -X- _ O
function -X- _ O
that -X- _ O
is -X- _ O
guided -X- _ O
by -X- _ O
features -X- _ O
reflecting -X- _ O
word-specific -X- _ O
properties, -X- _ O
such -X- _ O
as -X- _ O
shape -X- _ O
and -X- _ O
frequency, -X- _ O
and -X- _ O
show -X- _ O
that -X- _ O
this -X- _ O
is -X- _ O
beneficial -X- _ O
to -X- _ O
handle -X- _ O
subword-based -X- _ O
embeddings. -X- _ O

Even -X- _ O
so, -X- _ O
the -X- _ O
iter-DRBT -X- _ B-MethodName
yields -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
on -X- _ O
all -X- _ O
test -X- _ O
sets, -X- _ O
with -X- _ O
11.03 -X- _ B-MetricValue
and -X- _ O
0.79 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
improvements -X- _ O
on -X- _ O
average -X- _ O
compared -X- _ O
to -X- _ O
Base -X- _ B-MethodName
and -X- _ O
iter-BT, -X- _ B-MethodName
respectively. -X- _ O

QASR -X- _ B-DatasetName
is -X- _ O
the -X- _ O
first -X- _ O
speech -X- _ O
corpora -X- _ O
to -X- _ O
provide -X- _ O
resources -X- _ O
for -X- _ O
benchmarking -X- _ O
NER, -X- _ B-TaskName
punctuation -X- _ B-TaskName
restoration -X- _ I-TaskName
systems. -X- _ O

The -X- _ O
beam -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
10 -X- _ B-HyperparameterValue
was -X- _ O
chosen -X- _ O
for -X- _ O
our -X- _ O
experiments -X- _ O
based -X- _ O
on -X- _ O
preliminary -X- _ O
experiments. -X- _ O

We -X- _ O
summarize -X- _ O
the -X- _ O
model -X- _ O
performances -X- _ O
of -X- _ O
our -X- _ O
method -X- _ O
and -X- _ O
above-mentioned -X- _ O
baseline -X- _ O
models -X- _ O
in -X- _ O
The -X- _ O
overall -X- _ O
PR-curve -X- _ B-MetricName
on -X- _ O
NYT10-D -X- _ B-DatasetName
is -X- _ O
visualized -X- _ O
in -X- _ O
Figure -X- _ O
10. -X- _ O

Following -X- _ O
BERT -X- _ B-MethodName
(Devlin -X- _ O
et -X- _ O
al, -X- _ O
2019), -X- _ O
each -X- _ O
text -X- _ O
T -X- _ O
is -X- _ O
converted -X- _ O
into -X- _ O
n -X- _ O
words, -X- _ O
which -X- _ O
are -X- _ O
further -X- _ O
embedded -X- _ O
into -X- _ O
n -X- _ O
word -X- _ O
embeddings -X- _ O
W -X- _ O
= -X- _ O
{w -X- _ O
1 -X- _ O
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
w -X- _ O
n -X- _ O
}. -X- _ O

Our -X- _ O
empirical -X- _ O
evaluation -X- _ O
shows -X- _ O
that -X- _ O
discoursesemantic -X- _ O
annotations -X- _ O
combined -X- _ O
with -X- _ O
self-attention -X- _ O
yields -X- _ O
significant -X- _ O
(+3.43 -X- _ B-MetricValue
Rouge-L) -X- _ B-MetricName
improvement -X- _ O
over -X- _ O
QANet's -X- _ B-DatasetName
token-based -X- _ O
self-attention -X- _ O
when -X- _ O
applied -X- _ O
to -X- _ O
NarrativeQA -X- _ B-DatasetName
reading -X- _ B-TaskName
comprehension. -X- _ I-TaskName

In -X- _ O
the -X- _ O
1-shot -X- _ O
case, -X- _ O
our -X- _ O
model -X- _ O
achieves -X- _ O
an -X- _ O
average -X- _ O
F1 -X- _ B-MetricName
score -X- _ O
of -X- _ O
81.0%, -X- _ B-MetricValue
outperforming -X- _ O
the -X- _ O
best -X- _ O
baseline -X- _ O
significantly -X- _ O
(10.6% -X- _ B-MetricValue
improvement). -X- _ O

The -X- _ O
high -X- _ O
RAD -X- _ B-MetricName
values -X- _ I-MetricName
for -X- _ O
BT -X- _ B-MethodName
and -X- _ O
Reph -X- _ B-MethodName
might -X- _ O
indicate -X- _ O
that -X- _ O
VQA -X- _ B-MethodName
models -X- _ O
are -X- _ O
indeed -X- _ O
robust -X- _ O
to -X- _ O
linguistic -X- _ O
variation, -X- _ O
as -X- _ O
long -X- _ O
as -X- _ O
the -X- _ O
answer -X- _ O
does -X- _ O
not -X- _ O
change. -X- _ O

The -X- _ O
input -X- _ B-HyperparameterName
sequence -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
is -X- _ O
set -X- _ O
as -X- _ O
32 -X- _ B-HyperparameterValue
for -X- _ O
the -X- _ O
text -X- _ O
and -X- _ O
image -X- _ O
encoders. -X- _ O

Given -X- _ O
the -X- _ O
data-driven -X- _ O
nature -X- _ O
of -X- _ O
question -X- _ B-TaskName
generation -X- _ I-TaskName
and -X- _ I-TaskName
answering -X- _ I-TaskName
tasks, -X- _ O
recent -X- _ O
studies -X- _ O
take -X- _ O
advantage -X- _ O
of -X- _ O
the -X- _ O
availability -X- _ O
of -X- _ O
large-scale -X- _ O
QA -X- _ O
datasets, -X- _ O
such -X- _ O
as -X- _ B-DatasetName
SQuAD -X- _ I-DatasetName
(Rajpurkar -X- _ O
et -X- _ O
al, -X- _ O
2016), -X- _ B-DatasetName
MS -X- _ I-DatasetName
MARCO -X- _ I-DatasetName
(Bajaj -X- _ O
et -X- _ O
al, -X- _ O
2016), -X- _ B-DatasetName
HotpotQA -X- _ I-DatasetName
(Yang -X- _ O
et -X- _ O
al, -X- _ O
2018), -X- _ B-DatasetName
DROP -X- _ I-DatasetName
(Dua -X- _ O
et -X- _ O
al, -X- _ O
2019), -X- _ O
inter -X- _ O
alia. -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
4, -X- _ O
a -X- _ O
threshold -X- _ B-HyperparameterName
in -X- _ O
the -X- _ O
range -X- _ O
0.3-0.7 -X- _ B-HyperparameterValue
only -X- _ O
marginally -X- _ O
alters -X- _ O
the -X- _ O
results, -X- _ O
which -X- _ O
are -X- _ O
still -X- _ O
better -X- _ O
than -X- _ O
predicting -X- _ O
the -X- _ O
highest -X- _ O
scoring -X- _ O
label -X- _ O
only -X- _ O
(τ -X- _ B-HyperparameterName
= -X- _ O
1.0). -X- _ B-HyperparameterValue

For -X- _ O
example, -X- _ O
compared -X- _ O
with -X- _ O
StructShot, -X- _ B-MethodName
ESD -X- _ B-MethodName
achieves -X- _ O
11.17 -X- _ B-MetricValue
and -X- _ O
10.60 -X- _ B-MetricValue
average -X- _ O
F1 -X- _ B-MetricName
improvement -X- _ O
on -X- _ O
INTRA -X- _ B-DatasetName
and -X- _ O
INTER, -X- _ B-DatasetName
respectively. -X- _ O

Second, -X- _ O
the -X- _ O
multi-step -X- _ O
shrinking -X- _ O
(I→B→F) -X- _ O
further -X- _ O
boosts -X- _ O
the -X- _ O
fast -X- _ O
model -X- _ O
to -X- _ O
a -X- _ O
higher -X- _ O
recall@1, -X- _ B-MetricName
62.5. -X- _ B-MetricValue
And -X- _ O
the -X- _ O
intermediate -X- _ O
base -X- _ O
model -X- _ O
(I→B) -X- _ O
also -X- _ O
benefits -X- _ O
from -X- _ O
the -X- _ O
inflated -X- _ O
model, -X- _ O
which -X- _ O
gains -X- _ O
a -X- _ O
64.5 -X- _ B-MetricValue
recall@1. -X- _ B-MetricName

Compared -X- _ O
to -X- _ O
the -X- _ O
extraction-based -X- _ B-MethodName
C-MNMT, -X- _ I-MethodName
the -X- _ O
proposed -X- _ O
method -X- _ O
achieves -X- _ O
an -X- _ O
improvement -X- _ O
up -X- _ O
to -X- _ O
1.1 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
points -X- _ O
on -X- _ O
non-English -X- _ O
language -X- _ O
pairs. -X- _ O

The -X- _ O
result -X- _ O
of -X- _ O
BM25 -X- _ B-MethodName
covers -X- _ O
"knife" -X- _ O
and -X- _ O
"key", -X- _ O
but -X- _ O
the -X- _ O
meaning -X- _ O
of -X- _ O
the -X- _ O
whole -X- _ O
sentence -X- _ O
does -X- _ O
not -X- _ O
match -X- _ O
the -X- _ O
query. -X- _ O

For -X- _ O
fine-tuning -X- _ O
on -X- _ O
SAMSum, -X- _ B-DatasetName
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ O
is -X- _ O
set -X- _ O
to -X- _ O
3e-05, -X- _ B-HyperparameterValue
the -X- _ O
dropout -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
is -X- _ O
0.1, -X- _ B-HyperparameterValue
the -X- _ O
warmup -X- _ B-HyperparameterName
is -X- _ O
set -X- _ O
to -X- _ O
400. -X- _ B-HyperparameterValue

However, -X- _ O
when -X- _ O
setting -X- _ O
e -X- _ O
M -X- _ B-HyperparameterName
as -X- _ O
25 -X- _ B-HyperparameterValue
or -X- _ O
even -X- _ O
50, -X- _ B-HyperparameterValue
the -X- _ O
performances -X- _ O
decline. -X- _ O

Besides, -X- _ O
the -X- _ O
Residual -X- _ B-MethodName
Strategy -X- _ I-MethodName
outperforms -X- _ O
the -X- _ O
Attention -X- _ B-MethodName
strategies -X- _ I-MethodName
by -X- _ O
a -X- _ O
margin, -X- _ O
especially -X- _ O
at -X- _ O
the -X- _ O
low -X- _ O
token -X- _ O
remaining -X- _ O
proportion -X- _ O
(+31.8% -X- _ B-MetricValue
F1 -X- _ B-MetricName
on -X- _ O
SQuAD -X- _ B-DatasetName
2.0 -X- _ I-DatasetName
and -X- _ O
+9.5% -X- _ B-MetricValue
accuracy -X- _ B-MetricName
on -X- _ O
IMDB -X- _ B-DatasetName
when -X- _ O
selecting -X- _ O
10% -X- _ B-HyperparameterValue
tokens). -X- _ O

IRE -X- _ B-MethodName
(Sahu -X- _ O
et -X- _ O
al, -X- _ O
2019) -X- _ O
is -X- _ O
another -X- _ O
baseline -X- _ O
that -X- _ O
was -X- _ O
first -X- _ O
proposed -X- _ O
in -X- _ B-TaskName
relation -X- _ I-TaskName
extraction -X- _ I-TaskName
and -X- _ O
has -X- _ O
something -X- _ O
in -X- _ O
common -X- _ O
with -X- _ O
our -X- _ O
method. -X- _ O

5 -X- _ O
During -X- _ O
the -X- _ O
training -X- _ O
process, -X- _ O
we -X- _ O
fix -X- _ O
all -X- _ O
pre-trained -X- _ O
embeddings -X- _ O
in -X- _ O
the -X- _ O
embedding -X- _ O
layer -X- _ O
and -X- _ O
use -X- _ O
Adam -X- _ B-MethodName
(Kingma -X- _ O
and -X- _ O
Ba, -X- _ O
2015) -X- _ O
to -X- _ O
optimize -X- _ O
negative -X- _ O
loglikelihood -X- _ O
loss -X- _ O
function -X- _ O
with -X- _ O
the -X- _ O
learning -X- _ O
rate -X- _ O
set -X- _ O
to -X- _ O
η -X- _ B-HyperparameterName
= -X- _ O
0.0001, -X- _ B-HyperparameterValue
β -X- _ B-HyperparameterName
1 -X- _ I-HyperparameterName
= -X- _ O
0.9 -X- _ B-HyperparameterValue
and -X- _ O
β -X- _ B-HyperparameterName
2 -X- _ I-HyperparameterName
= -X- _ O
0.99. -X- _ B-HyperparameterValue

The -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
NumNet -X- _ B-MethodName
model -X- _ O
and -X- _ O
other -X- _ O
baselines -X- _ O
on -X- _ B-DatasetName
DROP -X- _ I-DatasetName
dataset -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
2. -X- _ O

The -X- _ O
keyword -X- _ O
set -X- _ O
used -X- _ O
for -X- _ O
the -X- _ O
Election -X- _ B-DatasetName
dataset -X- _ O
contains -X- _ O
438 -X- _ O
keywords, -X- _ O
while -X- _ O
the -X- _ O
COVID-19 -X- _ B-DatasetName
dataset -X- _ O
contains -X- _ O
80 -X- _ O
keywords -X- _ O
used -X- _ O
for -X- _ O
Twitter -X- _ O
API -X- _ O
tracking -X- _ O
(Chen -X- _ O
et -X- _ O
al, -X- _ O
2020). -X- _ O

Cross-lingual -X- _ B-TaskName
transfer -X- _ I-TaskName
learning -X- _ I-TaskName
(Yarowsky -X- _ O
and -X- _ O
Ngai, -X- _ O
2001;Wang -X- _ O
and -X- _ O
Manning, -X- _ O
2014;Guo -X- _ O
et -X- _ O
al, -X- _ O
2018;Lin -X- _ O
et -X- _ O
al, -X- _ O
2019;Hu -X- _ O
et -X- _ O
al, -X- _ O
2021) -X- _ O
recently -X- _ O
attracted -X- _ O
attention -X- _ O
for -X- _ O
tackling -X- _ O
that -X- _ O
problem, -X- _ O
by -X- _ O
transferring -X- _ O
the -X- _ O
knowledge -X- _ O
from -X- _ O
high-resource -X- _ O
languages -X- _ O
to -X- _ O
low-resource -X- _ O
ones. -X- _ O

We -X- _ O
analyzed -X- _ O
MAML's -X- _ B-MethodName
performance -X- _ O
improvements -X- _ O
over -X- _ O
NE -X- _ B-DatasetName
on -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
132 -X- _ O
dependency -X- _ O
relations, -X- _ O
and -X- _ O
found -X- _ O
that -X- _ O
they -X- _ O
are -X- _ O
consistent -X- _ O
across -X- _ O
relations. -X- _ O

Two -X- _ O
recent -X- _ O
datasets -X- _ O
were -X- _ O
proposed -X- _ O
to -X- _ O
address -X- _ O
this -X- _ O
issue: -X- _ O
Rashkin -X- _ O
et -X- _ O
al -X- _ O
(2019) -X- _ O
introduced -X- _ O
Empathetic -X- _ B-DatasetName
Dialogues, -X- _ I-DatasetName
which -X- _ O
contains -X- _ O
text -X- _ O
conversations -X- _ O
labelled -X- _ O
with -X- _ O
32 -X- _ O
emotion -X- _ O
labels, -X- _ O
and -X- _ O
Demszky -X- _ O
et -X- _ O
al -X- _ O
(2020) -X- _ O
introduced -X- _ O
GoEmotions, -X- _ B-DatasetName
which -X- _ O
contains -X- _ O
Reddit -X- _ O
comments -X- _ O
labelled -X- _ O
with -X- _ O
27 -X- _ O
emotion -X- _ O
labels. -X- _ O

Experimental -X- _ O
results -X- _ O
on -X- _ O
three -X- _ O
widelyused -X- _ O
benchmark -X- _ O
datasets -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
proposed -X- _ O
model -X- _ O
achieves -X- _ O
more -X- _ O
than -X- _ O
4× -X- _ B-MetricValue
speedup -X- _ O
while -X- _ O
maintaining -X- _ O
comparable -X- _ O
performance -X- _ O
compared -X- _ O
with -X- _ O
the -X- _ O
corresponding -X- _ O
autoregressive -X- _ B-MethodName
model. -X- _ I-MethodName
* -X- _ O
indicates -X- _ O
equal -X- _ O
contribution -X- _ O
† -X- _ O
indicates -X- _ O
corresponding -X- _ O
author -X- _ O
Src. -X- _ O

Our -X- _ O
main -X- _ O
focus -X- _ O
is -X- _ O
on -X- _ O
conversational -X- _ B-TaskName
semantic -X- _ I-TaskName
parsing, -X- _ I-TaskName
but -X- _ O
we -X- _ O
also -X- _ O
ran -X- _ O
experiments -X- _ O
on -X- _ O
nonconversational -X- _ O
semantic -X- _ O
parsing -X- _ O
benchmarks -X- _ O
to -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
is -X- _ O
a -X- _ O
strong -X- _ O
parser -X- _ O
irrespective -X- _ O
of -X- _ O
context. -X- _ O
Specifically, -X- _ O
we -X- _ O
manually -X- _ O
annotated -X- _ O
the -X- _ O
JOBS, -X- _ B-DatasetName
GEOQUERY, -X- _ B-DatasetName
and -X- _ B-DatasetName
ATIS -X- _ I-DatasetName
datasets -X- _ O
with -X- _ O
typed -X- _ O
declarations -X- _ O
(Appendix -X- _ O
C) -X- _ O
and -X- _ O
ran -X- _ O
experiments -X- _ O
comparing -X- _ O
with -X- _ O
multiple -X- _ O
baseline -X- _ O
and -X- _ O
state-of-the-art -X- _ O
methods. -X- _ O

EditSQL -X- _ B-MethodName
(Zhang -X- _ O
et -X- _ O
al, -X- _ O
2019b) -X- _ O
considers -X- _ O
"co-attention" -X- _ O
between -X- _ O
question -X- _ O
words -X- _ O
and -X- _ O
database -X- _ O
schema -X- _ O
nodes -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
common -X- _ O
practice -X- _ O
in -X- _ B-TaskName
text -X- _ I-TaskName
matching -X- _ I-TaskName
(Chen -X- _ O
et -X- _ O
al, -X- _ O
2017). -X- _ O

Evaluation -X- _ O
Metric -X- _ O
On -X- _ O
RCV1-V2 -X- _ B-DatasetName
and -X- _ B-DatasetName
WOS -X- _ I-DatasetName
datasets, -X- _ O
we -X- _ O
measure -X- _ O
the -X- _ O
experimental -X- _ O
results -X- _ O
by -X- _ O
Micro-F1 -X- _ B-MetricName
and -X- _ O
Macro-F1. -X- _ B-MetricName

The -X- _ O
task -X- _ O
of -X- _ O
news -X- _ B-TaskName
article -X- _ I-TaskName
image -X- _ I-TaskName
captioning -X- _ I-TaskName
aims -X- _ O
to -X- _ O
generate -X- _ O
descriptive -X- _ O
and -X- _ O
informative -X- _ O
captions -X- _ O
for -X- _ O
news -X- _ O
article -X- _ O
images. -X- _ O

In -X- _ O
particular, -X- _ O
we -X- _ O
measure -X- _ O
curriculum -X- _ O
difficulty -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
the -X- _ O
rarity -X- _ O
of -X- _ O
the -X- _ O
quest -X- _ O
in -X- _ O
the -X- _ O
original -X- _ O
training -X- _ O
distribution-an -X- _ O
easier -X- _ O
environment -X- _ O
is -X- _ O
one -X- _ O
that -X- _ O
is -X- _ O
more -X- _ O
likely -X- _ O
to -X- _ O
have -X- _ O
been -X- _ O
found -X- _ O
in -X- _ O
the -X- _ O
unaugmented -X- _ O
dataset. -X- _ O

We -X- _ O
reimplement -X- _ O
and -X- _ O
compare -X- _ O
the -X- _ O
following -X- _ O
previous -X- _ O
works -X- _ O
to -X- _ O
Hyper-SOS -X- _ B-DatasetName
on -X- _ O
temporal -X- _ O
split -X- _ O
( -X- _ O
§4.2): -X- _ O
(Grover -X- _ O
and -X- _ O
Leskovec, -X- _ O
2016) -X- _ O
embeddings -X- _ O
concatenated -X- _ O
with -X- _ O
GloVe -X- _ O
embeddings -X- _ O
for -X- _ O
the -X- _ O
tweet -X- _ O
to -X- _ O
be -X- _ O
assessed. -X- _ O

We -X- _ O
apply -X- _ O
label -X- _ B-MethodName
smoothing -X- _ I-MethodName
with -X- _ O
a -X- _ O
probability -X- _ B-HyperparameterName
of -X- _ O
0.1. -X- _ B-HyperparameterValue

In -X- _ O
this -X- _ O
work, -X- _ O
we -X- _ O
present -X- _ O
HIBRIDS, -X- _ B-MethodName
which -X- _ O
injects -X- _ O
Hierarchical -X- _ O
Biases -X- _ O
foR -X- _ O
Incorporating -X- _ O
Document -X- _ O
Structure -X- _ O
into -X- _ O
the -X- _ O
calculation -X- _ O
of -X- _ O
attention -X- _ O
scores. -X- _ O

With -X- _ O
cross-view -X- _ O
training, -X- _ O
our -X- _ O
model -X- _ O
achieves -X- _ O
91.2% -X- _ B-HyperparameterValue
F -X- _ B-HyperparameterName
1 -X- _ I-HyperparameterName
(the -X- _ O
difference -X- _ O
over -X- _ O
the -X- _ O
supervised -X- _ O
model -X- _ O
is -X- _ O
statistically -X- _ O
significant -X- _ O
at -X- _ O
p -X- _ O
< -X- _ O
0.05), -X- _ O
which -X- _ O
is -X- _ O
an -X- _ O
absolute -X- _ O
improvement -X- _ O
of -X- _ O
1.4% -X- _ B-HyperparameterValue
over -X- _ O
the -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art -X- _ O
. -X- _ O

The -X- _ O
label -X- _ O
dimensionality -X- _ B-HyperparameterName
of -X- _ O
all -X- _ O
generative -X- _ O
classifiers -X- _ O
is -X- _ O
set -X- _ O
to -X- _ O
100. -X- _ B-HyperparameterValue

Our -X- _ O
model, -X- _ O
named -X- _ O
REFUEL, -X- _ B-MethodName
achieves -X- _ O
a -X- _ O
new -X- _ O
state-of-the-art -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
AMBIGQA -X- _ B-DatasetName
dataset, -X- _ O
and -X- _ O
shows -X- _ O
competitive -X- _ O
performance -X- _ O
on -X- _ O
NQ-OPEN -X- _ B-DatasetName
and -X- _ O
Trivi-aQA. -X- _ B-DatasetName

We -X- _ O
use -X- _ O
a -X- _ O
combination -X- _ O
of -X- _ O
top-k -X- _ O
and -X- _ O
top-p -X- _ O
sampling -X- _ O
with -X- _ O
k -X- _ B-HyperparameterName
= -X- _ O
120 -X- _ B-HyperparameterValue
and -X- _ O
p -X- _ B-HyperparameterName
= -X- _ O
0.95 -X- _ B-HyperparameterValue
in -X- _ O
the -X- _ O
interest -X- _ O
of -X- _ O
lexical -X- _ O
and -X- _ O
syntactic -X- _ O
diversity -X- _ O
in -X- _ O
the -X- _ O
paraphrases. -X- _ O

PCFG -X- _ B-MethodName
also -X- _ O
significantly -X- _ O
benefits -X- _ O
from -X- _ O
weight -X- _ O
sharing, -X- _ O
with -X- _ O
the -X- _ O
large-6s -X- _ O
model -X- _ O
achieving -X- _ O
0.634 -X- _ B-MetricValue
and -X- _ O
0.828 -X- _ B-MetricValue
in -X- _ O
the -X- _ O
productivity -X- _ O
and -X- _ O
systematicity -X- _ O
versions, -X- _ O
respectively. -X- _ O

10 -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
implementation -X- _ O
in -X- _ O
Sempre, -X- _ B-MethodName
https://github.com/percyliang/sempre -X- _ O

• -X- _ O
SF-ID -X- _ O
Network. -X- _ O
(E -X- _ O
et -X- _ O
al, -X- _ O
2019) -X- _ O
introduced -X- _ O
an -X- _ O
SF-ID -X- _ B-MethodName
network -X- _ O
to -X- _ O
establish -X- _ O
direct -X- _ O
connections -X- _ O
for -X- _ O
the -X- _ B-TaskName
slot -X- _ I-TaskName
filling -X- _ I-TaskName
and -X- _ B-TaskName
intent -X- _ I-TaskName
detection -X- _ I-TaskName
to -X- _ O
help -X- _ O
them -X- _ O
promote -X- _ O
each -X- _ O
other -X- _ O
mutually. -X- _ O

Each -X- _ O
epoch -X- _ O
contains -X- _ O
10k -X- _ B-MetricValue
steps -X- _ B-MetricName
and -X- _ O
we -X- _ O
train -X- _ O
for -X- _ O
50 -X- _ B-MetricValue
epochs. -X- _ B-MetricName

Extensive -X- _ O
evaluations -X- _ O
over -X- _ O
both -X- _ O
an -X- _ O
open-released -X- _ O
English -X- _ O
dataset -X- _ O
and -X- _ O
our -X- _ O
Chinese -X- _ O
dataset -X- _ O
demonstrate -X- _ O
that -X- _ O
our -X- _ O
approach -X- _ O
ConKADI -X- _ B-MethodName
outperforms -X- _ O
the -X- _ O
state-of-the-art -X- _ O
approach -X- _ O
CCM, -X- _ B-MethodName
in -X- _ O
most -X- _ O
experiments. -X- _ O

The -X- _ O
maximum -X- _ B-HyperparameterName
length -X- _ I-HyperparameterName
of -X- _ O
input/output -X- _ O
sequence -X- _ O
is -X- _ O
set -X- _ O
to -X- _ O
512/64. -X- _ B-HyperparameterValue

We -X- _ O
use -X- _ O
the -X- _ O
CommonCrawl -X- _ B-DatasetName
dataset -X- _ O
from -X- _ O
the -X- _ O
CoNLL -X- _ O
2017 -X- _ O
shared -X- _ O
task -X- _ O
(Ginter -X- _ O
et -X- _ O
al, -X- _ O
2017): -X- _ O
http:// -X- _ O
hdl.handle.net/11234/1-1989. -X- _ O

Specifically, -X- _ O
as -X- _ O
part -X- _ O
of -X- _ O
this -X- _ O
work -X- _ O
we -X- _ O
collect -X- _ O
Spo-kenCOCO, -X- _ B-DatasetName
a -X- _ O
spoken -X- _ O
version -X- _ O
of -X- _ O
the -X- _ O
MSCOCO -X- _ O
captioning -X- _ O
dataset -X- _ O
(Lin -X- _ O
et -X- _ O
al, -X- _ O
2014) -X- _ O
with -X- _ O
742 -X- _ O
hours -X- _ O
from -X- _ O
2532 -X- _ O
speakers, -X- _ O
via -X- _ O
Amazon -X- _ O
Mechanical -X- _ O
Turk -X- _ O
by -X- _ O
displaying -X- _ O
the -X- _ O
text -X- _ O
to -X- _ O
a -X- _ O
person -X- _ O
and -X- _ O
having -X- _ O
them -X- _ O
read -X- _ O
it -X- _ O
aloud. -X- _ O

This -X- _ O
suggests -X- _ O
that -X- _ O
despite -X- _ O
being -X- _ O
nearly -X- _ O
perfect -X- _ O
replacements -X- _ O
of -X- _ O
the -X- _ O
original -X- _ O
masked -X- _ O
indicators, -X- _ O
these -X- _ O
40% -X- _ O
samples -X- _ O
are -X- _ O
penalized -X- _ O
as -X- _ O
wrong -X- _ O
predictions -X- _ O
when -X- _ O
training -X- _ O
the -X- _ O
generator. -X- _ O

Specifically, -X- _ O
we -X- _ O
tested -X- _ O
models -X- _ O
with -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
layers -X- _ I-HyperparameterName
l -X- _ B-HyperparameterName
equal -X- _ O
to -X- _ O
2, -X- _ B-HyperparameterValue
4 -X- _ B-HyperparameterValue
and -X- _ O
6, -X- _ B-HyperparameterValue
and -X- _ O
layers -X- _ O
of -X- _ O
two -X- _ O
sizes: -X- _ O
small -X- _ O
(d -X- _ B-HyperparameterName
= -X- _ O
64, -X- _ B-HyperparameterValue
f -X- _ B-HyperparameterName
= -X- _ O
256, -X- _ B-HyperparameterValue
h -X- _ B-HyperparameterName
= -X- _ O
4), -X- _ B-HyperparameterValue
and -X- _ O
large -X- _ O
(d -X- _ B-HyperparameterName
= -X- _ O
128, -X- _ B-HyperparameterValue
f -X- _ B-HyperparameterName
= -X- _ O
512, -X- _ B-HyperparameterValue
h -X- _ B-HyperparameterName
= -X- _ O
8). -X- _ B-HyperparameterValue

We -X- _ O
evaluate -X- _ O
our -X- _ O
proposed -X- _ O
method -X- _ O
on -X- _ O
one -X- _ O
simulation -X- _ O
experiment -X- _ O
and -X- _ O
two -X- _ O
NLP -X- _ O
applications: -X- _ B-TaskName
text -X- _ I-TaskName
classification -X- _ I-TaskName
and -X- _ O
dialog -X- _ B-TaskName
state -X- _ I-TaskName
tracking. -X- _ I-TaskName

Xun -X- _ O
Zhou -X- _ O
has -X- _ O
dedicated -X- _ O
her -X- _ O
passion -X- _ O
and -X- _ O
sincerity -X- _ O
in -X- _ O
this -X- _ O
film, -X- _ O
bringing -X- _ O
the -X- _ O
audience -X- _ O
into -X- _ O
the -X- _ O
"life -X- _ O
and -X- _ O
death -X- _ O
love", -X- _ O
and -X- _ O
giving -X- _ O
birth -X- _ O
to -X- _ O
a -X- _ O
lot -X- _ O
of -X- _ O
emotions -X- _ O
about -X- _ O
the -X- _ O
city, -X- _ O
about -X- _ O
love, -X- _ O
and -X- _ O
about -X- _ O
gains -X- _ O
and -X- _ O
losses.) -X- _ O
(b) -X- _ O
Case -X- _ O
generated -X- _ O
by -X- _ O
mBART -X- _ B-MethodName
for -X- _ O
task -X- _ O
4-5. -X- _ O

But -X- _ O
this -X- _ O
does -X- _ O
not -X- _ O
mean -X- _ O
that -X- _ O
NeuralLP -X- _ B-MethodName
is -X- _ O
a -X- _ O
highly -X- _ O
interpretable -X- _ O
model -X- _ O
because -X- _ O
its -X- _ O
PR -X- _ B-MetricName
score -X- _ I-MetricName
is -X- _ O
only -X- _ O
10.2. -X- _ B-MetricValue

For -X- _ O
example, -X- _ O
on -X- _ B-TaskName
part-of-speech -X- _ I-TaskName
tagging, -X- _ I-TaskName
97.3 -X- _ B-MetricValue
accuracy -X- _ B-MetricName
is -X- _ O
achieved, -X- _ O
compared -X- _ O
to -X- _ O
92.8 -X- _ B-MetricValue
control -X- _ O
task -X- _ O
accuracy, -X- _ O
resulting -X- _ O
in -X- _ O
4.5 -X- _ B-MetricValue
selectivity. -X- _ O

Moreover, -X- _ O
a -X- _ O
nice -X- _ O
property -X- _ O
of -X- _ O
our -X- _ O
approach -X- _ O
is -X- _ O
that -X- _ O
for -X- _ O
AMR -X- _ B-TaskName
parsing, -X- _ I-TaskName
unlike -X- _ O
related -X- _ O
studies -X- _ O
(Damonte -X- _ O
and -X- _ O
Cohen, -X- _ O
2018;Blloshmi -X- _ O
et -X- _ O
al, -X- _ O
2020), -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
need -X- _ O
to -X- _ O
perform -X- _ O
lemmatization, -X- _ O
POS -X- _ O
tagging, -X- _ O
NER, -X- _ O
or -X- _ O
re-categorization -X- _ O
of -X- _ O
entities, -X- _ O
thus -X- _ O
require -X- _ O
no -X- _ O
language -X- _ O
specific -X- _ O
toolkits -X- _ O
in -X- _ O
pre-processing. -X- _ O

All -X- _ O
characters -X- _ O
and -X- _ O
bytes -X- _ O
have -X- _ O
randomly -X- _ O
initialized -X- _ O
embeddings -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
256. -X- _ B-HyperparameterValue

A -X- _ O
recently -X- _ O
proposed -X- _ O
benchmark -X- _ O
(Tay -X- _ O
et -X- _ O
al, -X- _ O
2021), -X- _ O
named -X- _ B-DatasetName
long-range -X- _ I-DatasetName
arena -X- _ I-DatasetName
(LRA), -X- _ B-DatasetName
aims -X- _ O
to -X- _ O
address -X- _ O
the -X- _ O
lack -X- _ O
of -X- _ O
unified -X- _ O
evaluation -X- _ O
with -X- _ O
a -X- _ O
bundle -X- _ O
of -X- _ O
long-sequence -X- _ O
tasks. -X- _ O

We -X- _ O
provide -X- _ O
additional -X- _ O
maps -X- _ O
for -X- _ O
all -X- _ O
other -X- _ O
datasets -X- _ O
in -X- _ O
Appendix -X- _ O
G. -X- _ O
Comparing -X- _ O
datasets -X- _ O
The -X- _ O
comparison -X- _ O
of -X- _ B-DatasetName
MasakhaNER -X- _ I-DatasetName
to -X- _ O
the -X- _ O
WikiANN -X- _ B-DatasetName
dataset -X- _ O
(see -X- _ O
Appendix -X- _ O
G) -X- _ O
reveals -X- _ O
that -X- _ O
the -X- _ O
former -X- _ O
is -X- _ O
rather -X- _ O
more -X- _ O
localized -X- _ O
(e.g. -X- _ O
more -X- _ O
than -X- _ O
80% -X- _ O
of -X- _ O
the -X- _ O
identified -X- _ O
entities -X- _ O
in -X- _ O
the -X- _ O
Dholuo -X- _ B-DatasetName
dataset -X- _ O
are -X- _ O
related -X- _ O
to -X- _ O
Kenya) -X- _ O
while -X- _ O
the -X- _ O
latter -X- _ O
includes -X- _ O
a -X- _ O
smaller -X- _ O
portion -X- _ O
from -X- _ O
the -X- _ O
countries -X- _ O
where -X- _ O
most -X- _ O
native -X- _ O
speakers -X- _ O
reside -X- _ O
(between -X- _ O
10%-20%) -X- _ O
and -X- _ O
almost -X- _ O
always -X- _ O
also -X- _ O
includes -X- _ O
several -X- _ O
entries -X- _ O
that -X- _ O
are -X- _ O
very -X- _ O
European-or -X- _ O
western-centric. -X- _ O

The -X- _ O
United -X- _ B-DatasetName
States -X- _ I-DatasetName
Social -X- _ I-DatasetName
Security -X- _ I-DatasetName
Administration -X- _ I-DatasetName
(SSA) -X- _ B-DatasetName
dataset -X- _ O
contains -X- _ O
a -X- _ O
list -X- _ O
of -X- _ O
all -X- _ O
first -X- _ O
names -X- _ O
from -X- _ O
Social -X- _ O
Security -X- _ O
card -X- _ O
applications -X- _ O
for -X- _ O
births -X- _ O
in -X- _ O
the -X- _ O
United -X- _ O
States -X- _ O
after -X- _ O
1879, -X- _ O
along -X- _ O
with -X- _ O
their -X- _ O
gender. -X- _ O

When -X- _ O
l -X- _ B-HyperparameterName
= -X- _ O
32, -X- _ B-HyperparameterValue
it -X- _ O
is -X- _ O
equivalent -X- _ O
to -X- _ O
our -X- _ O
base -X- _ O
model. -X- _ O

If -X- _ O
we -X- _ O
bucket -X- _ O
the -X- _ O
sentences -X- _ O
into -X- _ O
low -X- _ O
(with -X- _ O
p -X- _ B-HyperparameterName
t -X- _ I-HyperparameterName
< -X- _ O
0.4) -X- _ B-HyperparameterValue
and -X- _ O
high -X- _ O
groups -X- _ O
(with -X- _ O
p -X- _ B-HyperparameterName
t -X- _ I-HyperparameterName
> -X- _ O
0.7), -X- _ B-HyperparameterValue
the -X- _ O
annotators' -X- _ O
preference -X- _ O
for -X- _ O
bucketing -X- _ O
the -X- _ O
output -X- _ O
into -X- _ O
the -X- _ O
right -X- _ O
confidence -X- _ B-MetricName
goes -X- _ O
up -X- _ O
to -X- _ O
73% -X- _ B-MetricValue
on -X- _ O
average -X- _ O
(68% -X- _ B-MetricValue
for -X- _ O
low, -X- _ O
and -X- _ O
81% -X- _ B-MetricValue
for -X- _ O
high), -X- _ O
hence, -X- _ O
confirming -X- _ O
our -X- _ O
hypothesis -X- _ O
towards -X- _ O
using -X- _ O
CF -X- _ B-MethodName
for -X- _ O
controlled -X- _ B-TaskName
generation. -X- _ I-TaskName

The -X- _ B-DatasetName
Fact -X- _ I-DatasetName
Extraction -X- _ I-DatasetName
and -X- _ I-DatasetName
VERification -X- _ I-DatasetName
(FEVER) -X- _ B-DatasetName
dataset -X- _ O
provides -X- _ O
such -X- _ O
a -X- _ O
resource -X- _ O
for -X- _ O
evaluating -X- _ O
endto-end -X- _ O
fact-checking, -X- _ B-TaskName
requiring -X- _ O
retrieval -X- _ O
of -X- _ O
evidence -X- _ O
from -X- _ O
Wikipedia -X- _ O
to -X- _ O
validate -X- _ O
a -X- _ O
veracity -X- _ O
prediction. -X- _ O

We -X- _ O
tokenize -X- _ O
all -X- _ O
datasets -X- _ O
with -X- _ O
byte-pair -X- _ B-MethodName
encoding -X- _ I-MethodName
(BPE, -X- _ B-MethodName
Sennrich -X- _ O
et -X- _ O
al -X- _ O
(2015)) -X- _ O
with -X- _ O
a -X- _ O
vocabulary -X- _ O
size -X- _ O
of -X- _ O
10k -X- _ O
for -X- _ O
datasets -X- _ O
in -X- _ O
IWSLT -X- _ B-DatasetName
and -X- _ O
32k -X- _ O
for -X- _ O
datasets -X- _ O
in -X- _ O
WMT. -X- _ B-DatasetName

We -X- _ O
trained -X- _ O
our -X- _ O
models -X- _ O
for -X- _ O
at -X- _ O
most -X- _ O
100 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
and -X- _ O
used -X- _ O
early -X- _ O
stopping -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
set -X- _ O
performance, -X- _ O
measured -X- _ O
as -X- _ O
an -X- _ O
average -X- _ B-MetricName
F1 -X- _ I-MetricName
score -X- _ O
of -X- _ O
clean -X- _ O
and -X- _ O
noisy -X- _ O
samples. -X- _ O

We -X- _ O
use -X- _ O
text -X- _ B-TaskName
classification -X- _ I-TaskName
on -X- _ O
the -X- _ O
above -X- _ O
two -X- _ O
datasets, -X- _ O
sst_2 -X- _ B-DatasetName
and -X- _ O
20news, -X- _ B-DatasetName
as -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
interest. -X- _ O

After -X- _ O
training -X- _ O
for -X- _ O
25000 -X- _ B-HyperparameterValue
steps -X- _ O
with -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
8, -X- _ B-HyperparameterValue
the -X- _ O
model -X- _ O
is -X- _ O
evaluated -X- _ O
with -X- _ O
ROUGE-1 -X- _ B-MetricName
of -X- _ O
20.51, -X- _ B-MetricValue
ROUGE-2 -X- _ B-MetricName
of -X- _ O
5.30, -X- _ B-MetricValue
and -X- _ O
ROUGE-L -X- _ B-MetricName
of -X- _ O
16.73 -X- _ B-MetricValue
on -X- _ O
the -X- _ O
test -X- _ O
set. -X- _ O

Strong -X- _ O
performance -X- _ O
gains -X- _ O
are -X- _ O
observed -X- _ O
on -X- _ O
the -X- _ O
next -X- _ O
utterance -X- _ O
retrieval -X- _ O
task -X- _ O
using -X- _ O
both -X- _ O
the -X- _ B-DatasetName
MultiWOZ -X- _ I-DatasetName
dataset -X- _ O
and -X- _ O
the -X- _ O
Ubuntu -X- _ B-DatasetName
dialog -X- _ O
corpus. -X- _ O

However, -X- _ O
some -X- _ O
of -X- _ O
them -X- _ O
can -X- _ O
be -X- _ O
irrelevant -X- _ O
and -X- _ O
unhelpful -X- _ O
for -X- _ O
the -X- _ O
next-turn -X- _ B-TaskName
dialogue -X- _ I-TaskName
response -X- _ I-TaskName
generation. -X- _ I-TaskName

The -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
is -X- _ O
set -X- _ O
as -X- _ O
128 -X- _ B-MetricValue
and -X- _ O
a -X- _ O
one-layer, -X- _ O
bidirectional -X- _ B-MethodName
Long -X- _ I-MethodName
Short-Term -X- _ I-MethodName
Memory -X- _ I-MethodName
(bi-LSTM) -X- _ B-MethodName
model -X- _ O
with -X- _ O
512 -X- _ B-HyperparameterValue
hidden -X- _ B-HyperparameterName
sizes -X- _ I-HyperparameterName
and -X- _ O
a -X- _ O
350 -X- _ B-HyperparameterValue
embedding -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
is -X- _ O
utilized. -X- _ O

For -X- _ O
the -X- _ O
distillation -X- _ O
(CFC-QC, -X- _ B-MethodName
CFC-QS, -X- _ B-MethodName
CFC-DQS), -X- _ B-MethodName
we -X- _ O
train -X- _ O
additional -X- _ O
10 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
on -X- _ O
reddit -X- _ O
and -X- _ O
5 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
on -X- _ O
twitter -X- _ O
respectively, -X- _ O
starting -X- _ O
from -X- _ O
the -X- _ O
early -X- _ O
checkpoints -X- _ O
(20 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
in -X- _ O
Reddit -X- _ O
and -X- _ O
5 -X- _ O
epochs -X- _ B-HyperparameterName
in -X- _ O
Twitter -X- _ O
for -X- _ O
fair -X- _ O
comparison) -X- _ O
of -X- _ O
BE-QC, -X- _ B-MethodName
BE-QS, -X- _ B-MethodName
TE-DQS. -X- _ B-MethodName

To -X- _ O
be -X- _ O
specific, -X- _ O
SCAN -X- _ B-MethodName
(Lee -X- _ O
et -X- _ O
al, -X- _ O
2018) -X- _ O
and -X- _ O
VisualSparta -X- _ B-MethodName
only -X- _ O
conduct -X- _ O
word-region -X- _ O
interactions -X- _ O
in -X- _ O
the -X- _ O
late -X- _ O
stage -X- _ O
when -X- _ O
the -X- _ O
word/region -X- _ O
features -X- _ O
have -X- _ O
already -X- _ O
been -X- _ O
extracted -X- _ O
by -X- _ O
the -X- _ O
image -X- _ O
encoder -X- _ O
and -X- _ O
the -X- _ O
text -X- _ O
encoder. -X- _ O

For -X- _ O
instance, -X- _ O
in -X- _ O
the -X- _ O
aforementioned -X- _ O
WMT'19 -X- _ B-DatasetName
shared -X- _ O
task, -X- _ O
many -X- _ O
translations -X- _ B-TaskName
from -X- _ O
the -X- _ O
competing -X- _ O
systems -X- _ O
did -X- _ O
not -X- _ O
receive -X- _ O
any -X- _ O
human -X- _ B-MethodName
assessment. -X- _ I-MethodName

To -X- _ O
cover -X- _ O
sentiment -X- _ B-TaskName
detection -X- _ I-TaskName
tasks -X- _ O
we -X- _ O
use -X- _ O
SST2 -X- _ B-DatasetName
(Socher -X- _ O
et -X- _ O
al, -X- _ O
2013), -X- _ O
MNLI -X- _ B-DatasetName
(Williams -X- _ O
et -X- _ O
al, -X- _ O
2018) -X- _ O
for -X- _ B-TaskName
Natural -X- _ I-TaskName
Language -X- _ I-TaskName
Inference -X- _ I-TaskName
and -X- _ O
Hatexplain -X- _ O
(Mathew -X- _ O
et -X- _ O
al, -X- _ O
2021) -X- _ O
in -X- _ B-TaskName
hate -X- _ I-TaskName
speech -X- _ I-TaskName
detection. -X- _ I-TaskName

On -X- _ O
the -X- _ O
other -X- _ O
hand, -X- _ O
learning -X- _ O
from -X- _ O
structured -X- _ O
languages -X- _ O
seems -X- _ O
to -X- _ O
be -X- _ O
important -X- _ O
in -X- _ B-TaskName
dependency -X- _ I-TaskName
parsing. -X- _ I-TaskName

Context -X- _ B-TaskName
Dependent -X- _ I-TaskName
Question -X- _ I-TaskName
Answering -X- _ I-TaskName
Baselines -X- _ O
We -X- _ O
finetune -X- _ O
our -X- _ O
closed -X- _ O
book -X- _ O
baselines -X- _ O
for -X- _ O
10 -X- _ B-MetricValue
epochs -X- _ B-HyperparameterName
with -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
256, -X- _ B-HyperparameterValue
using -X- _ O
the -X- _ O
AdamW -X- _ B-MethodName
optimizer -X- _ O
with -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
1e-5. -X- _ B-HyperparameterValue

GloVe -X- _ B-MethodName
(Pennington -X- _ O
et -X- _ O
al, -X- _ O
2014) -X- _ O
word -X- _ O
embeddings -X- _ O
(glove.840B.300d -X- _ O
7 -X- _ O
). -X- _ O

We -X- _ O
build -X- _ O
a -X- _ O
Chinese -X- _ O
dataset -X- _ O
for -X- _ O
controversy -X- _ O
detection, -X- _ O
consisting -X- _ O
of -X- _ O
5,676 -X- _ O
posts -X- _ O
collected -X- _ O
from -X- _ O
Chinese -X- _ O
Weibo, -X- _ O
each -X- _ O
of -X- _ O
which -X- _ O
are -X- _ O
manually -X- _ O
labeled -X- _ O
as -X- _ O
controversial -X- _ O
or -X- _ O
noncontroversial. -X- _ O

As -X- _ O
a -X- _ B-TaskName
question -X- _ I-TaskName
answering -X- _ I-TaskName
dataset, -X- _ O
we -X- _ O
adopt -X- _ O
the -X- _ O
standard -X- _ O
output -X- _ O
format -X- _ O
of -X- _ O
extractive -X- _ O
MRC -X- _ B-TaskName
tasks, -X- _ O
where -X- _ O
a -X- _ O
system -X- _ O
is -X- _ O
required -X- _ O
to -X- _ O
point -X- _ O
to -X- _ O
a -X- _ O
span -X- _ O
within -X- _ O
a -X- _ O
given -X- _ O
paragraph -X- _ O
p -X- _ O
as -X- _ O
its -X- _ O
prediction. -X- _ O

In -X- _ O
the -X- _ O
neural -X- _ B-TaskName
machine -X- _ I-TaskName
translation -X- _ I-TaskName
(NMT) -X- _ B-TaskName
domain, -X- _ O
non-autoregressive -X- _ B-MethodName
NMT -X- _ I-MethodName
(NART) -X- _ B-MethodName
models -X- _ O
(Gu -X- _ O
et -X- _ O
al, -X- _ O
2018) -X- _ O
have -X- _ O
been -X- _ O
proposed -X- _ O
to -X- _ O
alleviate -X- _ O
the -X- _ O
low -X- _ O
translation -X- _ O
speeds -X- _ O
of -X- _ O
autoregressive -X- _ B-MethodName
NMT -X- _ I-MethodName
(ART) -X- _ B-MethodName
models. -X- _ O

These -X- _ O
results -X- _ O
express -X- _ O
the -X- _ O
improvement -X- _ O
comparing -X- _ O
to -X- _ O
our -X- _ O
final -X- _ O
model -X- _ O
(ProCluster -X- _ B-MethodName
abs -X- _ I-MethodName
), -X- _ O
that -X- _ O
a -X- _ O
better -X- _ O
cluster -X- _ O
repre-sentative -X- _ O
choice -X- _ O
could -X- _ O
produce, -X- _ O
i.e., -X- _ O
up -X- _ O
to~2 -X- _ B-MetricValue
R-2 -X- _ B-MetricName
points -X- _ O
in -X- _ O
TAC -X- _ B-DatasetName
2011 -X- _ I-DatasetName
and~1 -X- _ B-MetricValue
point -X- _ O
in -X- _ B-DatasetName
DUC -X- _ I-DatasetName
2004. -X- _ I-DatasetName

For -X- _ O
the -X- _ B-DatasetName
SentEval -X- _ I-DatasetName
evaluations, -X- _ O
we -X- _ O
trained -X- _ O
a -X- _ O
logistic -X- _ O
regression -X- _ O
classifier -X- _ O
using -X- _ O
sentence -X- _ O
embeddings -X- _ O
as -X- _ O
input -X- _ O
features -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
extent -X- _ O
to -X- _ O
which -X- _ O
each -X- _ O
sentence -X- _ O
embedding -X- _ O
contained -X- _ O
the -X- _ O
important -X- _ O
information -X- _ O
for -X- _ O
each -X- _ O
task. -X- _ O

The -X- _ O
transfer -X- _ O
step -X- _ O
is -X- _ O
transfer -X- _ O
learning: -X- _ O
finetuning -X- _ O
a -X- _ O
large -X- _ O
pre-trained -X- _ O
BERT -X- _ B-MethodName
or -X- _ O
RoBERTa -X- _ B-MethodName
on -X- _ O
the -X- _ O
ASNQ -X- _ B-DatasetName
dataset: -X- _ O
a -X- _ O
large-scale -X- _ O
answer -X- _ O
sentence -X- _ O
selection -X- _ O
dataset -X- _ O
extracted -X- _ O
from -X- _ O
Google's -X- _ O
Natural -X- _ O
Questions -X- _ O
(Kwiatkowski -X- _ O
et -X- _ O
al, -X- _ O
2019). -X- _ O

For -X- _ O
all -X- _ O
models -X- _ O
above -X- _ O
we -X- _ O
apply -X- _ O
a -X- _ O
label -X- _ B-HyperparameterName
smoothing -X- _ I-HyperparameterName
of -X- _ O
0.1 -X- _ B-HyperparameterValue
to -X- _ O
prevent -X- _ O
overfitting -X- _ O
(Pereyra -X- _ O
et -X- _ O
al, -X- _ O
2017). -X- _ O

Multi-source -X- _ B-TaskName
sequence -X- _ I-TaskName
generation -X- _ I-TaskName
(MSG) -X- _ B-TaskName
is -X- _ O
an -X- _ O
important -X- _ O
kind -X- _ O
of -X- _ O
sequence -X- _ O
generation -X- _ O
tasks -X- _ O
that -X- _ O
takes -X- _ O
multiple -X- _ O
sources, -X- _ O
including -X- _ O
automatic -X- _ O
post-editing, -X- _ O
multi-source -X- _ O
translation, -X- _ O
multi-document -X- _ O
summarization, -X- _ O
etc. -X- _ O

We -X- _ O
conduct -X- _ O
extensive -X- _ O
experiments, -X- _ O
and -X- _ O
MIE -X- _ B-MethodName
achieves -X- _ O
a -X- _ O
overall -X- _ O
F-score -X- _ B-MetricName
of -X- _ O
69.28, -X- _ B-MetricValue
which -X- _ O
indicates -X- _ O
our -X- _ O
proposed -X- _ O
approach -X- _ O
is -X- _ O
a -X- _ O
promising -X- _ O
solution -X- _ O
for -X- _ O
the -X- _ O
task. -X- _ O

To -X- _ O
demonstrate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
model, -X- _ O
we -X- _ O
evaluate -X- _ O
it -X- _ O
on -X- _ O
two -X- _ B-TaskName
reading -X- _ I-TaskName
comprehension -X- _ I-TaskName
datasets, -X- _ O
namely -X- _ B-DatasetName
WikiHop -X- _ I-DatasetName
and -X- _ B-DatasetName
MedHop. -X- _ I-DatasetName

Using -X- _ B-DatasetName
JuICe, -X- _ I-DatasetName
we -X- _ O
train -X- _ O
models -X- _ O
for -X- _ O
two -X- _ O
tasks: -X- _ O
(1) -X- _ O
generation -X- _ B-TaskName
of -X- _ I-TaskName
the -X- _ I-TaskName
API -X- _ I-TaskName
call -X- _ I-TaskName
sequence -X- _ I-TaskName
in -X- _ I-TaskName
a -X- _ I-TaskName
code -X- _ I-TaskName
cell, -X- _ I-TaskName
and -X- _ O
(2) -X- _ O
full -X- _ B-TaskName
code -X- _ I-TaskName
cell -X- _ I-TaskName
generation, -X- _ I-TaskName
both -X- _ O
conditioned -X- _ O
on -X- _ O
the -X- _ O
NL-Code -X- _ O
history -X- _ O
up -X- _ O
to -X- _ O
a -X- _ O
particular -X- _ O
code -X- _ O
cell. -X- _ O

For -X- _ O
the -X- _ O
text, -X- _ O
we -X- _ O
considered -X- _ O
standard -X- _ O
metrics -X- _ O
like -X- _ O
ROUGE, -X- _ B-MetricName
BLEU -X- _ B-MetricName
popularly -X- _ O
used -X- _ O
in -X- _ O
the -X- _ O
literature -X- _ O
for -X- _ O
textual -X- _ B-TaskName
question -X- _ I-TaskName
answering -X- _ I-TaskName
task. -X- _ O

Averaging -X- _ O
across -X- _ O
labels, -X- _ O
RuleNN's -X- _ B-MethodName
AUC-PR -X- _ B-MetricName
is -X- _ O
6.8×, -X- _ B-MetricValue
7.6×, -X- _ B-MetricValue
1.5× -X- _ B-MetricValue
that -X- _ O
of -X- _ O
ILP, -X- _ B-MethodName
StarAI, -X- _ B-MethodName
other -X- _ O
neuro-symbolic -X- _ O
AI -X- _ O
approaches, -X- _ O
respectively. -X- _ O

We -X- _ O
propose -X- _ O
using -X- _ O
KTL -X- _ B-MethodName
to -X- _ O
perform -X- _ O
zero-shot -X- _ B-TaskName
question -X- _ I-TaskName
answering, -X- _ I-TaskName
and -X- _ O
our -X- _ O
experiments -X- _ O
show -X- _ O
considerable -X- _ O
improvements -X- _ O
over -X- _ O
large -X- _ O
pre-trained -X- _ O
transformer -X- _ O
language -X- _ O
models. -X- _ O

In -X- _ O
this -X- _ O
work -X- _ O
we -X- _ O
tackle -X- _ O
these -X- _ O
two -X- _ O
problems -X- _ O
so -X- _ O
as -X- _ O
to -X- _ O
enable -X- _ O
cross-lingual -X- _ B-TaskName
AMR -X- _ I-TaskName
parsing: -X- _ I-TaskName
we -X- _ O
explore -X- _ O
different -X- _ O
transfer -X- _ O
learning -X- _ O
techniques -X- _ O
for -X- _ O
producing -X- _ O
automatic -X- _ O
AMR -X- _ O
annotations -X- _ O
across -X- _ O
languages -X- _ O
and -X- _ O
develop -X- _ O
a -X- _ O
crosslingual -X- _ O
AMR -X- _ O
parser, -X- _ O
XL-AMR. -X- _ B-MethodName

For -X- _ O
both -X- _ O
LSTM -X- _ B-MethodName
and -X- _ O
Transformer -X- _ B-MethodName
encoders, -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
layers -X- _ I-HyperparameterName
is -X- _ O
set -X- _ O
to -X- _ O
3, -X- _ B-MetricValue
and -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
parameters -X- _ I-HyperparameterName
is -X- _ O
configured -X- _ O
to -X- _ O
be -X- _ O
the -X- _ O
same -X- _ O
(6.9M -X- _ B-HyperparameterValue
parameters) -X- _ O
to -X- _ O
enable -X- _ O
a -X- _ O
fair -X- _ O
comparison -X- _ O
between -X- _ O
architectures -X- _ O
(for -X- _ O
further -X- _ O
details, -X- _ O
see -X- _ O
Appendix -X- _ O
B). -X- _ O

meaning -X- _ B-TaskName
preservation -X- _ I-TaskName
judgments -X- _ I-TaskName
adopt -X- _ O
the -X- _ B-TaskName
Semantic -X- _ I-TaskName
Textual -X- _ I-TaskName
Similarity -X- _ I-TaskName
annotation -X- _ O
scheme -X- _ O
of -X- _ O
Agirre -X- _ O
et -X- _ O
al -X- _ O
(2016), -X- _ O
where -X- _ O
an -X- _ O
informal -X- _ O
input -X- _ O
and -X- _ O
its -X- _ O
corresponding -X- _ O
formal -X- _ O
system -X- _ O
output -X- _ O
are -X- _ O
rated -X- _ O
on -X- _ O
a -X- _ O
scale -X- _ O
from -X- _ O
1 -X- _ O
to -X- _ O
6 -X- _ O
based -X- _ O
on -X- _ O
their -X- _ O
similarity -X- _ O
(Completely -X- _ O
dissimilar, -X- _ O
Not -X- _ O
equivalent -X- _ O
but -X- _ O
on -X- _ O
same -X- _ O
topic, -X- _ O
Not -X- _ O
equivalent -X- _ O
but -X- _ O
share -X- _ O
some -X- _ O
details, -X- _ O
Roughly -X- _ O
equivalent, -X- _ O
Mostly -X- _ O
equivalent, -X- _ O
Completely -X- _ O
equivalent); -X- _ O
3. -X- _ O

We -X- _ O
find -X- _ O
that -X- _ O
a -X- _ O
proper -X- _ O
margin -X- _ O
γ -X- _ B-HyperparameterName
= -X- _ O
0.2 -X- _ B-HyperparameterValue
is -X- _ O
beneficial -X- _ O
for -X- _ O
matching -X- _ O
learning -X- _ O
compared -X- _ O
with -X- _ O
a -X- _ O
large -X- _ O
or -X- _ O
small -X- _ O
margin. -X- _ O

We -X- _ O
follow -X- _ O
the -X- _ O
basic -X- _ O
design -X- _ O
of -X- _ O
Dozat -X- _ O
and -X- _ O
Manning -X- _ O
( -X- _ O
2017), -X- _ O
but -X- _ O
instead -X- _ O
of -X- _ O
using -X- _ O
LSTMs -X- _ B-MethodName
as -X- _ O
input -X- _ O
feature -X- _ O
extractors, -X- _ O
we -X- _ O
opt -X- _ O
for -X- _ O
Transformer -X- _ B-MethodName
encoders -X- _ I-MethodName
(Vaswani -X- _ O
et -X- _ O
al, -X- _ O
2017), -X- _ O
which -X- _ O
have -X- _ O
previously -X- _ O
been -X- _ O
shown -X- _ O
to -X- _ O
be -X- _ O
successful -X- _ O
in -X- _ B-TaskName
constituency -X- _ I-TaskName
parsing -X- _ I-TaskName
(Kitaev -X- _ O
and -X- _ O
Klein, -X- _ O
2018;Kitaev -X- _ O
et -X- _ O
al, -X- _ O
2019), -X- _ B-TaskName
dependency -X- _ I-TaskName
parsing -X- _ I-TaskName
(Kondratyuk -X- _ O
and -X- _ O
Straka, -X- _ O
2019), -X- _ O
and -X- _ O
SRL -X- _ B-TaskName
(Tan -X- _ O
et -X- _ O
al, -X- _ O
2018;Strubell -X- _ O
et -X- _ O
al, -X- _ O
2018). -X- _ O

We -X- _ O
then -X- _ O
create -X- _ O
a -X- _ O
new -X- _ O
dataset -X- _ O
split -X- _ O
following -X- _ O
the -X- _ B-DatasetName
CMU-MOSEI -X- _ I-DatasetName
split -X- _ O
for -X- _ O
the -X- _ O
sentiment -X- _ B-TaskName
classification -X- _ I-TaskName
task. -X- _ O

Here -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
bert-large-uncased -X- _ O
checkpoint, -X- _ O
with -X- _ O
embeddings -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
dimension -X- _ I-HyperparameterName
1024. -X- _ B-MetricValue

A -X- _ O
task -X- _ O
that -X- _ O
is -X- _ O
key -X- _ O
to -X- _ O
achieving -X- _ O
this -X- _ O
goal -X- _ O
is -X- _ B-TaskName
Word -X- _ I-TaskName
Sense -X- _ I-TaskName
Disambiguation -X- _ I-TaskName
(WSD), -X- _ B-TaskName
where, -X- _ O
given -X- _ O
a -X- _ O
sentence -X- _ O
with -X- _ O
a -X- _ O
target -X- _ O
word, -X- _ O
a -X- _ O
model -X- _ O
has -X- _ O
to -X- _ O
predict -X- _ O
its -X- _ O
most -X- _ O
suitable -X- _ O
meaning -X- _ O
from -X- _ O
a -X- _ O
predefined -X- _ O
set -X- _ O
of -X- _ O
labels, -X- _ O
i.e., -X- _ O
its -X- _ O
senses. -X- _ O

To -X- _ O
facilitate -X- _ O
research -X- _ O
of -X- _ O
knowledge -X- _ O
probing -X- _ O
in -X- _ O
the -X- _ O
biomedical -X- _ O
domain, -X- _ O
we -X- _ O
create -X- _ O
the -X- _ O
MedLAMA -X- _ B-DatasetName
benchmark -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
largest -X- _ O
biomedical -X- _ O
knowledge -X- _ O
graph -X- _ B-DatasetName
UMLS -X- _ I-DatasetName
(Bodenreider, -X- _ O
2004). -X- _ O

Instead, -X- _ O
we -X- _ O
approximate -X- _ O
narrative -X- _ O
structure -X- _ O
automatically -X- _ O
by -X- _ O
pretraining -X- _ O
on -X- _ O
the -X- _ O
annotations -X- _ O
of -X- _ O
the -X- _ B-DatasetName
TRIPOD -X- _ I-DatasetName
dataset -X- _ O
of -X- _ O
Papalampidi -X- _ O
et -X- _ O
al -X- _ O
(2019) -X- _ O
and -X- _ O
employing -X- _ O
a -X- _ O
variant -X- _ O
of -X- _ O
their -X- _ O
model. -X- _ O

Most -X- _ O
dominant -X- _ O
neural -X- _ B-TaskName
machine -X- _ I-TaskName
translation -X- _ I-TaskName
(NMT) -X- _ B-TaskName
models -X- _ O
are -X- _ O
restricted -X- _ O
to -X- _ O
make -X- _ O
predictions -X- _ O
only -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
local -X- _ O
context -X- _ O
of -X- _ O
preceding -X- _ O
words -X- _ O
in -X- _ O
a -X- _ O
left-to-right -X- _ O
manner. -X- _ O

r-BLEU -X- _ B-MethodName
gets -X- _ O
30 -X- _ B-MetricValue
out -X- _ I-MetricValue
of -X- _ I-MetricValue
40 -X- _ I-MetricValue
comparisons -X- _ O
correct -X- _ O
while -X- _ O
the -X- _ O
other -X- _ O
metrics -X- _ O
get -X- _ O
25, -X- _ B-MetricValue
22, -X- _ B-MetricValue
and -X- _ O
19 -X- _ B-MetricValue
respectively. -X- _ O

We -X- _ O
can -X- _ O
see -X- _ O
that -X- _ O
in -X- _ O
general, -X- _ O
pretrained -X- _ O
models -X- _ O
outperform -X- _ O
others -X- _ O
by -X- _ O
a -X- _ O
large -X- _ O
margin, -X- _ O
and -X- _ O
increasing -X- _ O
the -X- _ O
model -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
seems -X- _ O
to -X- _ O
further -X- _ O
boost -X- _ O
the -X- _ O
performance -X- _ O
on -X- _ B-DatasetName
DART. -X- _ I-DatasetName

The -X- _ O
Mahalanobis -X- _ B-MetricName
distance -X- _ I-MetricName
consistently -X- _ O
outperforms -X- _ O
consistently -X- _ O
outperforms -X- _ O
MSP, -X- _ B-MethodName
and -X- _ O
the -X- _ O
L -X- _ B-MetricName
margin -X- _ I-MetricName
achieves -X- _ O
better -X- _ O
performance -X- _ O
except -X- _ O
for -X- _ O
the -X- _ O
FAR95 -X- _ B-MetricName
metric -X- _ O
on -X- _ O
the -X- _ O
TREC-10 -X- _ B-DatasetName
dataset. -X- _ O

Because -X- _ O
TTR -X- _ B-MetricName
decreases -X- _ O
for -X- _ O
longer -X- _ O
texts, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
moving -X- _ B-MetricName
average -X- _ I-MetricName
type-token -X- _ I-MetricName
ratio -X- _ I-MetricName
(MATTR) -X- _ B-MetricName
(Covington -X- _ O
and -X- _ O
McFall, -X- _ O
2010)-for -X- _ O
a -X- _ O
given -X- _ O
sequence -X- _ O
of -X- _ O
tokens, -X- _ O
we -X- _ O
slide -X- _ O
a -X- _ O
window -X- _ O
of -X- _ O
size -X- _ B-HyperparameterName
W -X- _ B-HyperparameterName
" -X- _ O
50 -X- _ B-HyperparameterValue
over -X- _ O
all -X- _ O
tokens -X- _ O
with -X- _ O
a -X- _ O
stride -X- _ B-HyperparameterName
of -X- _ O
s -X- _ B-HyperparameterName
" -X- _ O
1, -X- _ B-HyperparameterValue
compute -X- _ O
lexical -X- _ O
richness -X- _ O
for -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
windows, -X- _ O
and -X- _ O
output -X- _ O
the -X- _ O
average. -X- _ O

While -X- _ O
Nishida -X- _ O
et -X- _ O
al -X- _ O
(2019) -X- _ O
also -X- _ O
use -X- _ O
a -X- _ O
standard -X- _ B-TaskName
Reading -X- _ I-TaskName
Comprehension -X- _ I-TaskName
(RC) -X- _ B-TaskName
model, -X- _ O
they -X- _ O
combine -X- _ O
it -X- _ O
with -X- _ O
a -X- _ O
special -X- _ O
Query -X- _ O
Focused -X- _ O
Extractor -X- _ O
that -X- _ O
identifies -X- _ O
relevant -X- _ O
sentences -X- _ O
by -X- _ O
updating -X- _ O
a -X- _ O
RNN -X- _ B-MethodName
state -X- _ O
representation -X- _ O
in -X- _ O
each -X- _ O
step, -X- _ O
allowing -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
capture -X- _ O
dependencies -X- _ O
between -X- _ O
sentences -X- _ O
across -X- _ O
time-steps. -X- _ O

In -X- _ O
this -X- _ O
work -X- _ O
we -X- _ O
introduce -X- _ O
the -X- _ O
Generative -X- _ B-MethodName
Style -X- _ I-MethodName
Transformer -X- _ I-MethodName
(GST) -X- _ B-MethodName
-a -X- _ O
new -X- _ O
approach -X- _ O
to -X- _ O
rewriting -X- _ O
sentences -X- _ O
to -X- _ O
a -X- _ O
target -X- _ O
style -X- _ O
in -X- _ O
the -X- _ O
absence -X- _ O
of -X- _ O
parallel -X- _ O
style -X- _ O
corpora. -X- _ O

We -X- _ O
use -X- _ O
a -X- _ O
maximum -X- _ O
of -X- _ O
n -X- _ B-HyperparameterName
X -X- _ I-HyperparameterName
= -X- _ O
6 -X- _ B-HyperparameterValue
contextual -X- _ O
utterances -X- _ O
and -X- _ O
a -X- _ O
maximum -X- _ O
of -X- _ O
n -X- _ O
P -X- _ B-HyperparameterName
= -X- _ O
10 -X- _ B-HyperparameterValue
persona -X- _ O
sentences -X- _ O
for -X- _ O
each -X- _ O
conversation. -X- _ O

Additionally, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ B-DatasetName
CODAH -X- _ I-DatasetName
dataset -X- _ O
and -X- _ O
also -X- _ O
follow -X- _ O
the -X- _ O
method -X- _ O
in -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
(2020) -X- _ O
to -X- _ O
create -X- _ O
HellaSwag-2K -X- _ B-DatasetName
(Zellers -X- _ O
et -X- _ O
al, -X- _ O
2019) -X- _ O
for -X- _ O
testing -X- _ O
our -X- _ O
methods -X- _ O
in -X- _ O
low-resource -X- _ O
scenarios. -X- _ O

We -X- _ O
initialize -X- _ O
the -X- _ O
cross-stitch -X- _ B-MethodName
unit -X- _ I-MethodName
to -X- _ O
imbalanced, -X- _ O
set -X- _ O
the -X- _ O
standard -X- _ B-HyperparameterName
deviation -X- _ I-HyperparameterName
of -X- _ O
the -X- _ O
Gaussian -X- _ O
noise -X- _ O
to -X- _ O
2, -X- _ B-HyperparameterValue
and -X- _ O
use -X- _ O
simple -X- _ O
stochastic -X- _ B-MethodName
gradient -X- _ I-MethodName
descent -X- _ I-MethodName
(SGD) -X- _ B-MethodName
as -X- _ O
the -X- _ O
optimizer. -X- _ O

Textual -X- _ B-TaskName
Multi-hop -X- _ I-TaskName
Question -X- _ I-TaskName
Answering -X- _ I-TaskName
(QA) -X- _ O
is -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
answering -X- _ O
questions -X- _ O
by -X- _ O
combining -X- _ O
information -X- _ O
from -X- _ O
multiple -X- _ O
sentences -X- _ O
or -X- _ O
documents. -X- _ O

We -X- _ O
present -X- _ B-DatasetName
DART, -X- _ I-DatasetName
an -X- _ O
open -X- _ O
domain -X- _ O
structured -X- _ O
DAta-Record-to-Text -X- _ O
generation -X- _ O
dataset -X- _ O
with -X- _ O
over -X- _ O
82k -X- _ O
instances -X- _ O
(DARTs). -X- _ O

WikiQA -X- _ B-DatasetName
(Yang -X- _ O
et -X- _ O
al, -X- _ O
2015) -X- _ O
contains -X- _ O
questions -X- _ O
originally -X- _ O
sampled -X- _ O
from -X- _ O
Bing -X- _ O
query -X- _ O
logs, -X- _ O
and -X- _ O
matched -X- _ O
with -X- _ O
candidate -X- _ O
answer -X- _ O
sentences -X- _ O
from -X- _ O
the -X- _ O
first -X- _ O
paragraph -X- _ O
of -X- _ O
relevant -X- _ O
Wikipedia -X- _ O
articles. -X- _ O

We -X- _ O
use -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
239 -X- _ O
test -X- _ O
outputs -X- _ O
from -X- _ O
BART -X- _ B-MethodName
fine-tuned -X- _ O
on -X- _ O
XSUM -X- _ B-DatasetName
(Lewis -X- _ O
et -X- _ O
al, -X- _ O
2019). -X- _ O

We -X- _ O
implemented -X- _ O
our -X- _ O
model -X- _ O
in -X- _ O
Tensorflow -X- _ O
(Abadi -X- _ O
et -X- _ O
al, -X- _ O
2016) -X- _ O
and -X- _ O
Keras. -X- _ O
8 -X- _ O
To -X- _ O
achieve -X- _ O
a -X- _ O
fair -X- _ O
comparison -X- _ O
with -X- _ O
OpenTag -X- _ B-MethodName
(Zheng -X- _ O
et -X- _ O
al, -X- _ O
2018), -X- _ O
and -X- _ O
to -X- _ O
ensure -X- _ O
that -X- _ O
performance -X- _ O
improvements -X- _ O
stem -X- _ O
from -X- _ O
leveraging -X- _ O
the -X- _ O
product -X- _ O
taxonomy, -X- _ O
we -X- _ O
use -X- _ O
exactly -X- _ O
the -X- _ O
same -X- _ O
components -X- _ O
and -X- _ O
configuration -X- _ O
as -X- _ O
OpenTag -X- _ B-MethodName
for -X- _ O
ProductEnc: -X- _ B-DatasetName
We -X- _ O
initialize -X- _ O
the -X- _ O
word -X- _ O
embedding -X- _ O
layer -X- _ O
using -X- _ O
100-dimensional -X- _ B-HyperparameterValue
pre-trained -X- _ O
Glove -X- _ O
embeddings -X- _ O
(Pennington -X- _ O
et -X- _ O
al, -X- _ O
2014). -X- _ O

We -X- _ O
randomly -X- _ O
split -X- _ O
all -X- _ O
referring -X- _ O
expressions -X- _ O
in -X- _ B-DatasetName
WebNLG -X- _ I-DatasetName
with -X- _ O
ratio -X- _ B-HyperparameterValue
8:1:1. -X- _ B-MetricName

Since -X- _ O
knowing -X- _ O
the -X- _ O
span -X- _ O
of -X- _ O
descriptive -X- _ O
contexts -X- _ O
of -X- _ O
event -X- _ O
complexes -X- _ O
helps -X- _ O
infer -X- _ O
the -X- _ O
membership -X- _ O
of -X- _ O
events, -X- _ O
we -X- _ O
propose -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
event-based -X- _ B-MethodName
text -X- _ I-MethodName
segmentation -X- _ I-MethodName
(EVENTSEG) -X- _ O
as -X- _ O
an -X- _ O
auxiliary -X- _ O
task -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
learning -X- _ O
for -X- _ O
subevent -X- _ B-TaskName
detection. -X- _ I-TaskName

System1 -X- _ O
handles -X- _ O
tasks -X- _ O
that -X- _ O
humans -X- _ O
consider -X- _ O
fast, -X- _ O
intuitive -X- _ O
and -X- _ O
automatic, -X- _ O
such -X- _ O
as -X- _ O
object -X- _ B-TaskName
detection -X- _ I-TaskName
and -X- _ B-TaskName
document -X- _ I-TaskName
classification. -X- _ I-TaskName

We -X- _ O
show -X- _ O
that -X- _ O
current -X- _ O
methods -X- _ O
for -X- _ O
judging -X- _ O
metrics -X- _ O
are -X- _ O
highly -X- _ O
sensitive -X- _ O
to -X- _ O
the -X- _ O
translations -X- _ O
used -X- _ O
for -X- _ O
assessment, -X- _ O
particularly -X- _ O
the -X- _ O
presence -X- _ O
of -X- _ O
outliers, -X- _ O
which -X- _ O
often -X- _ O
leads -X- _ O
to -X- _ O
falsely -X- _ O
confident -X- _ O
conclusions -X- _ O
about -X- _ O
a -X- _ O
metric's -X- _ O
efficacy. -X- _ O

On -X- _ O
the -X- _ O
other -X- _ O
hand, -X- _ O
we -X- _ O
present -X- _ O
STRM -X- _ B-MethodName
which -X- _ O
can -X- _ O
compute -X- _ O
OOV -X- _ O
word -X- _ O
representation -X- _ O
and -X- _ O
contextualization -X- _ O
more -X- _ O
precisely -X- _ O
in -X- _ O
BERT-based -X- _ B-MethodName
models. -X- _ O

This -X- _ O
example -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
joint -X- _ O
modeling -X- _ O
of -X- _ O
global -X- _ O
and -X- _ O
local -X- _ O
context -X- _ O
can -X- _ O
improve -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ B-TaskName
keyphrase -X- _ I-TaskName
extraction -X- _ I-TaskName
and -X- _ O
our -X- _ O
model -X- _ O
really -X- _ O
captures -X- _ O
local -X- _ O
and -X- _ O
global -X- _ O
informa-tion. -X- _ O

For -X- _ O
instance, -X- _ O
given -X- _ O
a -X- _ O
sentence -X- _ O
of -X- _ O
n -X- _ O
words -X- _ O
and -X- _ O
an -X- _ O
image -X- _ O
with -X- _ O
m -X- _ O
regions, -X- _ O
SCAN -X- _ B-MethodName
and -X- _ O
VisualSparta -X- _ B-MethodName
only -X- _ O
have -X- _ O
access -X- _ O
to -X- _ O
nm -X- _ O
times -X- _ O
regionword -X- _ O
interactions -X- _ O
between -X- _ O
n -X- _ O
words -X- _ O
and -X- _ O
m -X- _ O
regions. -X- _ O

The -X- _ O
incremental -X- _ B-MethodName
coreference -X- _ I-MethodName
(ICOREF) -X- _ B-MethodName
model -X- _ O
(Xia -X- _ O
et -X- _ O
al, -X- _ O
2020) -X- _ O
used -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
is -X- _ O
a -X- _ O
constant-memory -X- _ O
adaptation -X- _ O
of -X- _ O
the -X- _ O
end-to-end -X- _ O
neural -X- _ B-TaskName
coreference -X- _ I-TaskName
resolution -X- _ I-TaskName
model -X- _ O
(Lee -X- _ O
et -X- _ O
al, -X- _ O
2017) -X- _ O
with -X- _ O
improvements -X- _ O
from -X- _ O
subsequent -X- _ O
work -X- _ O
that -X- _ O
incorporates -X- _ O
stronger -X- _ O
encoders -X- _ O
(Joshi -X- _ O
et -X- _ O
al, -X- _ O
2019(Joshi -X- _ O
et -X- _ O
al, -X- _ O
, -X- _ O
2020. -X- _ O

Reinforcement -X- _ O
learning -X- _ O
RL -X- _ O
has -X- _ O
been -X- _ O
used -X- _ O
for -X- _ O
many -X- _ O
NLP -X- _ O
tasks, -X- _ O
including -X- _ B-TaskName
coreference -X- _ I-TaskName
resolution -X- _ I-TaskName
(Clark -X- _ O
and -X- _ O
Manning, -X- _ O
2016) -X- _ O
and -X- _ B-TaskName
relation -X- _ I-TaskName
extraction -X- _ I-TaskName
(Zeng -X- _ O
et -X- _ O
al, -X- _ O
2018). -X- _ O

Yu -X- _ O
and -X- _ O
Ettinger -X- _ O
(2020), -X- _ O
using -X- _ O
partially -X- _ O
idiomatic -X- _ O
expressions -X- _ O
of -X- _ O
the -X- _ B-DatasetName
BiRD -X- _ I-DatasetName
dataset -X- _ O
(Asaadi -X- _ O
et -X- _ O
al, -X- _ O
2019), -X- _ O
show -X- _ O
that -X- _ O
contextualised -X- _ O
embeddings -X- _ O
from -X- _ O
language -X- _ O
models -X- _ O
heavily -X- _ O
rely -X- _ O
on -X- _ O
word -X- _ O
content, -X- _ O
missing -X- _ O
additional -X- _ O
information -X- _ O
provided -X- _ O
by -X- _ O
compositional -X- _ O
operations. -X- _ O

BERT -X- _ B-MethodName
is -X- _ O
fine-tuned -X- _ O
for -X- _ O
3, -X- _ B-HyperparameterValue
000 -X- _ I-HyperparameterValue
steps -X- _ B-HyperparameterName
for -X- _ O
the -X- _ O
regression -X- _ B-TaskName
tasks -X- _ O
and -X- _ O
for -X- _ O
8, -X- _ B-HyperparameterValue
000 -X- _ I-HyperparameterValue
steps -X- _ B-HyperparameterName
for -X- _ O
the -X- _ O
word-level -X- _ B-TaskName
metaphor -X- _ I-TaskName
detection -X- _ I-TaskName
task. -X- _ O

Even -X- _ O
though -X- _ O
our -X- _ O
GPT2-Medium-generated -X- _ O
training -X- _ O
dataset -X- _ O
is -X- _ O
completely -X- _ O
different -X- _ O
from -X- _ O
the -X- _ O
test -X- _ O
domain, -X- _ O
and -X- _ O
contains -X- _ O
essentially -X- _ O
zero -X- _ O
examples -X- _ O
of -X- _ O
correct -X- _ O
couplets, -X- _ O
FUDGE -X- _ B-MethodName
is -X- _ O
able -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
desired -X- _ O
attribute. -X- _ O

The -X- _ O
corresponding -X- _ O
box-plot -X- _ O
in -X- _ O
Figure -X- _ O
4 -X- _ O
shows -X- _ O
that -X- _ O
for -X- _ O
word-level -X- _ O
QE -X- _ O
quality -X- _ O
levels -X- _ O
63.5% -X- _ B-MetricValue
F1 -X- _ B-MetricName
and -X- _ O
75% -X- _ B-MetricValue
F1 -X- _ B-MetricName
binary -X- _ O
is -X- _ O
the -X- _ O
preferred -X- _ O
visualization -X- _ O
scheme -X- _ O
(preference -X- _ O
value -X- _ O
below -X- _ O
0.5). -X- _ B-MetricValue

To -X- _ O
alleviate -X- _ O
this -X- _ O
discrepancy, -X- _ O
we -X- _ O
introduce -X- _ O
a -X- _ O
simple -X- _ O
template -X- _ O
engine -X- _ O
that -X- _ O
recursively -X- _ O
traverses -X- _ O
the -X- _ O
compositional -X- _ B-TaskName
MR -X- _ I-TaskName
in -X- _ O
a -X- _ O
top-down -X- _ O
manner -X- _ O
to -X- _ O
generate -X- _ O
a -X- _ O
structure-aware -X- _ O
text -X- _ O
representation -X- _ O
(template -X- _ O
guided -X- _ O
representation). -X- _ O

(4) -X- _ O
This -X- _ O
constraint -X- _ O
is -X- _ O
reminiscent -X- _ O
of -X- _ O
the -X- _ O
idea -X- _ O
of -X- _ O
"cycle -X- _ O
consistency" -X- _ O
that -X- _ O
have -X- _ O
found -X- _ O
success -X- _ O
in -X- _ O
image -X- _ B-TaskName
and -X- _ I-TaskName
text -X- _ I-TaskName
style -X- _ I-TaskName
transfer -X- _ I-TaskName
(Zhu -X- _ O
et -X- _ O
al, -X- _ O
2017;Shen -X- _ O
et -X- _ O
al, -X- _ O
2017), -X- _ B-TaskName
question -X- _ I-TaskName
answering -X- _ I-TaskName
Wang -X- _ O
et -X- _ O
al, -X- _ O
2017a), -X- _ O
and -X- _ O
disentangled -X- _ B-TaskName
representation -X- _ I-TaskName
learning -X- _ I-TaskName
(Jha -X- _ O
et -X- _ O
al, -X- _ O
2018). -X- _ O

(4) -X- _ O
Although -X- _ O
the -X- _ O
main -X- _ O
focus -X- _ O
of -X- _ O
our -X- _ O
work -X- _ O
is -X- _ O
language -X- _ B-TaskName
generation, -X- _ I-TaskName
we -X- _ O
also -X- _ O
show -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
models -X- _ O
on -X- _ O
Arabic -X- _ B-TaskName
language -X- _ I-TaskName
understanding -X- _ I-TaskName
by -X- _ O
fine-tuning -X- _ O
our -X- _ O
new -X- _ O
models -X- _ O
on -X- _ O
a -X- _ O
large, -X- _ O
recently -X- _ O
proposed -X- _ O
Arabic -X- _ B-TaskName
language -X- _ I-TaskName
understanding -X- _ I-TaskName
benchmark. -X- _ O

We -X- _ O
do -X- _ O
so -X- _ O
by -X- _ O
performing -X- _ O
second-stage-pretraining -X- _ O
for -X- _ O
one -X- _ B-HyperparameterValue
epoch -X- _ O
on -X- _ O
a -X- _ O
combined -X- _ O
corpus -X- _ O
of -X- _ O
Wikipedia -X- _ B-DatasetName
and -X- _ O
changing -X- _ O
number -X- _ O
of -X- _ O
copies -X- _ O
of -X- _ O
SST-5. -X- _ B-DatasetName

Adaptive -X- _ O
policies -X- _ O
are -X- _ O
better -X- _ O
than -X- _ O
fixed -X- _ O
policies -X- _ O
for -X- _ O
simultaneous -X- _ B-TaskName
translation, -X- _ I-TaskName
since -X- _ O
they -X- _ O
can -X- _ O
flexibly -X- _ O
balance -X- _ O
the -X- _ O
tradeoff -X- _ O
between -X- _ O
translation -X- _ O
quality -X- _ O
and -X- _ O
latency -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
current -X- _ O
context -X- _ O
information. -X- _ O

The -X- _ O
'No -X- _ O
Explicit -X- _ O
Reproach' -X- _ O
category -X- _ O
has -X- _ O
the -X- _ O
highest -X- _ O
percentage -X- _ B-MetricName
(77.2%) -X- _ B-MetricValue
of -X- _ O
correctly -X- _ O
classified -X- _ O
data -X- _ O
points -X- _ O
by -X- _ O
the -X- _ O
model, -X- _ O
followed -X- _ O
by -X- _ O
label -X- _ O
'Disapproval' -X- _ O
with -X- _ O
59.0%. -X- _ B-MetricValue

We -X- _ O
set -X- _ O
the -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
to -X- _ O
256 -X- _ B-HyperparameterValue
and -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
to -X- _ O
0.1 -X- _ B-HyperparameterValue
and -X- _ O
use -X- _ O
a -X- _ O
stochastic -X- _ O
gradient -X- _ O
descent -X- _ O
optimizer -X- _ O
(Bottou, -X- _ O
2010). -X- _ O

We -X- _ O
further -X- _ O
fine-tune -X- _ O
the -X- _ O
target-to-source -X- _ O
attention -X- _ O
in -X- _ O
the -X- _ O
BTBA -X- _ B-MethodName
model -X- _ O
to -X- _ O
obtain -X- _ O
better -X- _ O
alignments -X- _ O
using -X- _ O
a -X- _ O
full -X- _ O
context -X- _ O
based -X- _ O
optimization -X- _ O
method -X- _ O
and -X- _ O
self-supervised -X- _ O
training. -X- _ O

QReCC -X- _ B-DatasetName
is -X- _ O
accompanied -X- _ O
with -X- _ O
scripts -X- _ O
for -X- _ O
building -X- _ O
a -X- _ O
collection -X- _ O
of -X- _ O
passages -X- _ O
from -X- _ O
the -X- _ B-DatasetName
Common -X- _ I-DatasetName
Crawl -X- _ I-DatasetName
and -X- _ O
the -X- _ O
Wayback -X- _ B-DatasetName
Machine -X- _ I-DatasetName
for -X- _ O
passage -X- _ O
retrieval. -X- _ O

Multimodal -X- _ B-TaskName
Machine -X- _ I-TaskName
Translation -X- _ I-TaskName
(MMT) -X- _ B-TaskName
aims -X- _ O
to -X- _ O
introduce -X- _ O
information -X- _ O
from -X- _ O
other -X- _ O
modality, -X- _ O
generally -X- _ O
static -X- _ O
images, -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
translation -X- _ O
quality. -X- _ O

Multi30K: -X- _ B-DatasetName
For -X- _ O
the -X- _ O
experiments -X- _ O
using -X- _ O
this -X- _ O
dataset, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
Transformer -X- _ B-MethodName
Network -X- _ I-MethodName
(Vaswani -X- _ O
et -X- _ O
al, -X- _ O
2017) -X- _ O
with -X- _ O
3 -X- _ B-HyperparameterValue
encoder -X- _ B-HyperparameterName
and -X- _ O
3 -X- _ B-HyperparameterValue
decoder -X- _ B-HyperparameterName
layers, -X- _ I-HyperparameterName
8 -X- _ B-HyperparameterValue
heads, -X- _ B-HyperparameterName
and -X- _ O
model -X- _ B-HyperparameterName
dimension -X- _ I-HyperparameterName
512. -X- _ B-HyperparameterValue

With -X- _ O
beam -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
4, -X- _ B-HyperparameterValue
our -X- _ O
MRT -X- _ B-MethodName
models -X- _ O
outperform -X- _ O
the -X- _ O
MLE -X- _ B-MethodName
baseline -X- _ O
by -X- _ O
0.5-0.8 -X- _ B-MetricValue
BLEU; -X- _ B-MetricName
with -X- _ O
beam -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
50, -X- _ B-HyperparameterValue
this -X- _ O
difference -X- _ O
grows -X- _ O
to -X- _ O
0.6-1.5 -X- _ B-MetricValue
BLEU. -X- _ B-MetricName

We -X- _ O
train -X- _ O
our -X- _ O
model -X- _ O
for -X- _ O
500K -X- _ B-HyperparameterValue
steps -X- _ B-HyperparameterName
on -X- _ O
the -X- _ O
TitanRTX, -X- _ O
24G -X- _ O
GPU -X- _ O
with -X- _ O
gradient -X- _ O
accumulation -X- _ O
in -X- _ O
every -X- _ O
two -X- _ O
steps -X- _ O
with -X- _ O
Adam -X- _ B-MethodName
optimizers. -X- _ O

Additionally, -X- _ O
the -X- _ O
difference -X- _ O
in -X- _ O
performance -X- _ O
in -X- _ O
those -X- _ O
two -X- _ O
instances -X- _ O
is -X- _ O
considerably -X- _ O
larger -X- _ O
(3.58% -X- _ B-MetricValue
and -X- _ O
1.15%), -X- _ B-MetricValue
than -X- _ O
the -X- _ O
setting -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
baseline -X- _ O
performs -X- _ O
better -X- _ O
(0.13%). -X- _ B-MetricValue

However, -X- _ O
these -X- _ O
more -X- _ O
esoteric -X- _ O
tasks -X- _ O
are -X- _ O
tenuously -X- _ O
associated -X- _ O
with -X- _ O
those -X- _ O
that -X- _ O
users -X- _ O
are -X- _ O
more -X- _ O
likely -X- _ O
to -X- _ O
interact -X- _ O
with, -X- _ O
such -X- _ O
as -X- _ B-TaskName
Machine -X- _ I-TaskName
Translation -X- _ I-TaskName
or -X- _ O
Speech -X- _ B-TaskName
Synthesis. -X- _ I-TaskName

The -X- _ O
Word-in-Context -X- _ B-DatasetName
dataset -X- _ O
(WiC) -X- _ B-DatasetName
addresses -X- _ O
the -X- _ O
dependence -X- _ O
on -X- _ O
sense -X- _ O
inventories -X- _ O
by -X- _ O
reformulating -X- _ O
the -X- _ O
standard -X- _ O
disambiguation -X- _ O
task -X- _ O
as -X- _ O
a -X- _ O
binary -X- _ O
classification -X- _ O
problem; -X- _ O
but, -X- _ O
it -X- _ O
is -X- _ O
limited -X- _ O
to -X- _ O
the -X- _ O
English -X- _ O
language. -X- _ O

Word -X- _ B-TaskName
Sense -X- _ I-TaskName
Disambiguation -X- _ I-TaskName
(WSD) -X- _ B-TaskName
is -X- _ O
a -X- _ O
historical -X- _ O
NLP -X- _ O
task -X- _ O
aimed -X- _ O
at -X- _ O
linking -X- _ O
words -X- _ O
in -X- _ O
contexts -X- _ O
to -X- _ O
discrete -X- _ O
sense -X- _ O
inventories -X- _ O
and -X- _ O
it -X- _ O
is -X- _ O
usually -X- _ O
cast -X- _ O
as -X- _ O
a -X- _ O
multi-label -X- _ O
classification -X- _ O
task. -X- _ O

We -X- _ O
also -X- _ O
experiment -X- _ O
with -X- _ O
512 -X- _ B-HyperparameterValue
hidden -X- _ B-HyperparameterName
dimensions, -X- _ I-HyperparameterName
for -X- _ O
comparison -X- _ O
with -X- _ O
previous -X- _ O
parallel -X- _ O
decoding -X- _ O
models -X- _ O
(Gu -X- _ O
et -X- _ O
al, -X- _ O
2018;. -X- _ O
We -X- _ O
follow -X- _ O
the -X- _ O
weight -X- _ O
initialization -X- _ O
scheme -X- _ O
from -X- _ O
BERT -X- _ B-MethodName
(Devlin -X- _ O
et -X- _ O
al, -X- _ O
2018), -X- _ O
which -X- _ O
samples -X- _ O
weights -X- _ O
from -X- _ O
N -X- _ B-HyperparameterValue
(0, -X- _ I-HyperparameterValue
0.02), -X- _ I-HyperparameterValue
initializes -X- _ O
biases -X- _ B-HyperparameterName
to -X- _ O
zero, -X- _ B-HyperparameterValue
and -X- _ O
sets -X- _ O
layer -X- _ B-HyperparameterName
normalization -X- _ I-HyperparameterName
parameters -X- _ I-HyperparameterName
to -X- _ O
β -X- _ B-HyperparameterName
= -X- _ O
0, -X- _ B-HyperparameterValue
γ -X- _ B-HyperparameterName
= -X- _ O
1. -X- _ B-HyperparameterValue

In -X- _ O
this -X- _ O
paper, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
CogAlign -X- _ B-MethodName
approach -X- _ O
to -X- _ O
these -X- _ O
issues, -X- _ O
which -X- _ O
learns -X- _ O
to -X- _ O
align -X- _ O
textual -X- _ O
neural -X- _ O
representations -X- _ O
to -X- _ O
cognitive -X- _ O
features. -X- _ O

In -X- _ O
this -X- _ O
work -X- _ O
we -X- _ O
reorganize -X- _ O
two -X- _ B-TaskName
emotion -X- _ I-TaskName
recognition -X- _ I-TaskName
datasets: -X- _ O
Interactive -X- _ O
Emotional -X- _ O
Dyadic -X- _ B-DatasetName
Motion -X- _ I-DatasetName
Capture -X- _ I-DatasetName
(IEMOCAP) -X- _ B-DatasetName
and -X- _ O
CMU -X- _ B-DatasetName
Multimodal -X- _ I-DatasetName
Opinion -X- _ I-DatasetName
Sentiment -X- _ I-DatasetName
and -X- _ I-DatasetName
Emotion -X- _ I-DatasetName
Intensity -X- _ I-DatasetName
(CMU-MOSEI). -X- _ B-DatasetName

With -X- _ O
gold -X- _ O
segmentation, -X- _ O
our -X- _ O
model -X- _ O
achieves -X- _ O
a -X- _ O
SoTA -X- _ O
F -X- _ B-MetricName
1 -X- _ I-MetricName
score -X- _ I-MetricName
of -X- _ O
50.2 -X- _ B-MetricValue
(Full), -X- _ O
outperforming -X- _ O
the -X- _ O
best -X- _ O
existing -X- _ O
system -X- _ O
by -X- _ O
2.1 -X- _ B-MetricValue
absolute -X- _ O
points. -X- _ O

Despite -X- _ O
such -X- _ O
differences, -X- _ B-DatasetName
OntoNotes -X- _ I-DatasetName
5.0 -X- _ I-DatasetName
(Weischedel -X- _ O
et -X- _ O
al, -X- _ O
2013) -X- _ O
emerged -X- _ O
as -X- _ O
the -X- _ O
most -X- _ O
widely-used -X- _ O
benchmark -X- _ O
for -X- _ O
the -X- _ O
full -X- _ O
task, -X- _ O
and -X- _ O
widely -X- _ O
used -X- _ O
public -X- _ O
models -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
this -X- _ O
dataset -X- _ O
(Manning -X- _ O
et -X- _ O
al, -X- _ O
2014;Gardner -X- _ O
et -X- _ O
al, -X- _ O
2018). -X- _ O

The -X- _ B-DatasetName
QASC -X- _ I-DatasetName
dataset -X- _ O
contains -X- _ O
a -X- _ O
textual -X- _ O
knowledge -X- _ O
corpus -X- _ O
containing -X- _ O
science -X- _ O
facts. -X- _ O

In -X- _ O
this -X- _ O
work -X- _ O
we -X- _ O
argued -X- _ O
that -X- _ B-TaskName
text -X- _ I-TaskName
generation -X- _ I-TaskName
should -X- _ O
be -X- _ O
interactive, -X- _ O
and, -X- _ O
as -X- _ O
a -X- _ O
means -X- _ O
towards -X- _ O
that -X- _ O
end, -X- _ O
we -X- _ O
proposed -X- _ O
a -X- _ O
general -X- _ O
text -X- _ O
editing -X- _ O
task, -X- _ O
where -X- _ O
a -X- _ O
system -X- _ O
must -X- _ O
edit -X- _ O
a -X- _ O
document -X- _ O
in -X- _ O
response -X- _ O
to -X- _ O
a -X- _ O
user -X- _ O
command. -X- _ O

SQuAD -X- _ B-DatasetName
2.0 -X- _ I-DatasetName
(Rajpurkar -X- _ O
et -X- _ O
al, -X- _ O
2018) -X- _ O
includes -X- _ O
unanswerable -X- _ O
questions -X- _ O
that -X- _ O
are -X- _ O
written -X- _ O
by -X- _ O
annotators -X- _ O
who -X- _ O
try -X- _ O
to -X- _ O
write -X- _ O
confusing -X- _ O
questions -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
single -X- _ O
paragraph. -X- _ O

Our -X- _ O
work -X- _ O
is -X- _ O
related -X- _ O
to -X- _ O
the -X- _ O
recent -X- _ O
work -X- _ O
(Kottur -X- _ O
et -X- _ O
al, -X- _ O
2018;Jiang -X- _ O
and -X- _ O
Bansal, -X- _ O
2019;Gupta -X- _ O
et -X- _ O
al, -X- _ O
2020) -X- _ O
that -X- _ O
extended -X- _ O
NMNs -X- _ B-MethodName
to -X- _ O
image -X- _ O
reasoning -X- _ B-TaskName
in -X- _ I-TaskName
dialogues -X- _ I-TaskName
and -X- _ O
reading -X- _ B-TaskName
comprehension -X- _ I-TaskName
reasoning. -X- _ I-TaskName

The -X- _ O
dropout -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
is -X- _ O
0.2 -X- _ B-HyperparameterValue
and -X- _ O
we -X- _ O
train -X- _ O
the -X- _ O
model -X- _ O
for -X- _ O
20 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
in -X- _ O
total. -X- _ O

To -X- _ O
further -X- _ O
analyze -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
different -X- _ O
factors -X- _ O
of -X- _ O
our -X- _ O
CLINE, -X- _ B-MethodName
we -X- _ O
choose -X- _ O
PERSPECTRUM -X- _ B-DatasetName
and -X- _ O
BoolQ -X- _ B-DatasetName
(Clark -X- _ O
et -X- _ O
al, -X- _ O
2019) -X- _ O
as -X- _ O
benchmark -X- _ O
datasets -X- _ O
and -X- _ O
report -X- _ O
the -X- _ O
ablation -X- _ O
test -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
1) -X- _ O
w/o -X- _ B-MethodName
RTD: -X- _ I-MethodName
we -X- _ O
remove -X- _ O
the -X- _ O
replaced -X- _ O
token -X- _ O
detection -X- _ O
objective -X- _ O
(L -X- _ B-MethodName
RTD -X- _ I-MethodName
) -X- _ O
in -X- _ O
our -X- _ O
model -X- _ O
to -X- _ O
verify -X- _ O
whether -X- _ O
our -X- _ O
model -X- _ O
mainly -X- _ O
benefits -X- _ O
from -X- _ O
the -X- _ O
contrastive -X- _ O
objective. -X- _ O
2) -X- _ O
w/o -X- _ B-MethodName
Hard -X- _ I-MethodName
Negative: -X- _ I-MethodName
we -X- _ O
replace -X- _ O
the -X- _ O
constructed -X- _ O
negative -X- _ O
examples -X- _ O
with -X- _ O
random -X- _ O
sampling -X- _ O
examples -X- _ O
to -X- _ O
verify -X- _ O
whether -X- _ O
the -X- _ O
negative -X- _ O
examples -X- _ O
constructed -X- _ O
by -X- _ O
unsupervised -X- _ O
word -X- _ O
substitution -X- _ O
are -X- _ O
better. -X- _ O

Finally, -X- _ O
we -X- _ O
remove -X- _ O
the -X- _ O
auxiliary -X- _ O
ranking -X- _ O
task -X- _ O
and -X- _ O
the -X- _ O
results -X- _ O
decrease -X- _ O
by -X- _ O
1.20 -X- _ B-MetricValue
on -X- _ O
alignment -X- _ B-MetricName
accuracy -X- _ I-MetricName
and -X- _ O
2.33 -X- _ B-MetricValue
on -X- _ O
joint -X- _ B-MetricName
accuracy. -X- _ I-MetricName

We -X- _ O
use -X- _ O
grid-search -X- _ B-MethodName
for -X- _ O
hyper-parameter -X- _ B-TaskName
tuning: -X- _ I-TaskName
learning -X- _ O
rate -X- _ O
{1e-5, -X- _ B-HyperparameterValue
3e-5, -X- _ B-HyperparameterValue
5e-5}, -X- _ B-HyperparameterValue
number -X- _ O
of -X- _ O
epochs -X- _ B-MetricName
{3, -X- _ B-MetricValue
4, -X- _ I-MetricValue
5, -X- _ I-MetricValue
8}, -X- _ I-MetricValue
batch-size -X- _ B-MetricName
{8, -X- _ B-MetricValue
16, -X- _ I-MetricValue
32} -X- _ I-MetricValue
with -X- _ O
three -X- _ O
different -X- _ O
random -X- _ O
seeds. -X- _ O

performing -X- _ O
better? -X- _ O
• -X- _ O
Are -X- _ O
there -X- _ O
NLU -X- _ B-TaskName
benchmarks, -X- _ O
other -X- _ O
than -X- _ B-DatasetName
GLUE, -X- _ I-DatasetName
on -X- _ O
which -X- _ O
shuffled -X- _ O
language -X- _ O
models -X- _ O
perform -X- _ O
poorly? -X- _ O
Contributions -X- _ O
We -X- _ O
first -X- _ O
demonstrate, -X- _ O
in -X- _ O
Section -X- _ O
3, -X- _ O
that -X- _ O
shuffled -X- _ O
language -X- _ O
models -X- _ O
do -X- _ O
contain -X- _ O
word -X- _ O
order -X- _ O
information, -X- _ O
and -X- _ O
are -X- _ O
quite -X- _ O
responsive -X- _ O
to -X- _ O
simple -X- _ O
tests -X- _ O
for -X- _ O
word -X- _ O
order -X- _ O
information, -X- _ O
particularly -X- _ O
when -X- _ O
compared -X- _ O
to -X- _ O
models -X- _ O
trained -X- _ O
without -X- _ O
position -X- _ O
representations. -X- _ O

We -X- _ O
varied -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
words -X- _ I-HyperparameterName
n -X- _ B-HyperparameterName
to -X- _ O
give -X- _ O
as -X- _ O
input -X- _ O
to -X- _ O
UKB -X- _ B-MethodName
between -X- _ O
5 -X- _ B-HyperparameterValue
and -X- _ O
25 -X- _ B-HyperparameterValue
with -X- _ O
a -X- _ O
5 -X- _ B-HyperparameterValue
step -X- _ B-HyperparameterName
and -X- _ O
selected -X- _ O
the -X- _ O
value -X- _ O
n -X- _ B-HyperparameterName
= -X- _ O
5 -X- _ B-HyperparameterValue
by -X- _ O
manually -X- _ O
assessing -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
a -X- _ O
sample -X- _ O
of -X- _ O
the -X- _ O
clusters' -X- _ O
disambiguation -X- _ O
output. -X- _ O

Meaning -X- _ O
Representation -X- _ O
(AMR) -X- _ B-MethodName
is -X- _ O
a -X- _ O
popular -X- _ O
formalism -X- _ O
of -X- _ O
natural -X- _ O
language -X- _ O
that -X- _ O
represents -X- _ O
the -X- _ O
meaning -X- _ O
of -X- _ O
a -X- _ O
sentence -X- _ O
as -X- _ O
a -X- _ O
semantic -X- _ O
graph. -X- _ O

We -X- _ O
train -X- _ O
models -X- _ O
for -X- _ O
10k -X- _ B-HyperparameterValue
gradient -X- _ B-HyperparameterName
steps -X- _ I-HyperparameterName
with -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
32, -X- _ B-HyperparameterValue
and -X- _ O
save -X- _ O
a -X- _ O
checkpoint -X- _ O
every -X- _ O
1k -X- _ B-HyperparameterValue
steps. -X- _ O

Overall, -X- _ O
compared -X- _ O
with -X- _ O
the -X- _ O
basic -X- _ O
model, -X- _ O
the -X- _ O
performance -X- _ O
on -X- _ B-TaskName
link -X- _ I-TaskName
prediction -X- _ I-TaskName
tasks -X- _ O
has -X- _ O
been -X- _ O
improved -X- _ O
by -X- _ O
SFBR. -X- _ B-MethodName

While -X- _ O
DrBoost -X- _ B-MethodName
improves -X- _ O
slightly -X- _ O
over -X- _ O
the -X- _ O
dimensionmatched -X- _ O
baseline -X- _ O
on -X- _ B-DatasetName
EntityQuestions, -X- _ I-DatasetName
where -X- _ O
the -X- _ O
passage -X- _ O
corpora -X- _ O
stays -X- _ O
the -X- _ O
same, -X- _ O
it -X- _ O
produces -X- _ O
worse -X- _ O
results -X- _ O
on -X- _ O
the -X- _ B-DatasetName
BEIR -X- _ I-DatasetName
datasets. -X- _ O

Experimental -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
we -X- _ O
achieve -X- _ O
an -X- _ O
overall -X- _ O
improvement -X- _ O
of -X- _ O
2.48% -X- _ B-MetricValue
on -X- _ O
grounding -X- _ B-MetricName
accuracy -X- _ I-MetricName
compared -X- _ O
to -X- _ O
a -X- _ O
strong -X- _ O
baseline, -X- _ O
and -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
outperforms -X- _ O
previous -X- _ O
methods -X- _ O
on -X- _ B-TaskName
phrase -X- _ I-TaskName
grounding. -X- _ I-TaskName

We -X- _ O
finally -X- _ O
detail -X- _ O
how -X- _ O
to -X- _ O
perform -X- _ O
context-aware -X- _ B-TaskName
decoding -X- _ I-TaskName
based -X- _ O
on -X- _ O
C-SCORE -X- _ B-DatasetName
( -X- _ O
§ -X- _ O
2.2). -X- _ O

BERT -X- _ B-MethodName
is -X- _ O
pre-trained -X- _ O
on -X- _ O
two -X- _ O
corpora: -X- _ O
BooksCorpus -X- _ B-DatasetName
(800M -X- _ O
words) -X- _ O
(Zhu -X- _ O
et -X- _ O
al, -X- _ O
2015) -X- _ O
and -X- _ O
English -X- _ B-DatasetName
Wikipedia -X- _ I-DatasetName
(2,500M -X- _ O
words), -X- _ O
which -X- _ O
leads -X- _ O
to -X- _ O
some -X- _ O
world -X- _ O
knowledge -X- _ O
learned -X- _ O
as -X- _ O
reported -X- _ O
in -X- _ O
Petroni -X- _ O
et -X- _ O
al -X- _ O
(2019); -X- _ O
Davison -X- _ O
et -X- _ O
al -X- _ O
(2019). -X- _ O

We -X- _ O
apply -X- _ O
our -X- _ O
method -X- _ O
to -X- _ O
improve -X- _ O
compositional -X- _ B-TaskName
question -X- _ I-TaskName
answering -X- _ I-TaskName
using -X- _ O
neural -X- _ O
module -X- _ O
networks -X- _ O
on -X- _ O
the -X- _ B-DatasetName
DROP -X- _ I-DatasetName
dataset. -X- _ O

We -X- _ O
find -X- _ O
that -X- _ O
precision -X- _ B-MetricName
dropped -X- _ O
by -X- _ O
8 -X- _ B-MetricValue
points, -X- _ I-MetricValue
compared -X- _ O
to -X- _ O
a -X- _ O
drop -X- _ O
of -X- _ O
28 -X- _ B-MetricValue
points -X- _ I-MetricValue
when -X- _ O
the -X- _ O
model -X- _ O
trained -X- _ O
only -X- _ O
on -X- _ B-DatasetName
IIRC -X- _ I-DatasetName
was -X- _ O
used, -X- _ O
indicating -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
learn -X- _ O
to -X- _ O
identify -X- _ O
when -X- _ O
no -X- _ O
external -X- _ O
information -X- _ O
is -X- _ O
required. -X- _ O

Extensive -X- _ O
works -X- _ O
in -X- _ O
this -X- _ O
direction -X- _ O
exist, -X- _ O
applied -X- _ O
to -X- _ O
different -X- _ O
NLP -X- _ O
tasks, -X- _ O
i.e., -X- _ O
WSD -X- _ B-TaskName
(Barba -X- _ O
et -X- _ O
al, -X- _ O
2020), -X- _ O
SRL -X- _ B-TaskName
(Padó -X- _ O
and -X- _ O
Lapata, -X- _ O
2009;Kozhevnikov -X- _ O
and -X- _ O
Titov, -X- _ O
2013), -X- _ B-TaskName
Dependency -X- _ I-TaskName
Parsing -X- _ I-TaskName
(Tiedemann, -X- _ O
2015), -X- _ O
concept -X- _ B-TaskName
representation -X- _ I-TaskName
(Conia -X- _ O
and -X- _ O
Navigli, -X- _ O
2020), -X- _ O
etc. -X- _ O

Furthermore, -X- _ O
automatic -X- _ B-TaskName
generation -X- _ I-TaskName
of -X- _ I-TaskName
adversarial -X- _ I-TaskName
datasets -X- _ I-TaskName
has -X- _ O
much -X- _ O
unrealized -X- _ O
potential; -X- _ O
e.g., -X- _ O
different -X- _ O
datasets, -X- _ O
paraphrase -X- _ O
generators, -X- _ O
and -X- _ O
training -X- _ O
approaches -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
generate -X- _ O
future -X- _ O
versions -X- _ O
of -X- _ O
AP -X- _ B-DatasetName
T -X- _ I-DatasetName
5 -X- _ I-DatasetName
in -X- _ O
order -X- _ O
to -X- _ O
produce -X- _ O
AP -X- _ O
T -X- _ O
passing -X- _ O
sentence -X- _ O
pairs -X- _ O
with -X- _ O
lower -X- _ O
lexical -X- _ O
and -X- _ O
syntactic -X- _ O
similarities -X- _ O
(as -X- _ O
measured -X- _ O
not -X- _ O
only -X- _ O
by -X- _ O
BLEURT, -X- _ B-MetricName
but -X- _ O
also -X- _ O
by -X- _ O
future -X- _ O
state-of-the-art -X- _ B-DatasetName
STS -X- _ I-DatasetName
metrics). -X- _ O

This -X- _ O
paper -X- _ O
presents -X- _ O
Neighborhood -X- _ B-MethodName
Matching -X- _ I-MethodName
Network -X- _ I-MethodName
(NMN), -X- _ B-MethodName
a -X- _ O
novel -X- _ B-TaskName
entity -X- _ I-TaskName
alignment -X- _ I-TaskName
framework -X- _ O
for -X- _ O
tackling -X- _ O
the -X- _ O
structural -X- _ O
heterogeneity -X- _ O
challenge. -X- _ O

Furthermore, -X- _ B-DatasetName
UR-FUNNY -X- _ I-DatasetName
is -X- _ O
the -X- _ O
only -X- _ B-TaskName
humor -X- _ I-TaskName
detection -X- _ I-TaskName
dataset -X- _ O
which -X- _ O
incorporates -X- _ O
all -X- _ O
three -X- _ O
modalities -X- _ O
of -X- _ O
text, -X- _ O
visual -X- _ O
and -X- _ O
acoustic. -X- _ O

For -X- _ O
example, -X- _ O
adversarially-modified -X- _ O
inputs -X- _ O
are -X- _ O
used -X- _ O
to -X- _ O
evaluate -X- _ O
reading -X- _ B-TaskName
comprehension -X- _ I-TaskName
models -X- _ O
(Jia -X- _ O
and -X- _ O
Liang, -X- _ O
2017;Ribeiro -X- _ O
et -X- _ O
al, -X- _ O
2018) -X- _ O
and -X- _ O
stress -X- _ O
test -X- _ O
neural -X- _ B-TaskName
machine -X- _ I-TaskName
translation -X- _ I-TaskName
(Belinkov -X- _ O
and -X- _ O
Bisk, -X- _ O
2018). -X- _ O

We -X- _ O
set -X- _ O
the -X- _ O
size -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
the -X- _ I-HyperparameterName
embeddings -X- _ I-HyperparameterName
K -X- _ B-HyperparameterName
= -X- _ O
100, -X- _ B-MetricValue
use -X- _ O
a -X- _ O
context -X- _ B-HyperparameterName
window -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
8 -X- _ B-HyperparameterValue
and -X- _ O
σ -X- _ B-HyperparameterName
= -X- _ O
1 -X- _ B-HyperparameterValue
throughout -X- _ O
all -X- _ O
experiments. -X- _ O

Finally, -X- _ O
another -X- _ O
concurrent -X- _ O
work -X- _ O
(Thakur -X- _ O
et -X- _ O
al, -X- _ O
2021) -X- _ O
introduces -X- _ O
the -X- _ B-DatasetName
BEIR -X- _ I-DatasetName
benchmark -X- _ O
for -X- _ O
zero-shot -X- _ O
evaluation -X- _ O
of -X- _ O
retrieval -X- _ O
models -X- _ O
and -X- _ O
shows -X- _ O
that -X- _ O
dense -X- _ O
retrieval -X- _ O
models -X- _ O
underperform -X- _ O
BM25 -X- _ B-MethodName
on -X- _ O
most -X- _ O
of -X- _ O
their -X- _ O
datasets. -X- _ O

The -X- _ O
comprehensive -X- _ O
human -X- _ B-MetricName
evaluation -X- _ I-MetricName
demonstrates -X- _ O
that -X- _ O
ValCAT -X- _ B-MethodName
has -X- _ O
a -X- _ O
significant -X- _ O
advantage -X- _ O
in -X- _ O
ensuring -X- _ O
the -X- _ O
fluency -X- _ O
of -X- _ O
the -X- _ O
adversarial -X- _ O
examples -X- _ O
and -X- _ O
achieves -X- _ O
better -X- _ O
semantic -X- _ O
consistency. -X- _ O

We -X- _ O
use -X- _ O
70GB -X- _ B-HyperparameterValue
of -X- _ O
MSA -X- _ O
text -X- _ O
(7.1B -X- _ O
tokens) -X- _ O
from -X- _ O
the -X- _ O
following -X- _ O
sources: -X- _ O
AraNews -X- _ B-DatasetName
(Nagoudi -X- _ O
et -X- _ O
al, -X- _ O
2020), -X- _ O
El-Khair -X- _ B-DatasetName
El-Khair -X- _ I-DatasetName
(2016), -X- _ O
Gigaword, -X- _ B-DatasetName
2 -X- _ O
, -X- _ O
OSCAR -X- _ B-DatasetName
(Suárez -X- _ O
et -X- _ O
al, -X- _ O
2019), -X- _ O
OSIAN -X- _ B-DatasetName
(Zeroual -X- _ O
et -X- _ O
al, -X- _ O
2019), -X- _ O
Wikipedia -X- _ B-DatasetName
Arabic, -X- _ I-DatasetName
and -X- _ O
Hindawi -X- _ B-DatasetName
Books. -X- _ I-DatasetName

Similar -X- _ O
to -X- _ O
the -X- _ O
next -X- _ B-MetricValue
sentence -X- _ I-MetricValue
prediction -X- _ I-MetricValue
(NSP) -X- _ B-MetricValue
objective -X- _ O
in -X- _ O
BERT -X- _ O
pretraining, -X- _ O
but -X- _ O
here -X- _ O
we -X- _ O
frame -X- _ O
it -X- _ O
as -X- _ O
a -X- _ O
4-way -X- _ O
classification -X- _ B-MetricValue
task, -X- _ O
with -X- _ O
one -X- _ O
positive -X- _ O
and -X- _ O
3 -X- _ O
negative -X- _ O
candidates -X- _ O
for -X- _ O
the -X- _ O
next -X- _ O
sentence. -X- _ O

• -X- _ O
For -X- _ B-DatasetName
MultiRC, -X- _ I-DatasetName
given -X- _ O
a -X- _ O
passage -X- _ O
p, -X- _ O
question -X- _ O
q -X- _ O
and -X- _ O
answer -X- _ O
a, -X- _ O
we -X- _ O
estimate -X- _ O
whether -X- _ O
a -X- _ O
is -X- _ O
a -X- _ O
proper -X- _ O
answer -X- _ O
with: -X- _ O
• -X- _ O
For -X- _ B-DatasetName
WiC, -X- _ I-DatasetName
given -X- _ O
two -X- _ O
sentences -X- _ O
s -X- _ O
1 -X- _ O
and -X- _ O
s -X- _ O
2 -X- _ O
and -X- _ O
a -X- _ O
word -X- _ O
w, -X- _ O
we -X- _ O
classify -X- _ O
whether -X- _ O
w -X- _ O
was -X- _ O
used -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
sense. -X- _ O
"s1" -X- _ O
/ -X- _ O
"s2". -X- _ O

Experiments -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
method -X- _ O
improves -X- _ O
over -X- _ O
both -X- _ O
BiDAF -X- _ B-MethodName
and -X- _ O
BERT -X- _ B-MethodName
QA -X- _ O
baselines, -X- _ O
even -X- _ O
without -X- _ O
introducing -X- _ O
new -X- _ O
articles. -X- _ O

In -X- _ O
this -X- _ O
section, -X- _ O
we -X- _ O
describe -X- _ O
our -X- _ O
QA -X- _ O
system -X- _ O
(called -X- _ O
BARQA) -X- _ B-MethodName
for -X- _ O
bridging -X- _ B-TaskName
anaphora -X- _ I-TaskName
resolution -X- _ I-TaskName
in -X- _ O
detail. -X- _ O

Note -X- _ O
that -X- _ O
briefly, -X- _ O
the -X- _ O
CKD -X- _ B-MethodName
also -X- _ O
outperforms -X- _ O
all -X- _ O
baselines -X- _ O
for -X- _ O
all -X- _ B-DatasetName
GLUE -X- _ I-DatasetName
datasets -X- _ O
and -X- _ B-DatasetName
SQuAD -X- _ I-DatasetName
dataset -X- _ O
except -X- _ O
for -X- _ B-DatasetName
RTE -X- _ I-DatasetName
for -X- _ O
task-specific -X- _ O
distillation, -X- _ O
convincingly -X- _ O
verifying -X- _ O
its -X- _ O
effectiveness. -X- _ O

We -X- _ O
first -X- _ O
discuss -X- _ O
the -X- _ O
results -X- _ O
with -X- _ O
the -X- _ O
general -X- _ O
caption -X- _ O
generation -X- _ O
metrics -X- _ O
BLEU-4, -X- _ B-MetricName
ROUGE, -X- _ B-MetricName
ME-TEOR -X- _ B-MetricName
and -X- _ O
CIDEr -X- _ B-MetricName
reported -X- _ O
in -X- _ O
Table -X- _ O
8. -X- _ O

Recently, -X- _ O
however, -X- _ O
Yao -X- _ O
et -X- _ O
al -X- _ O
(2019) -X- _ O
introduced -X- _ B-DatasetName
DocRED, -X- _ I-DatasetName
a -X- _ O
dataset -X- _ O
of -X- _ O
cross-sentence -X- _ O
relation -X- _ O
extractions -X- _ O
on -X- _ O
Wikipedia -X- _ O
paragraphs. -X- _ O

Inspired -X- _ O
by -X- _ O
the -X- _ B-DatasetName
LAMBADA -X- _ I-DatasetName
dataset -X- _ O
(Paperno -X- _ O
et -X- _ O
al, -X- _ O
2016), -X- _ O
a -X- _ B-TaskName
question -X- _ I-TaskName
answering -X- _ I-TaskName
dataset -X- _ O
which -X- _ O
asks -X- _ O
models -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
last -X- _ O
word -X- _ O
in -X- _ O
a -X- _ O
sentence -X- _ O
given -X- _ O
several -X- _ O
sentences -X- _ O
of -X- _ O
context, -X- _ O
we -X- _ O
create -X- _ O
a -X- _ O
"last -X- _ B-TaskName
phrase -X- _ I-TaskName
prediction" -X- _ I-TaskName
(LPP) -X- _ B-TaskName
task, -X- _ O
which -X- _ O
requires -X- _ O
predicting -X- _ O
the -X- _ O
last -X- _ O
phrase -X- _ O
in -X- _ O
a -X- _ O
sentence. -X- _ O

We -X- _ O
further -X- _ O
extend -X- _ O
SMART -X- _ B-MethodName
to -X- _ O
domain -X- _ B-TaskName
adaptation -X- _ I-TaskName
and -X- _ O
use -X- _ O
both -X- _ B-DatasetName
SNLI -X- _ I-DatasetName
(Bowman -X- _ O
et -X- _ O
al, -X- _ O
2015) -X- _ O
and -X- _ B-DatasetName
SciTail -X- _ I-DatasetName
(Khot -X- _ O
et -X- _ O
al, -X- _ O
2018) -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
effectiveness. -X- _ O

For -X- _ O
TREC -X- _ B-DatasetName
DL -X- _ I-DatasetName
test -X- _ O
sets -X- _ O
which -X- _ O
have -X- _ O
many -X- _ O
judgement -X- _ O
lables -X- _ O
per -X- _ O
query, -X- _ O
we -X- _ O
report -X- _ O
the -X- _ O
commonly -X- _ O
used -X- _ O
NDCG@10 -X- _ B-MetricName
score. -X- _ O

Resampling -X- _ B-MethodName
and -X- _ O
re-weighting -X- _ B-MethodName
are -X- _ O
common -X- _ O
approaches -X- _ O
used -X- _ O
for -X- _ O
addressing -X- _ O
the -X- _ O
class -X- _ O
imbalance -X- _ O
problem, -X- _ O
however, -X- _ O
they -X- _ O
are -X- _ O
not -X- _ O
effective -X- _ O
when -X- _ O
there -X- _ O
is -X- _ O
label -X- _ O
dependency -X- _ O
besides -X- _ O
class -X- _ O
imbalance -X- _ O
because -X- _ O
they -X- _ O
result -X- _ O
in -X- _ O
oversampling -X- _ O
of -X- _ O
common -X- _ O
labels. -X- _ O

We -X- _ O
evaluate -X- _ O
our -X- _ O
model -X- _ O
on -X- _ O
FewRel -X- _ B-DatasetName
1.0 -X- _ I-DatasetName
(Han -X- _ O
et -X- _ O
al, -X- _ O
2018) -X- _ O
and -X- _ O
FewRel -X- _ B-DatasetName
2.0 -X- _ I-DatasetName
(Gao -X- _ O
et -X- _ O
al, -X- _ O
2019b -X- _ O

Our -X- _ O
contributions -X- _ O
are -X- _ O
as -X- _ O
follows: -X- _ O
• -X- _ O
We -X- _ O
use -X- _ O
unsupervised -X- _ B-TaskName
stance -X- _ I-TaskName
detection -X- _ I-TaskName
to -X- _ O
automatically -X- _ O
determine -X- _ O
the -X- _ O
stance -X- _ O
of -X- _ O
Twitter -X- _ O
users -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
several -X- _ O
polarizing -X- _ O
topics. -X- _ O

Experiments -X- _ O
on -X- _ O
benchmark -X- _ O
ACE2005 -X- _ B-DatasetName
show -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
outperforms -X- _ O
nine -X- _ O
strong -X- _ O
baselines, -X- _ O
is -X- _ O
especially -X- _ O
effective -X- _ O
for -X- _ O
unseen/sparsely -X- _ O
labeled -X- _ O
trigger -X- _ O
words. -X- _ O

The -X- _ O
author -X- _ O
adapts -X- _ O
the -X- _ O
WEAT -X- _ B-MethodName
method -X- _ O
(Caliskan -X- _ O
et -X- _ O
al, -X- _ O
2017) -X- _ O
that -X- _ O
contains -X- _ O
material -X- _ O
for -X- _ O
measuring -X- _ O
bias -X- _ O
in -X- _ O
English -X- _ O
language -X- _ O
word -X- _ O
embeddings -X- _ O
to -X- _ O
(Swiss) -X- _ O
French -X- _ O
and -X- _ O
German -X- _ O
and -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
bias -X- _ O
identified -X- _ O
differ -X- _ O
between -X- _ O
the -X- _ O
three -X- _ O
languages -X- _ O
studied. -X- _ O

To -X- _ O
remove -X- _ O
the -X- _ O
shared -X- _ O
components, -X- _ O
or -X- _ O
the -X- _ O
language -X- _ O
identification -X- _ O
from -X- _ O
the -X- _ O
representations, -X- _ O
we -X- _ O
leverage -X- _ O
singular -X- _ B-MethodName
value -X- _ I-MethodName
decomposition -X- _ I-MethodName
(SVD) -X- _ B-MethodName
which -X- _ O
identifies -X- _ O
the -X- _ O
principal -X- _ O
directions -X- _ O
of -X- _ O
a -X- _ O
space. -X- _ O

The -X- _ O
convolutional -X- _ O
network -X- _ O
that -X- _ O
we -X- _ O
used -X- _ O
for -X- _ O
our -X- _ O
secondary -X- _ O
learner -X- _ O
was -X- _ O
trained -X- _ O
using -X- _ O
SGD -X- _ B-MethodName
with -X- _ O
Adam -X- _ B-MethodName
with -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
10 -X- _ B-HyperparameterValue
−5 -X- _ I-HyperparameterValue
and -X- _ O
β -X- _ B-HyperparameterName
1 -X- _ I-HyperparameterName
= -X- _ O
0.9, -X- _ B-HyperparameterValue
β -X- _ B-HyperparameterName
2 -X- _ I-HyperparameterName
= -X- _ O
0.999. -X- _ B-HyperparameterValue

14 -X- _ O
We -X- _ O
report -X- _ O
the -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
and -X- _ O
calibration -X- _ O
metrics -X- _ O
of -X- _ O
our -X- _ O
ensembles, -X- _ O
students, -X- _ O
and -X- _ O
baseline -X- _ O
models -X- _ O
in -X- _ O
Table -X- _ O
2. -X- _ O

2) -X- _ O
PLOME -X- _ B-MethodName
is -X- _ O
composed -X- _ O
of -X- _ O
two -X- _ B-HyperparameterName
1-layer -X- _ B-HyperparameterName
GRU -X- _ O
networks -X- _ O
and -X- _ O
a -X- _ O
12-layer -X- _ B-HyperparameterName
transformer -X- _ O
encoder, -X- _ O
and -X- _ O
totally -X- _ O
contains -X- _ O
more -X- _ O
than -X- _ O
110M -X- _ B-HyperparameterValue
parameters. -X- _ B-HyperparameterName

It -X- _ O
has -X- _ O
been -X- _ O
used -X- _ O
in -X- _ O
different -X- _ O
NLP -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
parsing -X- _ O
(Hashimoto -X- _ O
et -X- _ O
al, -X- _ O
2017), -X- _ B-TaskName
dependency -X- _ I-TaskName
parsing -X- _ I-TaskName
(Peng -X- _ O
et -X- _ O
al, -X- _ O
2017), -X- _ O
neural -X- _ B-TaskName
machine -X- _ I-TaskName
translation -X- _ I-TaskName
(Luong -X- _ O
et -X- _ O
al, -X- _ O
2016), -X- _ B-TaskName
sentiment -X- _ I-TaskName
analysis -X- _ I-TaskName
(Augenstein -X- _ O
et -X- _ O
al, -X- _ O
2018), -X- _ O
and -X- _ O
other -X- _ O
tasks. -X- _ O

IEMOCAP -X- _ O
(Busso -X- _ O
et -X- _ O
al, -X- _ O
2008) -X- _ O
is -X- _ O
a -X- _ O
multimodal -X- _ B-TaskName
emotion -X- _ I-TaskName
recognition -X- _ I-TaskName
dataset -X- _ O
containing -X- _ O
151 -X- _ O
videos. -X- _ O

As -X- _ O
a -X- _ O
result, -X- _ O
we -X- _ O
set -X- _ O
k -X- _ B-HyperparameterName
= -X- _ O
10 -X- _ B-HyperparameterValue
whenever -X- _ O
adopting -X- _ O
the -X- _ O
LGAM -X- _ B-MethodName
strategy -X- _ O
in -X- _ O
STANKER. -X- _ B-MethodName

This -X- _ O
is -X- _ O
due -X- _ O
to -X- _ O
practical -X- _ O
constraints, -X- _ O
and -X- _ O
because -X- _ O
most -X- _ B-TaskName
hate -X- _ I-TaskName
speech -X- _ I-TaskName
detection -X- _ I-TaskName
models -X- _ O
are -X- _ O
developed -X- _ O
for -X- _ O
such -X- _ O
data -X- _ O
(Poletto -X- _ O
et -X- _ O
al, -X- _ O
2020;Vidgen -X- _ O
and -X- _ O
Derczynski, -X- _ O
2020). -X- _ O

We -X- _ O
conside -X- _ O
five -X- _ O
strong -X- _ O
baselines, -X- _ O
described -X- _ O
in -X- _ O
§2: -X- _ O
(1) -X- _ O
GSAMN -X- _ B-MethodName
(Lai -X- _ O
et -X- _ O
al, -X- _ O
2019): -X- _ O
Gated -X- _ O
Self-Attention -X- _ O
Memory -X- _ O
Networks. -X- _ O
(2) -X- _ O
TandA -X- _ B-MethodName
(Garg -X- _ O
et -X- _ O
al, -X- _ O
2019): -X- _ O
the -X- _ O
two-step -X- _ O
Transfer -X- _ O
and -X- _ O
Adapt -X- _ O
method. -X- _ O
Baselines -X- _ O
1, -X- _ O
2, -X- _ O
and -X- _ O
5 -X- _ O
are -X- _ O
available -X- _ O
only -X- _ O
on -X- _ O
TrecQA -X- _ B-DatasetName
and/or -X- _ B-DatasetName
WikiQA, -X- _ I-DatasetName
whereas -X- _ O
baselines -X- _ O
3 -X- _ O
and -X- _ O
4 -X- _ O
use -X- _ O
the -X- _ O
exact -X- _ O
same -X- _ O
datasets -X- _ O
as -X- _ O
we -X- _ O
do. -X- _ O

We -X- _ O
propose -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
generated -X- _ O
QS -X- _ O
hierarchy -X- _ O
against -X- _ O
the -X- _ O
reference -X- _ O
hierarchy -X- _ O
with -X- _ O
F1 -X- _ B-MetricName
scores -X- _ I-MetricName
calculated -X- _ O
as -X- _ O
follows, -X- _ O
inspired -X- _ O
by -X- _ O
labeled -X- _ O
attachment -X- _ O
score -X- _ O
in -X- _ O
dependency -X- _ O
parsing -X- _ O
(Zeman -X- _ O
et -X- _ O
al, -X- _ O
2017): -X- _ O
We -X- _ O
first -X- _ O
map -X- _ O
each -X- _ O
generated -X- _ O
QS -X- _ O
pair -X- _ O
to -X- _ O
a -X- _ O
reference -X- _ O
QS -X- _ O
pair -X- _ O
following -X- _ O
the -X- _ O
highest -X- _ O
sum -X- _ O
of -X- _ O
ROUGE-1 -X- _ B-MetricName
and -X- _ O
ROUGE-2 -X- _ B-MetricName
scores -X- _ O
between -X- _ O
their -X- _ O
summaries. -X- _ O

Our -X- _ O
recursive -X- _ O
self-attention -X- _ O
layers -X- _ O
have: -X- _ O
16 -X- _ B-HyperparameterValue
attention -X- _ B-HyperparameterName
heads, -X- _ I-HyperparameterName
a -X- _ O
feed-forward -X- _ B-HyperparameterName
dimension -X- _ I-HyperparameterName
of -X- _ O
4096, -X- _ B-HyperparameterValue
and -X- _ O
a -X- _ O
hidden -X- _ B-HyperparameterName
dimension -X- _ I-HyperparameterName
of -X- _ O
2048. -X- _ B-HyperparameterValue

1) -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
two-stream -X- _ O
encoding -X- _ O
module -X- _ O
for -X- _ O
document-level -X- _ B-TaskName
EAE, -X- _ I-TaskName
which -X- _ O
encodes -X- _ O
the -X- _ O
document -X- _ O
through -X- _ O
two -X- _ O
different -X- _ O
perspectives -X- _ O
to -X- _ O
better -X- _ O
utilize -X- _ O
the -X- _ O
context. -X- _ O

The -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
query -X- _ B-TaskName
generation -X- _ I-TaskName
remains -X- _ O
a -X- _ O
difficult -X- _ O
task: -X- _ O
the -X- _ O
top-3 -X- _ B-HyperparameterValue
beam -X- _ B-MethodName
search -X- _ I-MethodName
output -X- _ O
from -X- _ O
a -X- _ O
standard -X- _ O
Seq2Seq -X- _ B-MethodName
with -X- _ O
attention -X- _ O
baseline -X- _ O
achieves -X- _ O
on -X- _ O
average -X- _ O
0.88 -X- _ B-MethodName
errors -X- _ B-MetricName
per -X- _ O
token. -X- _ O

To -X- _ O
analyze -X- _ O
how -X- _ O
p -X- _ O
val -X- _ O
affects -X- _ O
the -X- _ O
model -X- _ O
performance, -X- _ O
we -X- _ O
conduct -X- _ O
experiments -X- _ O
with -X- _ O
different -X- _ O
setting -X- _ O
p -X- _ B-HyperparameterName
val -X- _ I-HyperparameterName
in -X- _ O
{0.7, -X- _ B-HyperparameterValue
0.8, -X- _ B-HyperparameterValue
0.9, -X- _ B-HyperparameterValue
0.95, -X- _ B-HyperparameterValue
0.99}, -X- _ B-HyperparameterValue
and -X- _ O
the -X- _ O
size -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
word -X- _ I-HyperparameterName
collection -X- _ I-HyperparameterName
and -X- _ O
model -X- _ O
performance -X- _ O
on -X- _ O
DL -X- _ B-DatasetName
and -X- _ O
DM -X- _ B-DatasetName
datasets -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
4. -X- _ O

We -X- _ O
do -X- _ O
not -X- _ O
apply -X- _ O
our -X- _ O
method -X- _ O
to -X- _ B-DatasetName
RefCOCO -X- _ I-DatasetName
(Yu -X- _ O
et -X- _ O
al, -X- _ O
2016) -X- _ O
or -X- _ B-DatasetName
Visual -X- _ I-DatasetName
Genome -X- _ I-DatasetName
(Krishna -X- _ O
et -X- _ O
al, -X- _ O
2017) -X- _ O
because -X- _ O
they -X- _ O
consist -X- _ O
of -X- _ O
independently -X- _ O
grounded -X- _ O
entity -X- _ O
phrases -X- _ O
without -X- _ O
any -X- _ O
entity -X- _ O
dependencies -X- _ O
that -X- _ O
CRFs -X- _ B-MethodName
could -X- _ O
leverage. -X- _ O

Extensive -X- _ O
experiments -X- _ O
conducted -X- _ O
on -X- _ O
several -X- _ O
widely-used -X- _ O
benchmarks -X- _ O
show -X- _ O
that -X- _ O
REWRITE-NAT -X- _ B-DatasetName
can -X- _ O
achieve -X- _ O
better -X- _ O
performance -X- _ O
while -X- _ O
significantly -X- _ O
reducing -X- _ O
decoding -X- _ O
time, -X- _ O
compared -X- _ O
with -X- _ O
previous -X- _ O
iterative -X- _ O
decoding -X- _ O
strategies. -X- _ O

For -X- _ B-TaskName
text -X- _ I-TaskName
classification -X- _ I-TaskName
tasks, -X- _ O
Park -X- _ O
et -X- _ O
al -X- _ O
(2018) -X- _ O
augment -X- _ O
the -X- _ O
datasets -X- _ O
by -X- _ O
swapping -X- _ O
the -X- _ O
gender-implying -X- _ O
identityterms -X- _ O
(e.g., -X- _ O
"he" -X- _ O
to -X- _ O
"she", -X- _ O
"actor" -X- _ O
to -X- _ O
"actress") -X- _ O
in -X- _ O
the -X- _ O
sentences -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
to -X- _ O
remove -X- _ O
the -X- _ O
correlation -X- _ O
between -X- _ O
Z -X- _ O
and -X- _ O
Y -X- _ O
. -X- _ O

Despite -X- _ O
its -X- _ O
importance, -X- _ O
less -X- _ O
attention -X- _ O
has -X- _ O
been -X- _ O
paid -X- _ O
to -X- _ O
identifying -X- _ O
and -X- _ O
improving -X- _ O
the -X- _ O
robustness -X- _ O
of -X- _ O
Multimodal -X- _ B-TaskName
Sentiment -X- _ I-TaskName
Analysis -X- _ I-TaskName
(MSA) -X- _ O
models. -X- _ O

ROCC -X- _ B-MethodName
operates -X- _ O
by -X- _ O
first -X- _ O
creating -X- _ O
n -X- _ B-HyperparameterName
k -X- _ I-HyperparameterName
justification -X- _ O
sets -X- _ O
from -X- _ O
the -X- _ O
top -X- _ O
n -X- _ B-HyperparameterName
sentences -X- _ O
selected -X- _ O
by -X- _ O
the -X- _ O
BM25 -X- _ B-MethodName
information -X- _ O
retrieval -X- _ O
model -X- _ O
(Robertson -X- _ O
et -X- _ O
al, -X- _ O
2009), -X- _ O
where -X- _ O
k -X- _ B-HyperparameterName
ranges -X- _ O
from -X- _ O
2 -X- _ B-HyperparameterValue
to -X- _ O
n, -X- _ B-HyperparameterValue
and -X- _ O
then -X- _ O
ranking -X- _ O
them -X- _ O
all -X- _ O
by -X- _ O
a -X- _ O
formula -X- _ O
that -X- _ O
combines -X- _ O
the -X- _ O
three -X- _ O
criteria -X- _ O
above. -X- _ O

TED-Talks: -X- _ B-DatasetName
We -X- _ O
use -X- _ O
the -X- _ O
TED2020 -X- _ B-DatasetName
v1 -X- _ I-DatasetName
corpus -X- _ O
(Reimers -X- _ O
and -X- _ O
Gurevych, -X- _ O
2020) -X- _ O
that -X- _ O
includes -X- _ O
3123 -X- _ O
English-Vietnamese -X- _ O
subtitle -X- _ O
pairs -X- _ O
of -X- _ O
TED -X- _ O
talks. -X- _ O

However, -X- _ O
the -X- _ O
semantic -X- _ O
preservation -X- _ O
metrics -X- _ O
get -X- _ O
worse -X- _ O
with -X- _ O
more -X- _ O
fine-grained -X- _ O
syntactic -X- _ O
control, -X- _ O
we -X- _ O
hypothesize -X- _ O
this -X- _ O
is -X- _ O
because -X- _ O
deeper-level -X- _ O
of -X- _ O
control -X- _ O
signals -X- _ O
can -X- _ O
be -X- _ O
misleading, -X- _ O
but -X- _ O
such -X- _ O
signals -X- _ O
restrict -X- _ O
models -X- _ O
to -X- _ O
generate -X- _ O
paraphrases -X- _ O
that -X- _ O
conform -X- _ O
to -X- _ O
the -X- _ O
provided -X- _ O
misleading -X- _ O
syntactic -X- _ O
signals, -X- _ O
which -X- _ O
impairs -X- _ O
the -X- _ O
ability -X- _ O
of -X- _ O
pretrained -X- _ O
language -X- _ O
models -X- _ O
to -X- _ O
generate -X- _ O
fluent -X- _ O
texts. -X- _ O

AMR -X- _ B-DatasetName
unifies, -X- _ O
in -X- _ O
a -X- _ O
single -X- _ O
structure, -X- _ O
a -X- _ O
rich -X- _ O
set -X- _ O
of -X- _ O
information -X- _ O
coming -X- _ O
from -X- _ O
different -X- _ O
tasks, -X- _ O
such -X- _ O
as -X- _ B-TaskName
Named -X- _ I-TaskName
Entity -X- _ I-TaskName
Recognition -X- _ I-TaskName
(NER), -X- _ B-TaskName
Semantic -X- _ B-TaskName
Role -X- _ I-TaskName
Labeling -X- _ I-TaskName
(SRL), -X- _ B-TaskName
Word -X- _ B-TaskName
Sense -X- _ I-TaskName
Disambiguation -X- _ I-TaskName
(WSD) -X- _ B-TaskName
and -X- _ B-TaskName
coreference -X- _ I-TaskName
resolution. -X- _ I-TaskName

BART -X- _ B-MethodName
outperforms -X- _ O
most -X- _ O
other -X- _ O
models -X- _ O
in -X- _ O
layers -X- _ O
1-6 -X- _ O
for -X- _ O
these -X- _ O
tasks -X- _ O
(a -X- _ O
similar -X- _ O
observation -X- _ O
is -X- _ O
found -X- _ O
for -X- _ O
NSP -X- _ B-TaskName
and -X- _ O
Sentence -X- _ B-TaskName
Ordering) -X- _ I-TaskName
with -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
ALBERT -X- _ B-MethodName
struggling -X- _ O
particularly -X- _ O
in -X- _ O
the -X- _ O
earlier -X- _ O
layers. -X- _ O

To -X- _ O
validate -X- _ O
this, -X- _ O
we -X- _ O
experiment -X- _ O
the -X- _ O
following -X- _ O
variants -X- _ O
on -X- _ O
both -X- _ O
ACE05 -X- _ B-DatasetName
and -X- _ O
SciERC: -X- _ B-DatasetName
TEXT: -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
span -X- _ O
representations -X- _ O
defined -X- _ O
in -X- _ O
the -X- _ O
entity -X- _ O
model -X- _ O
(Section -X- _ O
3.2) -X- _ O
and -X- _ O
concatenate -X- _ O
the -X- _ O
hidden -X- _ O
representations -X- _ O
for -X- _ O
the -X- _ O
subject -X- _ O
and -X- _ O
the -X- _ O
object, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
their -X- _ O
element-wise -X- _ O
multiplication: -X- _ O
[h -X- _ O
e -X- _ O
(s -X- _ O
i -X- _ O
), -X- _ O
h -X- _ O
e -X- _ O
(s -X- _ O
j -X- _ O
), -X- _ O
h -X- _ O
e -X- _ O
(s -X- _ O
i -X- _ O
) -X- _ O
h -X- _ O
e -X- _ O
(s -X- _ O
j -X- _ O
)]. -X- _ O

Our -X- _ O
SoftRegex -X- _ B-MethodName
model -X- _ O
with -X- _ O
EQ -X- _ O
Reg -X- _ O
as -X- _ O
a -X- _ O
reward -X- _ O
function -X- _ O
substantially -X- _ O
speeds -X- _ O
up -X- _ O
the -X- _ O
training -X- _ O
phase -X- _ O
(at -X- _ O
least -X- _ O
3.6 -X- _ B-MetricValue
times -X- _ O
faster -X- _ O
than -X- _ O
SemRegex) -X- _ B-MethodName
while -X- _ O
having -X- _ O
similar -X- _ O
or -X- _ O
better -X- _ O
performance -X- _ O
on -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
standard -X- _ O
benchmarks. -X- _ O

To -X- _ O
analyze -X- _ O
how -X- _ O
this -X- _ O
ambiguity -X- _ O
(also -X- _ O
known -X- _ O
as -X- _ O
intrinsic -X- _ O
uncertainty) -X- _ O
shapes -X- _ O
the -X- _ O
distribution -X- _ O
learned -X- _ O
by -X- _ O
neural -X- _ O
sequence -X- _ O
models -X- _ O
we -X- _ O
measure -X- _ O
sentence-level -X- _ O
uncertainty -X- _ O
by -X- _ O
computing -X- _ O
the -X- _ O
degree -X- _ O
of -X- _ O
overlap -X- _ O
between -X- _ O
references -X- _ O
in -X- _ O
multi-reference -X- _ O
test -X- _ O
sets -X- _ O
from -X- _ O
two -X- _ O
different -X- _ O
NLP -X- _ O
tasks: -X- _ B-TaskName
machine -X- _ I-TaskName
translation -X- _ I-TaskName
(MT) -X- _ B-TaskName
and -X- _ B-TaskName
grammatical -X- _ I-TaskName
error -X- _ I-TaskName
correction -X- _ I-TaskName
(GEC). -X- _ B-TaskName

We -X- _ O
limit -X- _ O
the -X- _ O
length -X- _ O
of -X- _ O
the -X- _ O
text -X- _ O
to -X- _ O
up -X- _ O
to -X- _ O
50 -X- _ B-HyperparameterValue
tokens. -X- _ B-HyperparameterName

Before -X- _ O
delving -X- _ O
into -X- _ O
the -X- _ O
main -X- _ O
results, -X- _ O
we -X- _ O
note -X- _ O
that -X- _ O
we -X- _ O
explored -X- _ O
regularizing -X- _ O
different -X- _ O
attention -X- _ O
vectors -X- _ O
in -X- _ O
the -X- _ O
model -X- _ O
(Appendix -X- _ O
C.3) -X- _ O
and -X- _ O
obtain -X- _ O
the -X- _ O
best -X- _ O
BLEU -X- _ B-MetricName
and -X- _ O
COMET -X- _ B-MetricName
scores -X- _ O
for -X- _ O
attnreg-rand -X- _ O
when -X- _ O
regularizing -X- _ O
the -X- _ O
self-attention -X- _ O
of -X- _ O
the -X- _ O
top -X- _ O
encoder -X- _ O
layer, -X- _ O
cross-attention -X- _ O
of -X- _ O
the -X- _ O
top -X- _ O
decoder -X- _ O
layer -X- _ O
and -X- _ O
self-attention -X- _ O
of -X- _ O
the -X- _ O
bottom -X- _ O
decoder -X- _ O
layer. -X- _ O

Recently, -X- _ O
scholars -X- _ O
are -X- _ O
more -X- _ O
inclined -X- _ O
to -X- _ O
solve -X- _ B-TaskName
link -X- _ I-TaskName
prediction -X- _ I-TaskName
by -X- _ O
designing -X- _ O
models -X- _ O
with -X- _ O
more -X- _ O
powerful -X- _ O
representation, -X- _ O
such -X- _ O
as -X- _ O
ComplEx -X- _ B-MethodName
(Trouillon -X- _ O
et -X- _ O
al, -X- _ O
2016), -X- _ O
Tucker -X- _ B-MethodName
(Balazevic -X- _ O
et -X- _ O
al, -X- _ O
2019), -X- _ O
RotatE -X- _ B-MethodName
(Sun -X- _ O
et -X- _ O
al, -X- _ O
2019), -X- _ O
a -X- _ O
method -X- _ O
based -X- _ O
on -X- _ O
vector -X- _ O
space -X- _ O
rotation, -X- _ O
and -X- _ O
HAKE -X- _ B-MethodName
(Zhang -X- _ O
et -X- _ O
al, -X- _ O
2020a). -X- _ O

Our -X- _ O
learning -X- _ O
approach -X- _ O
significantly -X- _ O
outperforms -X- _ O
previous -X- _ O
methods -X- _ O
which -X- _ O
use -X- _ O
heuristic -X- _ O
supervision -X- _ O
and -X- _ O
MML -X- _ O
updates, -X- _ O
including -X- _ O
absolute -X- _ O
gains -X- _ O
of -X- _ O
2-10%, -X- _ B-MetricValue
and -X- _ O
achives -X- _ O
the -X- _ O
state-of-the-art -X- _ O
on -X- _ O
five -X- _ O
datasets. -X- _ O

For -X- _ O
example, -X- _ O
when -X- _ O
manually -X- _ O
evaluating -X- _ O
the -X- _ O
top -X- _ O
negatives -X- _ O
of -X- _ O
TF-IDF -X- _ B-MethodName
on -X- _ O
50 -X- _ O
random -X- _ O
samples -X- _ O
from -X- _ B-DatasetName
FEVER, -X- _ I-DatasetName
42% -X- _ O
are -X- _ O
false -X- _ O
negatives. -X- _ O

Finally, -X- _ O
to -X- _ O
make -X- _ O
the -X- _ O
input -X- _ O
feature -X- _ O
maps -X- _ O
M -X- _ O
sparse -X- _ O
while -X- _ O
reserving -X- _ O
important -X- _ O
information, -X- _ O
firstly, -X- _ O
we -X- _ O
perform -X- _ O
Nucleus -X- _ B-MethodName
Sampling -X- _ I-MethodName
(Holtzman -X- _ O
et -X- _ O
al, -X- _ O
2019) -X- _ O
on -X- _ O
M -X- _ O
i -X- _ O
to -X- _ O
get -X- _ O
the -X- _ O
top-p -X- _ O
portion -X- _ O
of -X- _ O
the -X- _ O
probability -X- _ O
mass -X- _ O
in -X- _ O
each -X- _ O
attention -X- _ O
score -X- _ O
map -X- _ O
(p -X- _ B-HyperparameterName
is -X- _ O
a -X- _ O
pre-defined -X- _ O
hyper-parameter -X- _ O
in -X- _ O
the -X- _ O
range -X- _ O
of -X- _ O
(0, -X- _ O
1]). -X- _ O

AdamW -X- _ B-HyperparameterValue
was -X- _ O
used -X- _ O
as -X- _ O
optimizer -X- _ B-HyperparameterName
for -X- _ O
both -X- _ O
models -X- _ O
with -X- _ O
same -X- _ O
weight -X- _ B-HyperparameterName
decay -X- _ I-HyperparameterName
of -X- _ O
0.01 -X- _ B-HyperparameterValue
but -X- _ O
learning -X- _ B-HyperparameterName
rates -X- _ I-HyperparameterName
2e -X- _ B-HyperparameterValue
−05 -X- _ I-HyperparameterValue
and -X- _ O
2e -X- _ B-HyperparameterValue
−05 -X- _ I-HyperparameterValue
respectively -X- _ O
for -X- _ O
Bert-itpt -X- _ B-MethodName
and -X- _ O
XLnet-large. -X- _ B-MethodName

We -X- _ O
fine-tune -X- _ O
a -X- _ O
language -X- _ O
model -X- _ O
on -X- _ O
a -X- _ O
dataset -X- _ O
heuristically-labeled -X- _ O
with -X- _ O
author -X- _ O
intent, -X- _ O
which -X- _ O
allows -X- _ O
IGA -X- _ B-MethodName
to -X- _ O
fill -X- _ O
in -X- _ O
these -X- _ O
tags -X- _ O
with -X- _ O
generated -X- _ O
text -X- _ O
that -X- _ O
users -X- _ O
can -X- _ O
subsequently -X- _ O
edit -X- _ O
to -X- _ O
their -X- _ O
liking. -X- _ O

Following -X- _ O
Chang -X- _ O
et -X- _ O
al -X- _ O
(2020), -X- _ O
given -X- _ O
a -X- _ O
BART -X- _ B-MethodName
model -X- _ O
and -X- _ O
an -X- _ O
input, -X- _ O
we -X- _ O
extract -X- _ O
ranked -X- _ O
triples -X- _ O
related -X- _ O
to -X- _ O
the -X- _ O
input -X- _ O
post -X- _ O
and -X- _ O
keep -X- _ O
the -X- _ O
top -X- _ O
k -X- _ O
triples -X- _ O
per -X- _ O
post -X- _ O
where -X- _ O
we -X- _ O
vary -X- _ O
the -X- _ O
k -X- _ B-HyperparameterName
∈ -X- _ O
{3, -X- _ B-HyperparameterValue
5, -X- _ B-HyperparameterValue
10, -X- _ B-HyperparameterValue
15, -X- _ B-HyperparameterValue
20, -X- _ B-HyperparameterValue
25}. -X- _ B-HyperparameterValue
We -X- _ O
experiment -X- _ O
with -X- _ O
both -X- _ O
concatenation -X- _ O
and -X- _ O
attention -X- _ O
based -X- _ O
methods -X- _ O
to -X- _ O
incorporate -X- _ O
the -X- _ O
top -X- _ O
k -X- _ O
triples, -X- _ O
but -X- _ O
settle -X- _ O
on -X- _ O
a -X- _ O
concatenation -X- _ O
based -X- _ O
approach -X- _ O
due -X- _ O
to -X- _ O
its -X- _ O
simplicity -X- _ O
and -X- _ O
the -X- _ O
lack -X- _ O
of -X- _ O
performance -X- _ O
gains -X- _ O
from -X- _ O
the -X- _ O
attention -X- _ O
based -X- _ O
approach. -X- _ O

Experimental -X- _ O
results -X- _ O
have -X- _ O
shown -X- _ O
that -X- _ O
our -X- _ O
proposed -X- _ O
method -X- _ O
significantly -X- _ O
outperforms -X- _ O
strong -X- _ O
baselines -X- _ O
on -X- _ O
two -X- _ O
public -X- _ O
role-oriented -X- _ B-TaskName
dialogue -X- _ I-TaskName
summarization -X- _ I-TaskName
datasets. -X- _ O

As -X- _ O
parallel -X- _ O
data -X- _ O
for -X- _ O
training -X- _ O
our -X- _ O
NMT -X- _ B-MethodName
systems, -X- _ O
we -X- _ O
used -X- _ O
all -X- _ O
the -X- _ O
parallel -X- _ O
data -X- _ O
provided -X- _ O
for -X- _ O
the -X- _ O
shared -X- _ O
translation -X- _ B-TaskName
tasks -X- _ O
of -X- _ O
WMT19 -X- _ B-DatasetName
1 -X- _ I-DatasetName
for -X- _ O
English-German -X- _ O
(en-de), -X- _ O
excluding -X- _ O
the -X- _ O
Paracrawl -X- _ O
corpus, -X- _ O
and -X- _ O
WMT15 -X- _ B-DatasetName
2 -X- _ I-DatasetName
for -X- _ O
English-French -X- _ O
(en-fr). -X- _ O

Our -X- _ O
experimental -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
a -X- _ O
good -X- _ O
retriever -X- _ O
can -X- _ O
significantly -X- _ O
improve -X- _ O
the -X- _ O
reader's -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ B-DatasetName
OK-VQA -X- _ I-DatasetName
challenge. -X- _ O

On -X- _ O
top -X- _ O
of -X- _ O
that, -X- _ O
Soft-Label -X- _ B-MethodName
Chain -X- _ I-MethodName
CRF -X- _ I-MethodName
improves -X- _ O
accuracy -X- _ B-MetricName
by -X- _ O
another -X- _ O
0.40%, -X- _ B-MetricValue
which -X- _ O
shows -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
treating -X- _ B-TaskName
phrase -X- _ I-TaskName
grounding -X- _ I-TaskName
as -X- _ O
a -X- _ O
sequence -X- _ B-TaskName
labeling -X- _ I-TaskName
task -X- _ O
and -X- _ O
using -X- _ O
CRFs -X- _ B-MethodName
to -X- _ O
capture -X- _ O
entity -X- _ O
dependencies. -X- _ O

We -X- _ O
can -X- _ O
see -X- _ O
that -X- _ O
the -X- _ O
size -X- _ B-HyperparameterName
is -X- _ O
the -X- _ O
main -X- _ O
factors -X- _ O
for -X- _ O
performance -X- _ O
improvements -X- _ O
at -X- _ O
the -X- _ O
beginning: -X- _ O
every -X- _ O
5,000 -X- _ O
additional -X- _ O
instances -X- _ O
can -X- _ O
result -X- _ O
in -X- _ O
a -X- _ O
significant -X- _ O
improvement -X- _ O
(about -X- _ O
2 -X- _ B-MetricValue
to -X- _ O
3 -X- _ B-MetricValue
F1 -X- _ B-MetricName
gain). -X- _ O

order -X- _ O
to -X- _ O
address -X- _ O
the -X- _ O
position -X- _ O
bias -X- _ O
of -X- _ O
news -X- _ O
articles, -X- _ O
Narayan -X- _ O
et -X- _ O
al -X- _ O
(2018a) -X- _ O
collected -X- _ O
a -X- _ O
new -X- _ O
dataset -X- _ O
called -X- _ B-DatasetName
XSum -X- _ I-DatasetName
to -X- _ O
create -X- _ O
single -X- _ B-TaskName
sentence -X- _ I-TaskName
summaries -X- _ I-TaskName
that -X- _ O
include -X- _ O
material -X- _ O
from -X- _ O
multiple -X- _ O
positions -X- _ O
in -X- _ O
the -X- _ O
source -X- _ O
document. -X- _ O

For -X- _ O
STC, -X- _ B-DatasetName
we -X- _ O
utilize -X- _ O
the -X- _ O
Chinese -X- _ O
word -X- _ O
as -X- _ O
input, -X- _ O
and -X- _ O
set -X- _ O
the -X- _ O
vocabulary -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
as -X- _ O
10,599. -X- _ B-HyperparameterValue
For -X- _ O
Reddit, -X- _ B-DatasetName
context-response -X- _ O
pairs -X- _ O
are -X- _ O
encoded -X- _ O
using -X- _ O
byte-pair -X- _ B-MethodName
encoding(BPE) -X- _ I-MethodName
(Sennrich -X- _ O
et -X- _ O
al, -X- _ O
2016) -X- _ O
with -X- _ O
vocabularies -X- _ B-HyperparameterName
of -X- _ O
11,527 -X- _ B-HyperparameterValue
tokens. -X- _ O

In -X- _ O
this -X- _ O
work, -X- _ O
we -X- _ O
broaden -X- _ O
the -X- _ O
scope -X- _ O
of -X- _ O
the -X- _ O
text -X- _ B-TaskName
plausibility -X- _ I-TaskName
evaluation -X- _ I-TaskName
to -X- _ O
cover -X- _ O
not -X- _ O
only -X- _ O
short -X- _ O
but -X- _ O
also -X- _ O
long -X- _ O
texts -X- _ O
with -X- _ O
more -X- _ O
than -X- _ O
512 -X- _ O
tokens. -X- _ O

Existing -X- _ O
works -X- _ O
on -X- _ O
multimodal -X- _ B-TaskName
affective -X- _ I-TaskName
computing -X- _ I-TaskName
tasks, -X- _ O
such -X- _ O
as -X- _ B-TaskName
emotion -X- _ I-TaskName
recognition, -X- _ I-TaskName
generally -X- _ O
adopt -X- _ O
a -X- _ O
two-phase -X- _ O
pipeline, -X- _ O
first -X- _ O
extracting -X- _ O
feature -X- _ O
representations -X- _ O
for -X- _ O
each -X- _ O
single -X- _ O
modality -X- _ O
with -X- _ O
hand-crafted -X- _ O
algorithms -X- _ O
and -X- _ O
then -X- _ O
performing -X- _ O
end-to-end -X- _ O
learning -X- _ O
with -X- _ O
the -X- _ O
extracted -X- _ O
features. -X- _ O

On -X- _ O
the -X- _ O
other -X- _ O
hand, -X- _ O
to -X- _ O
account -X- _ O
for -X- _ O
data -X- _ O
sparsity, -X- _ O
XL-AMR -X- _ B-MethodName
employs -X- _ O
several -X- _ O
common -X- _ O
techniques -X- _ O
in -X- _ O
English -X- _ B-TaskName
AMR -X- _ I-TaskName
parsing -X- _ I-TaskName
literature -X- _ O
(Konstas -X- _ O
et -X- _ O
al, -X- _ O
2017;, -X- _ O
such -X- _ O
as -X- _ O
anonymization -X- _ O
and -X- _ O
recategorization, -X- _ O
expanding -X- _ O
them -X- _ O
across -X- _ O
languages -X- _ O
by -X- _ O
relying -X- _ O
on -X- _ O
multilingual -X- _ O
resources. -X- _ O

Training -X- _ O
for -X- _ O
a -X- _ O
fixed -X- _ O
number -X- _ O
of -X- _ O
10 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
and -X- _ O
stopping -X- _ O
when -X- _ O
the -X- _ O
minimum -X- _ O
mixed -X- _ O
loss -X- _ O
perform -X- _ O
best, -X- _ O
yielding -X- _ O
comparable -X- _ O
accuracies -X- _ B-MetricName
of -X- _ O
91.75% -X- _ B-MetricValue
and -X- _ O
91.73% -X- _ B-MetricValue
respectively. -X- _ O

After -X- _ O
fine-tuning -X- _ O
with -X- _ O
as -X- _ O
little -X- _ O
as -X- _ O
20% -X- _ O
of -X- _ O
the -X- _ O
labelled -X- _ O
data, -X- _ O
we -X- _ O
also -X- _ O
outperform -X- _ O
BioBERT -X- _ B-MethodName
and -X- _ O
ClinicalBERT. -X- _ B-MethodName

Compared -X- _ O
to -X- _ O
English, -X- _ O
these -X- _ O
are -X- _ O
languages -X- _ O
with -X- _ O
very -X- _ O
different -X- _ O
morphology -X- _ O
and -X- _ O
syntax, -X- _ O
for -X- _ O
which -X- _ O
little -X- _ O
out-of-domain -X- _ O
parallel -X- _ O
data -X- _ O
is -X- _ O
available -X- _ O
and -X- _ O
for -X- _ O
which -X- _ O
relatively -X- _ O
large -X- _ O
amounts -X- _ O
of -X- _ O
monolingual -X- _ O
data -X- _ O
are -X- _ O
freely -X- _ O
available. -X- _ O

However, -X- _ O
when -X- _ O
we -X- _ O
convert -X- _ O
the -X- _ O
ratings -X- _ O
to -X- _ O
3-point -X- _ O
by -X- _ O
taking -X- _ O
{3}, -X- _ O
{4 -X- _ O
and -X- _ O
5}, -X- _ O
{1 -X- _ O
and -X- _ O
2} -X- _ O
as -X- _ O
3 -X- _ O
classes, -X- _ O
the -X- _ O
agreement -X- _ B-MetricName
increases -X- _ O
to -X- _ O
0.36 -X- _ B-MetricValue
to -X- _ O
0.63, -X- _ B-MetricValue
i.e., -X- _ O
fair -X- _ O
to -X- _ O
substantial -X- _ O
agreement. -X- _ O

They -X- _ O
are -X- _ O
extracted -X- _ O
by -X- _ O
a -X- _ O
Faster -X- _ B-MethodName
R- -X- _ I-MethodName
CNN -X- _ I-MethodName
(Ren -X- _ O
et -X- _ O
al, -X- _ O
2015) -X- _ O
object -X- _ O
detector -X- _ O
pre-trained -X- _ O
on -X- _ B-DatasetName
Visual -X- _ I-DatasetName
Genome -X- _ I-DatasetName
dataset -X- _ O
(Krishna -X- _ O
et -X- _ O
al, -X- _ O
2017). -X- _ O

First, -X- _ O
these -X- _ O
language -X- _ O
pairs -X- _ O
are -X- _ O
very -X- _ O
difficult, -X- _ O
as -X- _ O
even -X- _ O
supervised -X- _ O
NMT -X- _ B-MethodName
baselines -X- _ O
achieve -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
less -X- _ B-MetricValue
than -X- _ I-MetricValue
8. -X- _ I-MetricValue

In -X- _ O
this -X- _ O
paper, -X- _ O
we -X- _ O
present -X- _ O
a -X- _ O
new -X- _ O
multilingual -X- _ O
multi-aspect -X- _ O
hate -X- _ O
speech -X- _ O
analysis -X- _ O
dataset -X- _ O
and -X- _ O
use -X- _ O
it -X- _ O
to -X- _ O
test -X- _ O
the -X- _ O
current -X- _ O
state-of-the-art -X- _ O
multilingual -X- _ B-TaskName
multitask -X- _ I-TaskName
learning -X- _ I-TaskName
approaches. -X- _ O

Previous -X- _ O
work -X- _ O
suggests -X- _ O
that -X- _ O
BLEU-4 -X- _ B-MetricName
fails -X- _ O
to -X- _ O
accurately -X- _ O
capture -X- _ O
performance -X- _ O
for -X- _ O
tasks -X- _ O
related -X- _ O
to -X- _ O
edits, -X- _ O
such -X- _ O
as -X- _ B-TaskName
text -X- _ I-TaskName
simplification -X- _ I-TaskName
(Xu -X- _ O
et -X- _ O
al, -X- _ O
2016), -X- _ B-TaskName
grammatical -X- _ I-TaskName
error -X- _ I-TaskName
correction -X- _ I-TaskName
(Napoles -X- _ O
et -X- _ O
al, -X- _ O
2015), -X- _ O
and -X- _ O
style -X- _ B-TaskName
transfer -X- _ I-TaskName
(Sudhakar -X- _ O
et -X- _ O
al, -X- _ O
2019), -X- _ O
since -X- _ O
a -X- _ O
system -X- _ O
that -X- _ O
merely -X- _ O
copies -X- _ O
the -X- _ O
input -X- _ O
text -X- _ O
often -X- _ O
achieves -X- _ O
a -X- _ O
high -X- _ O
score. -X- _ O

Our -X- _ O
model -X- _ O
outperforms -X- _ O
competitive -X- _ O
baselines -X- _ O
on -X- _ O
the -X- _ O
PERSONA-CHAT -X- _ B-DatasetName
dataset -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
dialog -X- _ O
quality -X- _ O
and -X- _ O
diversity -X- _ O
while -X- _ O
achieving -X- _ O
persona-consistent -X- _ O
and -X- _ O
controllable -X- _ O
dialog -X- _ O
generation. -X- _ O

(1: -X- _ B-MetricValue
select, -X- _ O
0: -X- _ B-MetricValue
delete) -X- _ O
Figure -X- _ O
1: -X- _ O
Different -X- _ O
from -X- _ O
the -X- _ O
previous -X- _ O
work, -X- _ O
DIS-COBERT -X- _ B-MethodName
(Xu -X- _ O
et -X- _ O
al, -X- _ O
2020), -X- _ O
NeRoBERTa -X- _ B-MethodName
selects -X- _ O
sentences -X- _ O
by -X- _ O
considering -X- _ O
both -X- _ O
intra-and -X- _ O
inter-sentence -X- _ O
relationships -X- _ O
as -X- _ O
a -X- _ O
nested -X- _ O
tree -X- _ O
structure. -X- _ O
still -X- _ O
difficult -X- _ O
to -X- _ O
construct -X- _ O
a -X- _ O
coherent -X- _ O
summary -X- _ O
compared -X- _ O
to -X- _ O
BERTSUM -X- _ B-MethodName
in -X- _ O
human -X- _ B-MetricName
evaluation. -X- _ I-MetricName

We -X- _ O
highlight -X- _ O
that -X- _ O
our -X- _ O
single -X- _ O
model -X- _ O
with -X- _ O
356M -X- _ B-HyperparameterValue
parameters -X- _ O
(without -X- _ O
any -X- _ O
ensemble) -X- _ O
can -X- _ O
achieve -X- _ O
three -X- _ O
state-of-the-art -X- _ O
results -X- _ O
on -X- _ B-DatasetName
GLUE, -X- _ I-DatasetName
even -X- _ O
compared -X- _ O
with -X- _ O
all -X- _ O
existing -X- _ O
ensemble -X- _ O
models -X- _ O
and -X- _ O
the -X- _ O
T5 -X- _ B-MethodName
model -X- _ O
(Raffel -X- _ O
et -X- _ O
al, -X- _ O
2019), -X- _ O
which -X- _ O
contains -X- _ O
11 -X- _ O
billion -X- _ O
parameters. -X- _ O

The -X- _ O
input -X- _ O
to -X- _ O
CHEMNER -X- _ B-MethodName
includes -X- _ O
two -X- _ O
parts: -X- _ O
(1) -X- _ O
a -X- _ O
chemistry -X- _ O
literature -X- _ O
corpus, -X- _ O
and -X- _ O
(2) -X- _ O
a -X- _ O
fine-grained -X- _ O
chemistry -X- _ O
type -X- _ O
ontology -X- _ O
and -X- _ O
associated -X- _ O
entity -X- _ O
dictionaries -X- _ O
for -X- _ O
each -X- _ O
type. -X- _ O

Both -X- _ O
have -X- _ O
multi-class -X- _ O
and -X- _ O
multi-labelled -X- _ O
data -X- _ O
for -X- _ O
multimodal -X- _ B-TaskName
emotion -X- _ I-TaskName
recognition -X- _ I-TaskName
obtained -X- _ O
by -X- _ O
generating -X- _ O
raw -X- _ O
utterance-level -X- _ O
data, -X- _ O
aligning -X- _ O
the -X- _ O
three -X- _ O
modalities, -X- _ O
and -X- _ O
creating -X- _ O
a -X- _ O
new -X- _ O
split -X- _ O
over -X- _ O
the -X- _ O
aligned -X- _ O
data. -X- _ O

For -X- _ O
humor -X- _ O
classification, -X- _ O
we -X- _ O
use -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
128 -X- _ B-HyperparameterValue
and -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
epochs -X- _ I-HyperparameterName
is -X- _ O
set -X- _ O
to -X- _ O
2 -X- _ O
with -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
3e -X- _ B-HyperparameterValue
−5 -X- _ I-HyperparameterValue
. -X- _ O

Pre-training -X- _ O
Corpus -X- _ O
Construction. -X- _ O
When -X- _ O
we -X- _ O
prepare -X- _ O
the -X- _ O
QA -X- _ B-TaskName
pre-training -X- _ O
corpus, -X- _ O
data -X- _ O
sparsity -X- _ O
problem -X- _ O
is -X- _ O
extremely -X- _ O
severe -X- _ O
because -X- _ O
(1) -X- _ O
it -X- _ O
is -X- _ O
impractical -X- _ O
and -X- _ O
laborious -X- _ O
to -X- _ O
obtain -X- _ O
a -X- _ O
large-scale -X- _ O
highquality -X- _ O
annotated -X- _ O
data -X- _ O
for -X- _ O
pre-training -X- _ O
and -X- _ O
(2) -X- _ O
it -X- _ O
is -X- _ O
hard -X- _ O
to -X- _ O
generate -X- _ O
QA-centric -X- _ O
self-supervised -X- _ O
data -X- _ O
using -X- _ O
rule-based -X- _ O
methods -X- _ O
(e.g., -X- _ O
token -X- _ O
masking -X- _ O
or -X- _ O
sentence -X- _ O
reordering). -X- _ O

We -X- _ O
also -X- _ O
initially -X- _ O
considered -X- _ O
some -X- _ O
very -X- _ O
interesting -X- _ O
legal -X- _ B-TaskName
Information -X- _ I-TaskName
Retrieval -X- _ I-TaskName
(IR) -X- _ O
datasets -X- _ O
(Locke -X- _ O
and -X- _ O
Zuccon, -X- _ O
2018;Chalkidis -X- _ O
et -X- _ O
al, -X- _ O
2021b) -X- _ O
that -X- _ O
aim -X- _ O
to -X- _ O
examine -X- _ O
crucial -X- _ O
real-life -X- _ O
tasks -X- _ O
(relevant -X- _ O
case -X- _ O
law -X- _ O
retrieval, -X- _ O
regulatory -X- _ O
compliance). -X- _ O

Then, -X- _ O
we -X- _ O
fine-tune -X- _ O
on -X- _ O
MNLI -X- _ B-DatasetName
(Williams -X- _ O
et -X- _ O
al, -X- _ O
2018) -X- _ O
and -X- _ O
SQuAD(v1.1 -X- _ B-DatasetName
and -X- _ O
v2.0) -X- _ O
(Rajpurkar -X- _ O
et -X- _ O
al, -X- _ O
2016(Rajpurkar -X- _ O
et -X- _ O
al, -X- _ O
, -X- _ O
2018. -X- _ O

In -X- _ O
order -X- _ O
to -X- _ O
evaluate -X- _ O
our -X- _ O
setup, -X- _ O
we -X- _ O
consider -X- _ O
the -X- _ O
application -X- _ O
of -X- _ O
the -X- _ O
above -X- _ O
framework -X- _ O
to -X- _ O
two -X- _ O
binary -X- _ B-TaskName
text -X- _ I-TaskName
classification -X- _ I-TaskName
tasks: -X- _ O
formality -X- _ B-TaskName
classification -X- _ I-TaskName
and -X- _ B-TaskName
sarcasm -X- _ I-TaskName
detection. -X- _ I-TaskName

We -X- _ O
perform -X- _ O
our -X- _ O
experiments -X- _ O
on -X- _ O
standard -X- _ O
datasets -X- _ O
FB15K -X- _ B-DatasetName
(Bordes -X- _ O
et -X- _ O
al, -X- _ O
2013), -X- _ O
FB15K-237 -X- _ B-DatasetName
(Toutanova -X- _ O
et -X- _ O
al, -X- _ O
2015), -X- _ O
YAGO3-10 -X- _ B-DatasetName
(Dettmers -X- _ O
et -X- _ O
al, -X- _ O
2018), -X- _ O
and -X- _ O
on -X- _ O
a -X- _ O
new -X- _ O
large-scale -X- _ O
dataset -X- _ O
FB1.9M -X- _ B-DatasetName
which -X- _ O
we -X- _ O
construced -X- _ O
from -X- _ O
FB3M -X- _ B-DatasetName
(Xu -X- _ O
and -X- _ O
Barbosa, -X- _ O
2018). -X- _ O

Additionally, -X- _ O
some -X- _ O
terms -X- _ O
(cancer) -X- _ O
are -X- _ O
ambiguous -X- _ O
and -X- _ O
could -X- _ O
refer -X- _ O
to -X- _ O
multiple -X- _ O
concepts -X- _ O
(breast -X- _ O
cancer, -X- _ O
colon -X- _ O
cancer, -X- _ O
etc.) -X- _ O
The -X- _ O
related -X- _ O
task -X- _ O
of -X- _ O
Entity -X- _ B-TaskName
Linking -X- _ I-TaskName
-linking -X- _ O
named -X- _ O
entities -X- _ O
(people, -X- _ O
places, -X- _ O
and -X- _ O
organizations) -X- _ O
to -X- _ O
a -X- _ O
knowledge -X- _ O
base -X- _ O
-has -X- _ O
been -X- _ O
explored -X- _ O
in -X- _ O
nonmedical -X- _ O
domains -X- _ O
(Dredze -X- _ O
et -X- _ O
al, -X- _ O
2010;Durrett -X- _ O
and -X- _ O
Klein, -X- _ O
2014;Gupta -X- _ O
et -X- _ O
al, -X- _ O
2017). -X- _ O

On -X- _ O
the -X- _ O
backend, -X- _ O
the -X- _ O
input -X- _ O
fed -X- _ O
to -X- _ O
our -X- _ O
IGA -X- _ B-MethodName
model -X- _ O
is -X- _ O
the -X- _ O
concatenation -X- _ O
of -X- _ O
content -X- _ O
in -X- _ O
the -X- _ O
main -X- _ O
textbox -X- _ O
(i.e., -X- _ O
context) -X- _ O
and -X- _ O
the -X- _ O
input -X- _ O
in -X- _ O
the -X- _ O
assistant -X- _ O
box, -X- _ O
truncated -X- _ O
at -X- _ O
300 -X- _ B-HyperparameterValue
tokens. -X- _ B-HyperparameterName

Knowledge-graph -X- _ B-TaskName
question -X- _ I-TaskName
answering -X- _ I-TaskName
(KGQA) -X- _ O
is -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
answering -X- _ O
questions -X- _ O
regarding -X- _ O
facts -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
inferred/retrieved -X- _ O
from -X- _ O
a -X- _ O
KG -X- _ O
given -X- _ O
the -X- _ O
question, -X- _ O
image -X- _ O
and -X- _ O
the -X- _ O
graph. -X- _ O

Because -X- _ B-DatasetName
DROP -X- _ I-DatasetName
uses -X- _ O
only -X- _ O
a -X- _ O
single -X- _ O
paragraph -X- _ O
of -X- _ O
context, -X- _ O
we -X- _ O
add -X- _ O
a -X- _ O
two-stage -X- _ O
pipeline -X- _ O
to -X- _ O
retrieve -X- _ O
necessary -X- _ O
context -X- _ O
for -X- _ O
the -X- _ O
model -X- _ O
from -X- _ O
the -X- _ O
linked -X- _ O
articles. -X- _ O

The -X- _ O
argument-wise -X- _ B-MetricName
annotation -X- _ I-MetricName
accuracy -X- _ I-MetricName
for -X- _ O
each -X- _ O
label -X- _ O
is -X- _ O
calculated -X- _ O
by -X- _ O
n -X- _ O
i=1 -X- _ O
#Arg -X- _ O
l -X- _ O
correct -X- _ O
i -X- _ O
2×#Arg -X- _ O
l -X- _ O
gold -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
numerator -X- _ O
is -X- _ O
the -X- _ O
sum -X- _ O
of -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
correctly -X- _ O
annotated -X- _ O
arguments -X- _ O
with -X- _ O
the -X- _ O
concerned -X- _ O
label -X- _ O
l -X- _ O
submitted -X- _ O
by -X- _ O
all -X- _ O
annotators, -X- _ O
the -X- _ O
denominator -X- _ O
is -X- _ O
the -X- _ O
total -X- _ O
number -X- _ O
of -X- _ O
all -X- _ O
gold -X- _ O
arguments -X- _ O
with -X- _ O
the -X- _ O
concerned -X- _ O
label -X- _ O
l; -X- _ O
n -X- _ O
is -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
annotators. -X- _ O

We -X- _ O
release -X- _ O
XL-AMR -X- _ B-MethodName
at -X- _ O
github.com/SapienzaNLP/xlamr. -X- _ O

We -X- _ O
set -X- _ O
the -X- _ O
dimensions -X- _ B-HyperparameterName
of -X- _ O
the -X- _ O
word -X- _ O
embeddings -X- _ O
to -X- _ O
300, -X- _ B-MetricValue
the -X- _ O
vocabulary -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
to -X- _ O
50k, -X- _ B-HyperparameterValue
the -X- _ O
hidden -X- _ B-MetricName
di- -X- _ I-MetricName
mensions -X- _ I-MetricName
to -X- _ O
256, -X- _ B-HyperparameterValue
the -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
to -X- _ O
8, -X- _ B-HyperparameterValue
and -X- _ O
dropout -X- _ B-HyperparameterName
(Srivastava -X- _ O
et -X- _ O
al, -X- _ O
2014) -X- _ O
to -X- _ O
0.1. -X- _ B-HyperparameterValue
For -X- _ O
our -X- _ O
discriminator, -X- _ O
we -X- _ O
employed -X- _ O
an -X- _ O
LDA -X- _ B-MethodName
topic -X- _ O
model -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
review -X- _ O
corpus, -X- _ O
with -X- _ O
50 -X- _ O
(Rotten -X- _ O
Tomatoes) -X- _ O
and -X- _ O
100 -X- _ O
(Yelp) -X- _ O
topics -X- _ O
(tuned -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
set). -X- _ O

We -X- _ O
train -X- _ O
Electric -X- _ B-MethodName
using -X- _ O
an -X- _ O
algorithm -X- _ O
based -X- _ O
on -X- _ O
noise-contrastive -X- _ O
estimation -X- _ O
and -X- _ O
elucidate -X- _ O
how -X- _ O
this -X- _ O
learning -X- _ O
objective -X- _ O
is -X- _ O
closely -X- _ O
related -X- _ O
to -X- _ O
the -X- _ O
recently -X- _ O
proposed -X- _ O
ELECTRA -X- _ B-MethodName
pre-training -X- _ O
method. -X- _ O

On -X- _ O
DenseNet-161, -X- _ B-MethodName
we -X- _ O
observe -X- _ O
a -X- _ O
failure -X- _ O
mode -X- _ O
for -X- _ O
CW -X- _ O
(Figure -X- _ O
8c) -X- _ O
due -X- _ O
to -X- _ O
low -X- _ O
accuracy -X- _ B-MetricName
on -X- _ O
the -X- _ O
upstream -X- _ O
task -X- _ O
(Table -X- _ O
16). -X- _ O

PreCo -X- _ B-DatasetName
(Chen -X- _ O
et -X- _ O
al, -X- _ O
2018) -X- _ O
is -X- _ O
a -X- _ O
dataset -X- _ O
consisting -X- _ O
of -X- _ B-TaskName
reading -X- _ I-TaskName
comprehension -X- _ I-TaskName
passages -X- _ O
used -X- _ O
in -X- _ O
test -X- _ O
questions. -X- _ O

We -X- _ O
observe -X- _ O
a -X- _ O
similar -X- _ O
phenomenon -X- _ O
in -X- _ O
multi-hop -X- _ B-TaskName
question -X- _ I-TaskName
answering -X- _ I-TaskName
(QA) -X- _ O
model -X- _ O
(Yang -X- _ O
et -X- _ O
al, -X- _ O
2018), -X- _ O
where -X- _ O
a -X- _ O
non-target -X- _ O
span -X- _ O
extraction -X- _ O
head -X- _ O
outputs -X- _ O
supporting -X- _ O
evidence -X- _ O
for -X- _ O
the -X- _ O
answer -X- _ O
predicted -X- _ O
by -X- _ O
a -X- _ O
classification -X- _ O
head -X- _ O
(Figure -X- _ O
2, -X- _ O
center). -X- _ O

Under -X- _ O
the -X- _ O
constraints -X- _ O
of -X- _ O
Section -X- _ O
4, -X- _ O
we -X- _ O
repeat -X- _ O
the -X- _ O
experiment -X- _ O
using -X- _ O
encoders -X- _ O
based -X- _ O
on -X- _ O
VGG-16 -X- _ B-MethodName
(Figure -X- _ O
9) -X- _ O
and -X- _ O
DenseNet-161 -X- _ B-MethodName
(Figure -X- _ O
10). -X- _ O

Our -X- _ O
work -X- _ O
is -X- _ O
different: -X- _ O
(1) -X- _ O
Conceptually, -X- _ O
SPLA -X- _ B-MethodName
and -X- _ O
SPRE -X- _ B-MethodName
are -X- _ O
related -X- _ O
but -X- _ O
different -X- _ O
from -X- _ O
novelty, -X- _ O
(2) -X- _ O
they -X- _ O
are -X- _ O
mostly -X- _ O
based -X- _ O
on -X- _ O
structured -X- _ O
Subject-Verb-Object -X- _ O
triples, -X- _ O
rather -X- _ O
than -X- _ O
natural -X- _ O
language -X- _ O
sentences, -X- _ O
and -X- _ O
(3) -X- _ O
they -X- _ O
use -X- _ O
fully -X- _ O
labeled -X- _ O
data -X- _ O
(Dasigi -X- _ O
and -X- _ O
Hovy, -X- _ O
2014) -X- _ O
while -X- _ O
we -X- _ O
do -X- _ O
novelty -X- _ O
detection -X- _ O
with -X- _ O
only -X- _ O
normal -X- _ O
data -X- _ O
in -X- _ O
training. -X- _ O

Table -X- _ O
5 -X- _ O
shows -X- _ O
the -X- _ O
averaged -X- _ O
CBOW, -X- _ B-MetricName
SGNS, -X- _ B-MetricName
and -X- _ O
GloVe -X- _ B-MetricName
scores -X- _ O
for -X- _ O
different -X- _ O
vector -X- _ O
dimensions, -X- _ O
50, -X- _ B-HyperparameterValue
100, -X- _ B-HyperparameterValue
200, -X- _ B-HyperparameterValue
and -X- _ O
300. -X- _ B-HyperparameterValue

It -X- _ O
provides -X- _ O
machine -X- _ O
translations -X- _ O
of -X- _ O
only -X- _ O
the -X- _ B-DatasetName
MultiNLI -X- _ I-DatasetName
training -X- _ O
set, -X- _ O
so -X- _ O
we -X- _ O
report -X- _ O
comparisons -X- _ O
with -X- _ O
just -X- _ O
the -X- _ O
corresponding -X- _ O
section -X- _ O
of -X- _ O
NLI-TR, -X- _ B-DatasetName
and -X- _ O
we -X- _ O
train -X- _ O
models -X- _ O
only -X- _ O
on -X- _ O
these -X- _ O
two -X- _ O
training -X- _ O
sets. -X- _ O

We -X- _ O
conduct -X- _ O
experiments -X- _ O
on -X- _ O
five -X- _ O
aspectbased -X- _ B-TaskName
sentiment -X- _ I-TaskName
datasets, -X- _ O
and -X- _ O
the -X- _ O
proposed -X- _ O
model -X- _ O
significantly -X- _ O
outperforms -X- _ O
recent -X- _ O
strong -X- _ O
baselines. -X- _ O

Future -X- _ O
work -X- _ O
involves -X- _ O
extending -X- _ O
the -X- _ O
SUM-QE -X- _ B-MethodName
model -X- _ O
to -X- _ O
capture -X- _ O
content-related -X- _ O
aspects, -X- _ O
either -X- _ O
in -X- _ O
combination -X- _ O
with -X- _ O
existing -X- _ O
eval-Figure -X- _ O
3: -X- _ O
Comparison -X- _ O
of -X- _ O
the -X- _ O
mean -X- _ O
gold -X- _ O
scores -X- _ O
assigned -X- _ O
for -X- _ O
Q2 -X- _ O
and -X- _ O
Q3 -X- _ O
to -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
32 -X- _ O
systems -X- _ O
in -X- _ O
the -X- _ O
DUC-05 -X- _ B-MethodName
dataset, -X- _ O
and -X- _ O
the -X- _ O
corresponding -X- _ O
scores -X- _ O
predicted -X- _ O
by -X- _ O
SUM-QE. -X- _ B-MethodName

For -X- _ B-TaskName
sentiment -X- _ I-TaskName
analysis, -X- _ I-TaskName
BERT-PT -X- _ B-MethodName
(Xu -X- _ O
et -X- _ O
al, -X- _ O
2019) -X- _ O
conducts -X- _ O
post-training -X- _ O
on -X- _ O
the -X- _ O
corpora -X- _ O
which -X- _ O
belong -X- _ O
to -X- _ O
the -X- _ O
same -X- _ O
domain -X- _ O
of -X- _ O
the -X- _ O
downstream -X- _ O
tasks -X- _ O
to -X- _ O
benefit -X- _ O
aspect-level -X- _ O
sentiment -X- _ O
analysis. -X- _ O

Therefore -X- _ O
in -X- _ O
the -X- _ O
inference -X- _ O
stage, -X- _ O
for -X- _ O
each -X- _ O
bridging -X- _ O
anaphor -X- _ O
a, -X- _ O
we -X- _ O
first -X- _ O
identify -X- _ O
the -X- _ O
position -X- _ O
of -X- _ O
a -X- _ O
in -X- _ O
its -X- _ O
context -X- _ O
c -X- _ O
a -X- _ O
, -X- _ O
then -X- _ O
we -X- _ O
only -X- _ O
predict -X- _ O
text -X- _ O
spans -X- _ O
which -X- _ O
appear -X- _ O
before -X- _ O
a. -X- _ O
We -X- _ O
further -X- _ O
prune -X- _ O
the -X- _ O
list -X- _ O
of -X- _ O
predicted -X- _ O
text -X- _ O
spans -X- _ O
by -X- _ O
only -X- _ O
keeping -X- _ O
the -X- _ O
top -X- _ O
k -X- _ B-HyperparameterName
span -X- _ O
candidates -X- _ O
that -X- _ O
contain -X- _ O
at -X- _ O
most -X- _ O
l -X- _ B-HyperparameterName
words -X- _ O
(k -X- _ B-HyperparameterName
and -X- _ O
l -X- _ B-HyperparameterName
are -X- _ O
empirically -X- _ O
set -X- _ O
to -X- _ O
20 -X- _ B-HyperparameterValue
and -X- _ O
5, -X- _ B-HyperparameterValue
respectively). -X- _ O

The -X- _ O
existing -X- _ O
multimodal -X- _ B-TaskName
emotion -X- _ I-TaskName
recognition -X- _ I-TaskName
datasets -X- _ O
cannot -X- _ O
be -X- _ O
directly -X- _ O
applied -X- _ O
for -X- _ O
the -X- _ O
fully -X- _ O
end-to-end -X- _ O
training -X- _ O
for -X- _ O
two -X- _ O
main -X- _ O
reasons. -X- _ O

γ -X- _ O
q -X- _ O
achieves -X- _ O
a -X- _ O
macro -X- _ B-MetricName
F1 -X- _ I-MetricName
score -X- _ O
of -X- _ O
0.80 -X- _ B-MetricValue
on -X- _ O
a -X- _ O
reserved -X- _ O
test -X- _ O
set, -X- _ O
with -X- _ O
data -X- _ O
splits -X- _ O
detailed -X- _ O
in -X- _ O
Appendix -X- _ O
B. -X- _ O
To -X- _ O
train -X- _ O
γ -X- _ O
a -X- _ O
, -X- _ O
in -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
annotated -X- _ O
questions, -X- _ O
we -X- _ O
run -X- _ O
γ -X- _ O
q -X- _ O
on -X- _ O
unlabeled -X- _ O
questions -X- _ O
in -X- _ O
Reddit -X- _ O
and -X- _ O
Yahoo -X- _ O
and -X- _ O
include -X- _ O
samples -X- _ O
whose -X- _ O
type -X- _ O
prediction -X- _ O
confidence -X- _ B-HyperparameterName
score -X- _ I-HyperparameterName
is -X- _ O
above -X- _ O
0.9. -X- _ B-HyperparameterValue

These -X- _ O
models -X- _ O
are -X- _ O
jointly -X- _ O
optimized -X- _ O
with -X- _ O
the -X- _ O
task-specific -X- _ O
losses -X- _ O
and -X- _ O
are -X- _ O
regularized -X- _ O
to -X- _ O
generate -X- _ O
similar -X- _ O
predictions -X- _ O
based -X- _ O
on -X- _ O
an -X- _ O
agreement -X- _ O
loss, -X- _ O
which -X- _ O
prevents -X- _ O
overfitting -X- _ O
on -X- _ O
noisy -X- _ O
labels. -X- _ O

CoSHC -X- _ B-MethodName
can -X- _ O
retain -X- _ O
at -X- _ O
least -X- _ O
99.2% -X- _ B-MetricValue
of -X- _ O
performance -X- _ O
on -X- _ O
R@1 -X- _ B-MetricName
in -X- _ O
both -X- _ O
datasets, -X- _ O
which -X- _ O
demonstrates -X- _ O
that -X- _ O
CoSHC -X- _ B-MethodName
can -X- _ O
retain -X- _ O
almost -X- _ O
the -X- _ O
same -X- _ O
performance -X- _ O
as -X- _ O
the -X- _ O
original -X- _ O
code -X- _ O
search -X- _ O
model. -X- _ O

Even -X- _ O
without -X- _ O
TAPT, -X- _ B-MethodName
ENG -X- _ B-MethodName
outperforms -X- _ O
all -X- _ O
baselines, -X- _ O
rendering -X- _ O
2 -X- _ B-MetricValue
− -X- _ I-MetricValue
3% -X- _ I-MetricValue
absolute -X- _ O
F1-score -X- _ B-MetricName
improvement. -X- _ O

ROUGE, -X- _ B-MetricName
the -X- _ O
most -X- _ O
used -X- _ O
summarization -X- _ O
metric, -X- _ O
is -X- _ O
known -X- _ O
to -X- _ O
suffer -X- _ O
from -X- _ O
bias -X- _ O
towards -X- _ O
lexical -X- _ O
similarity -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
from -X- _ O
suboptimal -X- _ O
accounting -X- _ O
for -X- _ O
fluency -X- _ O
and -X- _ O
readability -X- _ O
of -X- _ O
the -X- _ O
generated -X- _ O
abstracts. -X- _ O

The -X- _ B-DatasetName
TicketTalk -X- _ I-DatasetName
movie -X- _ O
ticketing -X- _ O
dataset -X- _ O
was -X- _ O
created -X- _ O
using -X- _ O
the -X- _ O
self-dialog -X- _ O
collection -X- _ O
method -X- _ O
(Krause -X- _ O
et -X- _ O
al, -X- _ O
2017;Moghe -X- _ O
et -X- _ O
al, -X- _ O
2018;Byrne -X- _ O
et -X- _ O
al, -X- _ O
2019) -X- _ O
in -X- _ O
which -X- _ O
a -X- _ O
paid -X- _ O
crowd-sourced -X- _ O
worker -X- _ O
writes -X- _ O
both -X- _ O
sides -X- _ O
of -X- _ O
the -X- _ O
dialog -X- _ O
(i.e. -X- _ O
both -X- _ O
customer -X- _ O
and -X- _ O
ticketing -X- _ O
agent -X- _ O
turns) -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
particular -X- _ O
scenario -X- _ O
and -X- _ O
set -X- _ O
of -X- _ O
instructions. -X- _ O

We -X- _ O
first -X- _ O
evaluate -X- _ O
our -X- _ O
supervised -X- _ O
models -X- _ O
on -X- _ O
the -X- _ O
three -X- _ O
supervised -X- _ O
tasks: -X- _ B-TaskName
dialogue -X- _ I-TaskName
generation, -X- _ I-TaskName
movie -X- _ B-TaskName
recommendation, -X- _ I-TaskName
and -X- _ O
per-turn -X- _ B-TaskName
decision -X- _ I-TaskName
to -X- _ I-TaskName
speak -X- _ I-TaskName
or -X- _ I-TaskName
recommend. -X- _ I-TaskName

6 -X- _ O
Phrase -X- _ B-MethodName
Based -X- _ I-MethodName
Statistical -X- _ I-MethodName
Machine -X- _ I-MethodName
Translation -X- _ I-MethodName
(PBSMT) -X- _ B-MethodName
Since -X- _ O
Koehn -X- _ O
and -X- _ O
Knowles -X- _ O
(2017) -X- _ O
report -X- _ O
that -X- _ O
PBSMT -X- _ B-MethodName
models -X- _ O
outperform -X- _ O
vanilla -X- _ O
NMT -X- _ O
models -X- _ O
in -X- _ O
case -X- _ O
of -X- _ O
small -X- _ O
parallel -X- _ O
training -X- _ O
data, -X- _ O
we -X- _ O
use -X- _ O
PBSMT -X- _ B-MethodName
as -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
baselines. -X- _ O

At -X- _ O
prediction -X- _ O
time -X- _ O
we -X- _ O
set -X- _ O
the -X- _ O
size -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
beam -X- _ I-HyperparameterName
search -X- _ I-HyperparameterName
to -X- _ O
5. -X- _ B-HyperparameterValue

We -X- _ O
use -X- _ O
the -X- _ O
BOLT -X- _ B-DatasetName
Egyptian -X- _ I-DatasetName
Arabic -X- _ I-DatasetName
SMS/Chat -X- _ I-DatasetName
and -X- _ I-DatasetName
Transliteration -X- _ I-DatasetName
dataset -X- _ O
(Song -X- _ O
et -X- _ O
al, -X- _ O
2014), -X- _ O
13 -X- _ O
a -X- _ O
collection -X- _ O
of -X- _ O
naturally-occurring -X- _ O
chat -X- _ O
and -X- _ O
short -X- _ O
messages -X- _ O
(SMS) -X- _ O
from -X- _ O
Egyptian -X- _ O
native -X- _ O
speakers. -X- _ O

We -X- _ O
compare -X- _ O
our -X- _ O
proposed -X- _ O
model -X- _ O
with -X- _ O
the -X- _ O
following -X- _ O
baseline -X- _ O
and -X- _ O
state-of-the-art -X- _ O
models: -X- _ O
1) -X- _ O
DTR: -X- _ B-MethodName
A -X- _ B-MethodName
Decision-Tree-based -X- _ I-MethodName
Ranking -X- _ I-MethodName
model -X- _ I-MethodName
(Zhao -X- _ O
et -X- _ O
al, -X- _ O
2015) -X- _ O
that -X- _ O
identifies -X- _ O
trending -X- _ O
rumors -X- _ O
by -X- _ O
searching -X- _ O
for -X- _ O
inquiry -X- _ O
phrases. -X- _ O

We -X- _ O
ran -X- _ O
100 -X- _ B-HyperparameterValue
000 -X- _ I-HyperparameterValue
iterations -X- _ B-HyperparameterName
of -X- _ O
both -X- _ O
methods -X- _ O
on -X- _ O
AP -X- _ B-DatasetName
and -X- _ O
CGCBIB. -X- _ B-DatasetName

Test -X- _ O
bed -X- _ O
We -X- _ O
evaluate -X- _ O
on -X- _ O
the -X- _ O
Abstract -X- _ B-DatasetName
Meaning -X- _ I-DatasetName
Representation -X- _ I-DatasetName
2.0 -X- _ I-DatasetName
-Four -X- _ O
Translations -X- _ O
(Damonte -X- _ O
and -X- _ O
Cohen, -X- _ O
2020), -X- _ O
a -X- _ O
corpus -X- _ O
containing -X- _ O
translations -X- _ O
of -X- _ O
the -X- _ O
test -X- _ O
split -X- _ O
of -X- _ O
1371 -X- _ O
sentences -X- _ O
from -X- _ O
the -X- _ O
LDC2017T10 -X- _ B-DatasetName
(AMR -X- _ B-DatasetName
2.0), -X- _ I-DatasetName
in -X- _ O
Chinese -X- _ O
(ZH), -X- _ O
German -X- _ O
(DE), -X- _ O
Italian -X- _ O
(IT) -X- _ O
and -X- _ O
Spanish -X- _ O
(ES). -X- _ O

We -X- _ O
can -X- _ O
see -X- _ O
that -X- _ O
for -X- _ O
higher -X- _ O
compression -X- _ B-HyperparameterName
factors, -X- _ I-HyperparameterName
KroneckerBERT -X- _ B-MethodName
21 -X- _ O
outperforms -X- _ O
the -X- _ O
baselines -X- _ O
on -X- _ O
all -X- _ O
available -X- _ O
results. -X- _ O

During -X- _ O
inference, -X- _ O
we -X- _ O
set -X- _ O
the -X- _ O
beam -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
to -X- _ O
4 -X- _ B-HyperparameterValue
and -X- _ O
length -X- _ B-HyperparameterName
penalty -X- _ I-HyperparameterName
α -X- _ B-HyperparameterName
= -X- _ O
0.6. -X- _ B-HyperparameterValue
While -X- _ O
constructing -X- _ O
the -X- _ O
fine-tuning -X- _ O
dataset -X- _ O
for -X- _ O
BLEURT, -X- _ B-DatasetName
we -X- _ O
generate -X- _ O
up -X- _ O
to -X- _ O
4 -X- _ O
different -X- _ O
negative -X- _ O
candidates -X- _ O
for -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
6 -X- _ O
transformations. -X- _ O

Our -X- _ O
work -X- _ O
rigorously -X- _ O
tests -X- _ O
state-of-the-art -X- _ O
models -X- _ O
on -X- _ B-DatasetName
DROP, -X- _ I-DatasetName
a -X- _ O
numerical -X- _ O
MRC -X- _ O
dataset, -X- _ O
to -X- _ O
see -X- _ O
if -X- _ O
they -X- _ O
can -X- _ O
handle -X- _ O
passages -X- _ O
that -X- _ O
contain -X- _ O
out-of-range -X- _ O
numbers. -X- _ O

We -X- _ O
compute -X- _ O
R-2 -X- _ B-MetricName
Precision -X- _ I-MetricName
(Pre) -X- _ O
of -X- _ O
generated -X- _ O
summaries -X- _ O
instead -X- _ O
of -X- _ O
F1, -X- _ B-MetricName
because -X- _ O
when -X- _ O
the -X- _ O
desired -X- _ O
length -X- _ O
of -X- _ O
generated -X- _ O
summaries -X- _ O
is -X- _ O
shorter -X- _ O
than -X- _ O
reference -X- _ O
summary -X- _ O
lengths, -X- _ O
precision -X- _ B-MetricName
can -X- _ O
reflect -X- _ O
the -X- _ O
accuracy -X- _ B-MetricName
of -X- _ O
information -X- _ O
selection -X- _ O
within -X- _ O
that -X- _ O
limited -X- _ O
budget. -X- _ O

For -X- _ O
the -X- _ O
first -X- _ O
encoder -X- _ O
layer -X- _ O
of -X- _ O
MAE-7, -X- _ B-MethodName
the -X- _ O
percentages -X- _ B-MetricName
of -X- _ I-MetricName
instances -X- _ I-MetricName
attributed -X- _ O
to -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
8 -X- _ O
experts -X- _ O
are -X- _ O
relatively -X- _ O
balanced: -X- _ O
13%, -X- _ B-MetricValue
14%, -X- _ B-MetricValue
9%, -X- _ B-MetricValue
16%, -X- _ B-MetricValue
10%, -X- _ B-MetricValue
15%, -X- _ B-MetricValue
10%, -X- _ B-MetricValue
12%. -X- _ B-MetricValue

The -X- _ O
finetuned -X- _ O
and -X- _ O
binary -X- _ O
masked -X- _ O
models -X- _ O
of -X- _ O
SEM -X- _ B-MethodName
generalize -X- _ O
well -X- _ O
on -X- _ O
SST2, -X- _ B-DatasetName
showing -X- _ O
≈ -X- _ O
20% -X- _ B-MetricValue
improvement -X- _ O
against -X- _ O
the -X- _ O
majority-vote -X- _ O
baseline. -X- _ O

With -X- _ O
more -X- _ O
unlabeled -X- _ O
data, -X- _ O
the -X- _ O
accuracy -X- _ B-MetricName
became -X- _ O
much -X- _ O
higher -X- _ O
on -X- _ O
both -X- _ B-DatasetName
AG -X- _ I-DatasetName
News -X- _ I-DatasetName
and -X- _ O
Yahoo! -X- _ B-DatasetName
Answer, -X- _ I-DatasetName
which -X- _ O
further -X- _ O
validated -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
usage -X- _ O
of -X- _ O
unlabeled -X- _ O
data. -X- _ O

To -X- _ O
evaluate -X- _ O
our -X- _ O
trained -X- _ O
classifier, -X- _ O
we -X- _ O
construct -X- _ O
a -X- _ O
test -X- _ O
set -X- _ O
by -X- _ O
randomly -X- _ O
sampling -X- _ O
100 -X- _ O
headlines -X- _ O
from -X- _ O
the -X- _ O
test -X- _ O
split -X- _ O
of -X- _ B-DatasetName
LCSTS -X- _ I-DatasetName
dataset -X- _ O
and -X- _ O
the -X- _ O
labels -X- _ O
are -X- _ O
obtained -X- _ O
by -X- _ O
11 -X- _ O
human -X- _ O
annotators. -X- _ O

Using -X- _ B-DatasetName
FairytaleQA -X- _ I-DatasetName
with -X- _ O
question -X- _ O
types -X- _ O
action, -X- _ O
causal -X- _ O
relationship, -X- _ O
and -X- _ O
outcome -X- _ O
resolution, -X- _ O
we -X- _ O
trained -X- _ O
one -X- _ O
BART-large -X- _ B-MethodName
model -X- _ O
to -X- _ O
generate -X- _ O
questions -X- _ O
based -X- _ O
one -X- _ O
paragraph -X- _ O
end-to-end. -X- _ O

Thus, -X- _ O
we -X- _ O
leverage -X- _ O
a -X- _ O
model -X- _ O
(Kim -X- _ O
et -X- _ O
al, -X- _ O
2021) -X- _ O
which -X- _ O
is -X- _ O
trained -X- _ O
to -X- _ O
jointly -X- _ O
detect -X- _ O
an -X- _ O
emotion -X- _ O
and -X- _ O
emotion -X- _ O
cause -X- _ O
words -X- _ O
of -X- _ O
the -X- _ O
speaker -X- _ O
utterance, -X- _ O
using -X- _ B-DatasetName
EmpatheticDialogues. -X- _ I-DatasetName

Our -X- _ O
work -X- _ O
lies -X- _ O
between -X- _ O
two -X- _ O
areas, -X- _ O
namely, -X- _ B-TaskName
semantic -X- _ I-TaskName
parsing -X- _ I-TaskName
and -X- _ O
cross-lingual -X- _ B-TaskName
transfer -X- _ I-TaskName
learning. -X- _ I-TaskName

The -X- _ B-DatasetName
HotpotQA -X- _ I-DatasetName
dataset -X- _ O
(Yang -X- _ O
et -X- _ O
al, -X- _ O
2018) -X- _ O
is -X- _ O
the -X- _ O
first -X- _ O
explainable -X- _ O
multi-hop -X- _ B-TaskName
QA -X- _ I-TaskName
dataset -X- _ O
with -X- _ O
sentencelevel -X- _ O
evidence -X- _ O
supervision. -X- _ O

For -X- _ O
each -X- _ O
spectrogram -X- _ O
chunk -X- _ O
and -X- _ O
image -X- _ O
frame -X- _ O
in -X- _ O
the -X- _ O
visual -X- _ O
and -X- _ O
acoustic -X- _ O
modalities, -X- _ O
we -X- _ O
first -X- _ O
use -X- _ O
a -X- _ O
pre-trained -X- _ O
CNN -X- _ O
model -X- _ O
(an -X- _ O
11-layer -X- _ O
VGG -X- _ B-MethodName
(Simonyan -X- _ O
and -X- _ O
Zisserman, -X- _ O
2014) -X- _ O
model) -X- _ O
to -X- _ O
extract -X- _ O
the -X- _ O
input -X- _ O
features, -X- _ O
which -X- _ O
are -X- _ O
then -X- _ O
flattened -X- _ O
to -X- _ O
vector -X- _ O
representations -X- _ O
using -X- _ O
a -X- _ O
linear -X- _ O
transformation. -X- _ O

For -X- _ O
reference, -X- _ O
here -X- _ O
is -X- _ O
the -X- _ O
sequence -X- _ O
of -X- _ O
perplexities -X- _ O
using -X- _ O
Eq. -X- _ O
(1) -X- _ B-MetricValue
in -X- _ O
the -X- _ O
upper -X- _ O
half -X- _ O
of -X- _ O
Tab. -X- _ O

Each -X- _ O
method -X- _ O
has -X- _ O
a -X- _ O
parameter -X- _ O
that -X- _ O
controls -X- _ O
the -X- _ O
various -X- _ O
tradeoffs: -X- _ O
for -X- _ O
arithmetic -X- _ O
encoding -X- _ O
we -X- _ O
vary -X- _ O
the -X- _ O
temperature -X- _ O
from -X- _ O
0.4 -X- _ B-HyperparameterValue
to -X- _ O
1.2 -X- _ B-HyperparameterValue
with -X- _ O
k -X- _ B-HyperparameterName
= -X- _ O
300, -X- _ B-HyperparameterValue
for -X- _ O
Huffman -X- _ O
encoding -X- _ O
we -X- _ O
vary -X- _ O
the -X- _ O
truncation -X- _ B-HyperparameterName
length -X- _ I-HyperparameterName
from -X- _ O
2 -X- _ B-HyperparameterValue
1 -X- _ I-HyperparameterValue
to -X- _ O
2 -X- _ B-HyperparameterValue
8 -X- _ I-HyperparameterValue
, -X- _ O
for -X- _ O
block -X- _ O
encoding -X- _ O
we -X- _ O
vary -X- _ O
the -X- _ O
block -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
from -X- _ O
2 -X- _ B-HyperparameterValue
1 -X- _ I-HyperparameterValue
to -X- _ O
2 -X- _ B-HyperparameterValue
5 -X- _ I-HyperparameterValue
. -X- _ O

3) -X- _ O
Two -X- _ O
strategies -X- _ O
of -X- _ O
combining -X- _ O
local -X- _ O
and -X- _ O
non-local -X- _ O
relations -X- _ O
introduced -X- _ O
in -X- _ O
§ -X- _ O
3.2.1 -X- _ O
(w/ -X- _ O
MSDE -X- _ O
or -X- _ O
MMC) -X- _ O
are -X- _ O
both -X- _ O
beneficial -X- _ O
to -X- _ O
the -X- _ O
eventual -X- _ O
performances -X- _ O
of -X- _ O
LGESQL -X- _ B-MethodName
(2.0% -X- _ B-MetricValue
and -X- _ O
2.1% -X- _ B-MetricValue
gains, -X- _ O
respectively). -X- _ O

The -X- _ O
value -X- _ O
of -X- _ O
d -X- _ B-HyperparameterName
model -X- _ I-HyperparameterName
is -X- _ O
128, -X- _ B-HyperparameterValue
and -X- _ O
the -X- _ O
numbers -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
attention -X- _ I-HyperparameterName
heads -X- _ I-HyperparameterName
and -X- _ O
layers -X- _ B-HyperparameterName
are -X- _ O
4 -X- _ B-HyperparameterValue
and -X- _ O
6, -X- _ B-HyperparameterValue
respectively. -X- _ O

We -X- _ O
introduce -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
Semi-Open -X- _ B-TaskName
Relation -X- _ I-TaskName
Extraction -X- _ I-TaskName
(SORE) -X- _ B-TaskName
on -X- _ O
scientific -X- _ O
texts -X- _ O
and -X- _ O
the -X- _ O
Focused -X- _ B-DatasetName
Open -X- _ I-DatasetName
Biological -X- _ I-DatasetName
Information -X- _ I-DatasetName
Extraction -X- _ I-DatasetName
(FOBIE) -X- _ B-DatasetName
dataset. -X- _ O

While -X- _ O
many -X- _ O
datasets -X- _ O
and -X- _ O
models -X- _ O
have -X- _ O
been -X- _ O
developed -X- _ O
to -X- _ O
this -X- _ O
end, -X- _ O
state-ofthe-art -X- _ O
AI -X- _ O
systems -X- _ O
are -X- _ O
brittle; -X- _ O
failing -X- _ O
to -X- _ O
perform -X- _ O
the -X- _ O
underlying -X- _ B-TaskName
mathematical -X- _ I-TaskName
reasoning -X- _ I-TaskName
when -X- _ O
they -X- _ O
appear -X- _ O
in -X- _ O
a -X- _ O
slightly -X- _ O
different -X- _ O
scenario. -X- _ O

In -X- _ O
this -X- _ O
work, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
unified -X- _ O
model, -X- _ O
Missing -X- _ B-MethodName
Modality -X- _ I-MethodName
Imagination -X- _ I-MethodName
Network -X- _ I-MethodName
(MMIN), -X- _ B-MethodName
to -X- _ O
deal -X- _ O
with -X- _ O
the -X- _ O
uncertain -X- _ O
missing -X- _ O
modality -X- _ O
problem. -X- _ O

To -X- _ O
our -X- _ O
surprise, -X- _ O
there -X- _ O
also -X- _ O
exists -X- _ O
an -X- _ O
overall -X- _ B-MetricName
alignment -X- _ I-MetricName
of -X- _ O
0.248 -X- _ B-MetricValue
between -X- _ O
BERT-based -X- _ B-MethodName
graders -X- _ I-MethodName
and -X- _ O
human -X- _ B-MethodName
graders -X- _ I-MethodName
in -X- _ O
G2. -X- _ O

Textual -X- _ O
reasoning -X- _ O
As -X- _ O
seen -X- _ O
in -X- _ O
Table -X- _ O
2, -X- _ O
when -X- _ O
trained -X- _ O
on -X- _ B-DatasetName
DROP -X- _ I-DatasetName
using -X- _ O
question-program -X- _ O
supervision, -X- _ O
the -X- _ O
model -X- _ O
achieves -X- _ O
65.3 -X- _ B-MetricValue
F -X- _ B-MetricName
1 -X- _ I-MetricName
performance -X- _ O
and -X- _ O
a -X- _ O
faithfulness -X- _ B-MetricName
score -X- _ I-MetricName
of -X- _ O
11.2. -X- _ B-MetricValue

Compared -X- _ O
to -X- _ O
the -X- _ O
PURE -X- _ B-MethodName
(Full), -X- _ O
our -X- _ O
model -X- _ O
obtains -X- _ O
a -X- _ O
2.2x-2.8x -X- _ B-MetricValue
speedup -X- _ B-MetricName
and -X- _ O
better -X- _ O
performance -X- _ O
on -X- _ O
ACE05 -X- _ B-DatasetName
and -X- _ B-DatasetName
SciERC. -X- _ I-DatasetName

If -X- _ O
a -X- _ O
token -X- _ O
in -X- _ O
a -X- _ O
specific -X- _ O
position -X- _ O
is -X- _ O
selected -X- _ O
to -X- _ O
be -X- _ O
masked -X- _ O
80% -X- _ B-HyperparameterValue
of -X- _ O
the -X- _ O
time -X- _ O
is -X- _ O
replaced -X- _ O
with -X- _ O
a -X- _ O
[MASK] -X- _ O
token, -X- _ O
10% -X- _ B-HyperparameterValue
of -X- _ O
the -X- _ O
time -X- _ O
with -X- _ O
a -X- _ O
random -X- _ O
token -X- _ O
and -X- _ O
10% -X- _ B-HyperparameterValue
of -X- _ O
the -X- _ O
time -X- _ O
remains -X- _ O
unchanged. -X- _ O

Another -X- _ O
common -X- _ O
objective -X- _ O
is -X- _ O
Causal -X- _ B-TaskName
Language -X- _ I-TaskName
Modelling -X- _ I-TaskName
(CLM), -X- _ B-TaskName
where -X- _ O
the -X- _ O
task -X- _ O
is -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
next -X- _ O
token. -X- _ O

Although -X- _ O
multilingual -X- _ O
sentence -X- _ O
encoders -X- _ O
are -X- _ O
useful -X- _ O
for -X- _ O
cross-lingual -X- _ B-TaskName
NLU, -X- _ I-TaskName
their -X- _ O
embeddings -X- _ O
are -X- _ O
highly -X- _ O
biased -X- _ O
by -X- _ O
language-specific -X- _ O
information, -X- _ O
which -X- _ O
separates -X- _ O
sentence -X- _ O
embeddings -X- _ O
into -X- _ O
multiple -X- _ O
languages, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1. -X- _ O

This -X- _ O
simplification -X- _ O
results -X- _ O
in -X- _ O
ambiguity -X- _ O
for -X- _ O
the -X- _ O
NERC -X- _ B-TaskName
task -X- _ O
in -X- _ O
the -X- _ O
case -X- _ O
of -X- _ O
two -X- _ O
consecutive -X- _ O
named-entities -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
class, -X- _ O
however -X- _ O
it -X- _ O
reduces -X- _ O
the -X- _ O
model -X- _ B-MetricName
parameters -X- _ I-MetricName
by -X- _ O
half -X- _ B-MetricValue
while -X- _ O
affecting -X- _ O
5.8% -X- _ B-MetricValue
of -X- _ O
the -X- _ O
entities -X- _ O
across -X- _ O
the -X- _ O
validation -X- _ O
and -X- _ O
test -X- _ O
splits -X- _ O
of -X- _ O
both -X- _ O
datasets -X- _ O
(c.f. -X- _ O
row -X- _ O
# -X- _ O
consecutive -X- _ O
entities -X- _ O
of -X- _ O
same -X- _ O
class -X- _ O
in -X- _ O
Table -X- _ O
1). -X- _ O

From -X- _ O
the -X- _ O
overall -X- _ O
results, -X- _ O
we -X- _ O
can -X- _ O
see -X- _ O
that: -X- _ O
1) -X- _ O
by -X- _ O
involving -X- _ O
the -X- _ O
line -X- _ O
graph -X- _ O
into -X- _ O
computation, -X- _ O
LGESQL -X- _ B-MethodName
outperforms -X- _ O
the -X- _ O
baseline -X- _ O
model -X- _ O
RGATSQL -X- _ B-MethodName
with -X- _ O
different -X- _ O
PLMs, -X- _ O
further -X- _ O
demonstrating -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
explicitly -X- _ O
modeling -X- _ O
edge -X- _ O
features. -X- _ O

The -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
for -X- _ O
both -X- _ O
post-training -X- _ O
and -X- _ O
fine-tuning -X- _ O
is -X- _ O
3e-5 -X- _ B-HyperparameterValue
with -X- _ O
Adam -X- _ B-MethodName
as -X- _ O
the -X- _ O
optimizer. -X- _ O

Experimental -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
MultiWOZ -X- _ B-DatasetName
benchmark -X- _ O
(Budzianowski -X- _ O
et -X- _ O
al, -X- _ O
2018) -X- _ O
suggest -X- _ O
that -X- _ O
1) -X- _ O
our -X- _ O
model -X- _ O
achieves -X- _ O
significantly -X- _ O
higher -X- _ O
joint -X- _ O
goal -X- _ O
accuracy -X- _ B-MetricName
compared -X- _ O
to -X- _ O
existing -X- _ O
results -X- _ O
in -X- _ O
zero-shot -X- _ O
cross -X- _ O
domain -X- _ O
DST; -X- _ O
2) -X- _ O
models -X- _ O
using -X- _ O
the -X- _ O
proposed -X- _ O
slot -X- _ O
description -X- _ O
formulation -X- _ O
substantially -X- _ O
outperform -X- _ O
those -X- _ O
using -X- _ O
other -X- _ O
slot -X- _ O
description -X- _ O
variants. -X- _ O

In -X- _ O
summary, -X- _ O
I -X- _ O
have -X- _ O
proposed -X- _ O
a -X- _ B-TaskName
data -X- _ I-TaskName
augmentation -X- _ I-TaskName
protocol -X- _ O
called -X- _ O
GE3, -X- _ B-MethodName
which -X- _ O
extrapolates -X- _ O
the -X- _ O
hidden -X- _ O
space -X- _ O
distribution -X- _ O
of -X- _ O
one -X- _ O
class -X- _ O
onto -X- _ O
another. -X- _ O

Nevertheless, -X- _ O
the -X- _ O
heavy -X- _ O
text-image -X- _ O
interactions -X- _ O
in -X- _ O
the -X- _ O
cross-BERT -X- _ B-MethodName
model -X- _ O
are -X- _ O
prohibitively -X- _ O
slow -X- _ O
for -X- _ O
large-scale -X- _ O
retrieval. -X- _ O

Our -X- _ O
main -X- _ O
contributions -X- _ O
can -X- _ O
be -X- _ O
summarized -X- _ O
as -X- _ O
follows: -X- _ O
(1) -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
framework, -X- _ O
PPVAE, -X- _ B-MethodName
for -X- _ O
conditional -X- _ O
text -X- _ O
generation, -X- _ O
which -X- _ O
allows -X- _ O
a -X- _ O
separate -X- _ O
training -X- _ O
for -X- _ O
a -X- _ O
new -X- _ O
condition -X- _ O
without -X- _ O
retraining -X- _ O
the -X- _ O
whole -X- _ O
network. -X- _ O
(2) -X- _ O
We -X- _ O
conduct -X- _ O
extensive -X- _ O
experiments -X- _ O
and -X- _ O
analysis -X- _ O
to -X- _ O
verify -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
PPVAE. -X- _ B-MethodName

The -X- _ O
models -X- _ O
are -X- _ O
validated -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
set -X- _ O
of -X- _ O
the -X- _ B-DatasetName
MTNT -X- _ I-DatasetName
dataset -X- _ O
and -X- _ O
tested -X- _ O
on -X- _ O
the -X- _ O
released -X- _ O
test -X- _ O
set -X- _ O
of -X- _ O
the -X- _ O
WMT'19 -X- _ B-DatasetName
robustness -X- _ O
task. -X- _ O

Comprehensive -X- _ O
experiments -X- _ O
demonstrate -X- _ O
that -X- _ O
SentiBERT -X- _ B-MethodName
achieves -X- _ O
competitive -X- _ O
performance -X- _ O
on -X- _ O
phrase-level -X- _ B-TaskName
sentiment -X- _ I-TaskName
classification. -X- _ I-TaskName

Figure -X- _ O
3 -X- _ O
shows -X- _ O
the -X- _ O
probability -X- _ O
distribution, -X- _ O
on -X- _ O
which -X- _ O
even -X- _ O
taking -X- _ O
0.8 -X- _ B-HyperparameterValue
as -X- _ O
a -X- _ O
threshold -X- _ O
gives -X- _ O
a -X- _ O
lower -X- _ O
F1 -X- _ B-MetricName
score -X- _ O
because -X- _ O
of -X- _ O
false -X- _ O
positive -X- _ O
attachment. -X- _ O

The -X- _ O
performance -X- _ O
of -X- _ O
RoSTER -X- _ B-MethodName
is -X- _ O
equivalent -X- _ O
to -X- _ O
using -X- _ O
1, -X- _ O
000 -X- _ O
cleanly -X- _ O
annotated -X- _ O
sequences -X- _ O
for -X- _ O
supervised -X- _ O
RoBERTa. -X- _ B-MethodName

Sparse -X- _ O
scaling -X- _ O
architectures, -X- _ O
such -X- _ O
as -X- _ O
BASE-Layers, -X- _ B-MethodName
provide -X- _ O
flexible -X- _ O
mechanisms -X- _ O
for -X- _ O
tasks -X- _ O
to -X- _ O
have -X- _ O
a -X- _ O
variable -X- _ O
number -X- _ O
of -X- _ O
parameters, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
useful -X- _ O
to -X- _ O
counterbalance -X- _ O
skewed -X- _ O
data -X- _ O
distributions. -X- _ O

However, -X- _ O
in -X- _ O
scenario -X- _ O
(ii) -X- _ O
with -X- _ O
a -X- _ O
fixed -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
clusters -X- _ I-HyperparameterName
(r -X- _ B-HyperparameterName
= -X- _ O
0), -X- _ B-HyperparameterValue
the -X- _ O
system -X- _ O
performance -X- _ O
consistently -X- _ O
gets -X- _ O
higher -X- _ O
with -X- _ O
larger -X- _ O
clusters, -X- _ O
even -X- _ O
though -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
clusters -X- _ I-HyperparameterName
is -X- _ O
kept -X- _ O
constant. -X- _ O

This -X- _ O
finding -X- _ O
is -X- _ O
reminiscent -X- _ O
of -X- _ B-TaskName
data -X- _ I-TaskName
augmentation -X- _ I-TaskName
strategies -X- _ O
for -X- _ O
supervised -X- _ B-TaskName
parsers -X- _ I-TaskName
using -X- _ O
synthetic -X- _ O
samples -X- _ O
induced -X- _ O
from -X- _ O
(annotated) -X- _ O
parallel -X- _ O
data -X- _ O
(Jia -X- _ O
and -X- _ O
Liang, -X- _ O
2016;Wang -X- _ O
et -X- _ O
al, -X- _ O
2021b). -X- _ O

The -X- _ O
Parallel -X- _ B-DatasetName
Universal -X- _ I-DatasetName
Dependencies -X- _ I-DatasetName
(PUD) -X- _ B-DatasetName
corpus -X- _ O
consists -X- _ O
of -X- _ O
1000 -X- _ O
sentences -X- _ O
translated -X- _ O
into -X- _ O
various -X- _ O
languages -X- _ O
by -X- _ O
professional -X- _ O
translators. -X- _ O

We -X- _ O
adopt -X- _ O
the -X- _ B-DatasetName
MSR-VTT -X- _ I-DatasetName
video -X- _ O
description -X- _ O
dataset -X- _ O
(Xu -X- _ O
et -X- _ O
al, -X- _ O
2016) -X- _ O
as -X- _ O
a -X- _ O
source -X- _ O
of -X- _ O
videos -X- _ O
and -X- _ O
captions. -X- _ O

The -X- _ O
average -X- _ O
Krippendorff -X- _ B-MetricName
scores -X- _ I-MetricName
for -X- _ O
inter- -X- _ O
annotator -X- _ O
agreement -X- _ O
(IAA) -X- _ O
are -X- _ O
0.153, -X- _ B-MetricValue
0.244, -X- _ B-MetricValue
and -X- _ O
0.202 -X- _ B-MetricValue
for -X- _ O
English, -X- _ O
French, -X- _ O
and -X- _ O
Arabic -X- _ O
respectively, -X- _ O
which -X- _ O
are -X- _ O
comparable -X- _ O
to -X- _ O
existing -X- _ O
complex -X- _ O
annotations -X- _ O
(Sanguinetti -X- _ O
et -X- _ O
al, -X- _ O
2018) -X- _ O
given -X- _ O
the -X- _ O
nature -X- _ O
of -X- _ O
the -X- _ O
labeling -X- _ O
tasks -X- _ O
and -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
labels. -X- _ O

UNIPELT -X- _ B-MethodName
has -X- _ O
a -X- _ O
slightly -X- _ O
larger -X- _ O
inference -X- _ O
overhead -X- _ O
(4%~11% -X- _ O
compared -X- _ O
to -X- _ O
its -X- _ O
slowest -X- _ O
submodule), -X- _ O
which -X- _ O
we -X- _ O
argue -X- _ O
is -X- _ O
insignificant -X- _ O
since -X- _ O
larger -X- _ O
models -X- _ O
that -X- _ O
may -X- _ O
achieve -X- _ O
similar -X- _ O
performance -X- _ O
gains -X- _ O
(e.g., -X- _ O
BERT -X- _ B-MethodName
large -X- _ I-MethodName
) -X- _ O
need -X- _ O
around -X- _ O
300% -X- _ B-MetricValue
inference -X- _ B-MetricName
time -X- _ I-MetricName
(Wolf -X- _ O
et -X- _ O
al, -X- _ O
2020). -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
Transformers -X- _ O
code -X- _ O
from -X- _ O
Hug-gingFace -X- _ O
(Wolf -X- _ O
et -X- _ O
al, -X- _ O
2020) -X- _ O
to -X- _ O
fine-tune -X- _ O
a -X- _ O
T5-base -X- _ B-MethodName
model -X- _ O
over -X- _ O
IDKD -X- _ B-DatasetName
for -X- _ O
2 -X- _ B-HyperparameterValue
epochs. -X- _ B-HyperparameterName

Through -X- _ O
extensive -X- _ O
set -X- _ O
of -X- _ O
experiments -X- _ O
on -X- _ O
CMU-MOSI -X- _ B-DatasetName
and -X- _ B-DatasetName
CMU-MOSEI, -X- _ I-DatasetName
we -X- _ O
have -X- _ O
shown -X- _ O
that -X- _ O
SOTA -X- _ O
architectures -X- _ O
can -X- _ O
benefit -X- _ O
from -X- _ O
these -X- _ O
innovations -X- _ O
with -X- _ O
little -X- _ O
modifications. -X- _ O

We -X- _ O
clarify -X- _ O
that -X- _ O
this -X- _ O
does -X- _ O
not -X- _ O
diminish -X- _ O
the -X- _ O
utility -X- _ O
of -X- _ O
the -X- _ O
datasets -X- _ O
themselves -X- _ O
as -X- _ O
tools -X- _ O
for -X- _ O
comparing -X- _ O
models -X- _ O
and -X- _ O
making -X- _ O
progress -X- _ O
in -X- _ O
NLP: -X- _ B-DatasetName
MLQA -X- _ I-DatasetName
is -X- _ O
extremely -X- _ O
useful -X- _ O
for -X- _ O
comparing -X- _ O
models -X- _ O
across -X- _ O
languages -X- _ O
on -X- _ O
the -X- _ O
exact -X- _ O
same -X- _ O
data, -X- _ O
thus -X- _ O
facilitating -X- _ O
easy -X- _ O
comparisons -X- _ O
of -X- _ O
the -X- _ O
cross-lingual -X- _ O
abilities -X- _ O
of -X- _ O
QA -X- _ O
systems, -X- _ O
without -X- _ O
the -X- _ O
need -X- _ O
for -X- _ O
approximations -X- _ O
or -X- _ O
additional -X- _ O
statistical -X- _ O
tests. -X- _ O
But -X- _ O
we -X- _ O
argue -X- _ O
that -X- _ O
MLQA -X- _ B-DatasetName
should -X- _ O
not -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
asses -X- _ O
the -X- _ O
potential -X- _ O
utility -X- _ O
of -X- _ O
QA -X- _ O
systems -X- _ O
for -X- _ O
German -X- _ O
or -X- _ O
Telugu -X- _ O
speakers. -X- _ O

Especially, -X- _ O
when -X- _ O
the -X- _ O
sentiment -X- _ O
labels -X- _ O
of -X- _ O
both -X- _ O
children -X- _ O
are -X- _ O
different -X- _ O
from -X- _ O
the -X- _ O
parent -X- _ O
node -X- _ O
(i.e., -X- _ O
local -X- _ O
difficulty -X- _ O
is -X- _ O
2), -X- _ O
the -X- _ O
performance -X- _ O
gap -X- _ O
between -X- _ O
SentiBERT -X- _ B-MethodName
and -X- _ O
BERT -X- _ B-MethodName
w/ -X- _ I-MethodName
Tree-LSTM -X- _ I-MethodName
is -X- _ O
about -X- _ O
7% -X- _ B-MetricValue
accuracy. -X- _ B-MetricName

Even -X- _ O
the -X- _ O
best -X- _ O
model -X- _ O
among -X- _ O
them, -X- _ O
ROBERTa-wwm-ext -X- _ B-MethodName
just -X- _ O
achieves -X- _ O
an -X- _ O
accuracy -X- _ B-MetricName
of -X- _ O
49.79% -X- _ B-MetricValue
and -X- _ O
F1 -X- _ B-MetricName
of -X- _ O
36.45%. -X- _ B-MetricValue

As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1, -X- _ O
our -X- _ O
proposed -X- _ O
kNN-KD -X- _ B-MethodName
can -X- _ O
be -X- _ O
described -X- _ O
as -X- _ O
follows: -X- _ O
Step -X- _ O
1: -X- _ O
Datastore -X- _ O
Building -X- _ O
We -X- _ O
build -X- _ O
the -X- _ O
datastore -X- _ O
D -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
way -X- _ O
as -X- _ O
vanilla -X- _ O
kNN-MT -X- _ B-MethodName
(Khandelwal -X- _ O
et -X- _ O
al, -X- _ O
2021) -X- _ O
which -X- _ O
has -X- _ O
been -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
2.2, -X- _ O
so -X- _ O
we -X- _ O
omit -X- _ O
it -X- _ O
here. -X- _ O

The -X- _ O
DTPC-GCN -X- _ B-MethodName
rely -X- _ O
more -X- _ O
on -X- _ O
the -X- _ O
topic-unrelated -X- _ O
features -X- _ O
from -X- _ O
Branch -X- _ O
U -X- _ O
when -X- _ O
classifying -X- _ O
Post -X- _ O
1 -X- _ O
(0.874 -X- _ B-MetricValue
> -X- _ O
0.126), -X- _ B-MetricValue
while -X- _ O
more -X- _ O
on -X- _ O
the -X- _ O
topic-related -X- _ O
features -X- _ O
from -X- _ O
Branch -X- _ O
R -X- _ O
when -X- _ O
classifying -X- _ O
Post -X- _ O
2 -X- _ O
(0.217 -X- _ B-MetricValue
< -X- _ O
0.783). -X- _ B-MetricValue

Note -X- _ O
that, -X- _ O
ViLT -X- _ B-MethodName
(Kim -X- _ O
et -X- _ O
al, -X- _ O
2021), -X- _ O
ViLBERT -X- _ B-MethodName
(Lu -X- _ O
et -X- _ O
al, -X- _ O
2019) -X- _ O
and -X- _ O
12-in-1 -X- _ B-MethodName
(Lu -X- _ O
et -X- _ O
al, -X- _ O
2020) -X- _ O
are -X- _ O
pre-trained -X- _ O
on -X- _ O
large-scale -X- _ O
multimodal -X- _ O
datasets, -X- _ O
whereas -X- _ O
ours -X- _ O
is -X- _ O
not -X- _ O
pre-trained -X- _ O
on -X- _ O
these -X- _ O
datasets. -X- _ O

In -X- _ O
Figure -X- _ O
1-B -X- _ O
we -X- _ O
show -X- _ O
the -X- _ O
list -X- _ O
of -X- _ O
concepts -X- _ O
that -X- _ O
represent -X- _ O
the -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
sentences -X- _ O
of -X- _ O
Figure -X- _ O
1-A. -X- _ O
The -X- _ O
relation -X- _ O
identification -X- _ O
procedure, -X- _ O
instead, -X- _ O
is -X- _ O
inspired -X- _ O
by -X- _ O
the -X- _ O
arc-factored -X- _ O
approaches -X- _ O
employed -X- _ O
in -X- _ B-TaskName
dependency -X- _ I-TaskName
parsing -X- _ I-TaskName
(Kiperwasser -X- _ O
and -X- _ O
Goldberg, -X- _ O
2016), -X- _ O
i.e., -X- _ O
searching -X- _ O
for -X- _ O
the -X- _ O
maximum-scoring -X- _ O
connected -X- _ O
subgraph -X- _ O
over -X- _ O
the -X- _ O
identified -X- _ O
concepts -X- _ O
in -X- _ O
the -X- _ O
previous -X- _ O
step. -X- _ O

An -X- _ O
exception -X- _ O
is -X- _ O
K -X- _ B-HyperparameterName
=500 -X- _ B-HyperparameterValue
on -X- _ O
SCHOLAR, -X- _ B-DatasetName
where -X- _ O
the -X- _ O
perplexity -X- _ B-MetricName
on -X- _ O
out-of-coverage -X- _ O
samples -X- _ O
is -X- _ O
slightly -X- _ O
lower. -X- _ O

Aug-WoW-claimonly -X- _ B-MethodName
achieves -X- _ O
33.2% -X- _ B-MetricValue
accuracy -X- _ B-MetricName
and -X- _ O
28.9% -X- _ B-MetricValue
macro -X- _ B-MetricName
F1 -X- _ I-MetricName
score -X- _ I-MetricName
on -X- _ O
the -X- _ O
DIALFACT -X- _ B-DatasetName
test -X- _ O
set. -X- _ O

The -X- _ O
SymAcc -X- _ B-MetricName
drops -X- _ O
from -X- _ O
about -X- _ O
55% -X- _ B-MetricValue
to -X- _ O
40% -X- _ B-MetricValue
by -X- _ O
ablating -X- _ O
Phase -X- _ O
I, -X- _ O
and -X- _ O
to -X- _ O
23% -X- _ B-MetricValue
by -X- _ O
ablating -X- _ O
Phase -X- _ O
II. -X- _ O

(2) -X- _ O
R-GCN+GPT: -X- _ B-MethodName
A -X- _ O
joint -X- _ O
model -X- _ O
combining -X- _ O
a -X- _ O
R-GCN -X- _ B-MethodName
(Schlichtkrull -X- _ O
et -X- _ O
al, -X- _ O
2018) -X- _ O
for -X- _ O
movie -X- _ O
recommendation -X- _ O
with -X- _ O
a -X- _ O
Transformer-based -X- _ O
language -X- _ O
model -X- _ O
(Vaswani -X- _ O
et -X- _ O
al, -X- _ O
2017) -X- _ O
for -X- _ B-TaskName
response -X- _ I-TaskName
generation. -X- _ I-TaskName

We -X- _ O
considered -X- _ O
several -X- _ O
available -X- _ O
datasets -X- _ O
, -X- _ O
such -X- _ O
as -X- _ B-DatasetName
DailyDialog -X- _ I-DatasetName
(Li -X- _ O
et -X- _ O
al, -X- _ O
2017), -X- _ O
SwDA -X- _ B-DatasetName
(Switchboard -X- _ B-DatasetName
Dialogue -X- _ I-DatasetName
Act -X- _ I-DatasetName
Corpus -X- _ I-DatasetName
(Jurafsky, -X- _ O
1997)), -X- _ O
MRDA -X- _ B-DatasetName
(Meeting -X- _ B-DatasetName
Recorder -X- _ I-DatasetName
Dialogue -X- _ I-DatasetName
Act -X- _ I-DatasetName
corpus -X- _ O
(Janin -X- _ O
et -X- _ O
al, -X- _ O
2003)), -X- _ O
Ubuntu -X- _ B-DatasetName
, -X- _ O
OpenSubtitles -X- _ B-DatasetName
(Tiedemann, -X- _ O
2009), -X- _ O
etc. -X- _ O

We -X- _ O
also -X- _ O
note -X- _ O
that -X- _ O
Kuki, -X- _ B-MethodName
like -X- _ O
the -X- _ O
E2E -X- _ O
neural -X- _ O
models, -X- _ O
is -X- _ O
not -X- _ O
immune -X- _ O
to -X- _ O
responding -X- _ O
with -X- _ O
unsafe -X- _ O
language: -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
in -X- _ O
cases -X- _ O
when -X- _ O
Kuki's -X- _ B-MethodName
responses -X- _ O
are -X- _ O
marked -X- _ O
as -X- _ O
unsafe -X- _ O
by -X- _ O
all -X- _ O
tools, -X- _ O
it -X- _ O
often -X- _ O
had -X- _ O
repeated -X- _ O
all -X- _ O
or -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
(potentially -X- _ O
offensive) -X- _ O
input. -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
polynomial -X- _ O
learning -X- _ O
rate -X- _ O
scheduler -X- _ O
with -X- _ O
warmup -X- _ O
and -X- _ O
train -X- _ O
for -X- _ O
40,000 -X- _ B-HyperparameterValue
steps -X- _ O
with -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
24. -X- _ B-HyperparameterValue

k-nearest-neighbor -X- _ B-MethodName
machine -X- _ I-MethodName
translation -X- _ I-MethodName
(kNN-MT), -X- _ B-MethodName
proposed -X- _ O
by -X- _ O
Khandelwal -X- _ O
et -X- _ O
al. -X- _ O
(2021), -X- _ O
has -X- _ O
achieved -X- _ O
many -X- _ O
state-of-the-art -X- _ O
results -X- _ O
in -X- _ O
machine -X- _ O
translation -X- _ O
tasks. -X- _ O

After -X- _ O
that, -X- _ O
our -X- _ O
EMC-GCN -X- _ B-MethodName
transforms -X- _ O
the -X- _ O
sentence -X- _ O
into -X- _ O
a -X- _ O
multi-channel -X- _ O
graph -X- _ O
by -X- _ O
treating -X- _ O
words -X- _ O
and -X- _ O
the -X- _ O
relation -X- _ O
adjacent -X- _ O
tensor -X- _ O
as -X- _ O
nodes -X- _ O
and -X- _ O
edges, -X- _ O
respectively. -X- _ O

With -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
multi-turn -X- _ O
safety -X- _ O
classifier, -X- _ O
results -X- _ O
were -X- _ O
mixed -X- _ O
across -X- _ O
models, -X- _ O
with -X- _ O
the -X- _ O
majority -X- _ O
of -X- _ O
both -X- _ O
DialoGPT -X- _ B-MethodName
and -X- _ O
GPT-2's -X- _ B-MethodName
responses -X- _ O
flagged -X- _ O
as -X- _ O
offensive. -X- _ O

We -X- _ O
decode -X- _ O
programs -X- _ O
using -X- _ O
beam -X- _ B-MethodName
search -X- _ I-MethodName
with -X- _ O
a -X- _ O
beam -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
5. -X- _ B-HyperparameterValue

Many -X- _ O
machine -X- _ B-TaskName
reading -X- _ I-TaskName
comprehension -X- _ I-TaskName
(MRC) -X- _ B-TaskName
datasets -X- _ O
have -X- _ O
been -X- _ O
released -X- _ O
in -X- _ O
recent -X- _ O
years -X- _ O
(Rajpurkar -X- _ O
et -X- _ O
al, -X- _ O
2016;Nguyen -X- _ O
et -X- _ O
al, -X- _ O
2016;Reddy -X- _ O
et -X- _ O
al, -X- _ O
2018;Yang -X- _ O
et -X- _ O
al, -X- _ O
2018) -X- _ O
to -X- _ O
benchmark -X- _ O
a -X- _ O
system's -X- _ O
ability -X- _ O
to -X- _ O
understand -X- _ O
and -X- _ O
reason -X- _ O
over -X- _ O
natural -X- _ O
language. -X- _ O

In -X- _ O
this -X- _ O
paper, -X- _ O
we -X- _ O
propose -X- _ O
Target-Specified -X- _ B-MethodName
sequence -X- _ I-MethodName
labeling -X- _ I-MethodName
with -X- _ I-MethodName
Multi-head -X- _ I-MethodName
Self-Attention -X- _ I-MethodName
(TSMSA) -X- _ B-MethodName
for -X- _ O
TOWE, -X- _ O
in -X- _ O
which -X- _ O
any -X- _ O
pre-trained -X- _ O
language -X- _ O
model -X- _ O
with -X- _ O
multi-head -X- _ O
self-attention -X- _ O
can -X- _ O
be -X- _ O
integrated -X- _ O
conveniently. -X- _ O

We -X- _ O
denote -X- _ O
the -X- _ O
matrix -X- _ O
as -X- _ O
A, -X- _ O
A[i][j] -X- _ O
means -X- _ O
the -X- _ O
frequency -X- _ O
of -X- _ O
the -X- _ O
circumstance -X- _ O
that -X- _ O
the -X- _ O
true -X- _ O
label -X- _ O
is -X- _ O
i -X- _ O
while -X- _ O
MIE-multi -X- _ B-MethodName
gives -X- _ O
the -X- _ O
answer -X- _ O
j. -X- _ O
We -X- _ O
study -X- _ O
the -X- _ O
matrix -X- _ O
and -X- _ O
find -X- _ O
that -X- _ O
MIEmulti -X- _ B-MethodName
failed -X- _ O
to -X- _ O
predict -X- _ O
Symptom:Limited -X- _ O
possible -X- _ O
reason -X- _ O
is -X- _ O
that -X- _ O
they -X- _ O
rarely -X- _ O
appear -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
set, -X- _ O
with -X- _ O
frequency -X- _ O
of -X- _ O
0.63%, -X- _ O
2.63%, -X- _ O
2.38% -X- _ O
and -X- _ O
1.25%, -X- _ O
respectively. -X- _ O

When -X- _ O
target -X- _ O
groups -X- _ O
and -X- _ O
attributes -X- _ O
are -X- _ O
trained -X- _ O
jointly, -X- _ O
the -X- _ O
macro -X- _ B-MetricName
F-score -X- _ I-MetricName
of -X- _ O
the -X- _ O
target -X- _ O
group -X- _ O
classification -X- _ O
in -X- _ O
Arabic -X- _ O
improves -X- _ O
by -X- _ O
0.25 -X- _ B-MetricValue
and -X- _ O
when -X- _ O
we -X- _ O
train -X- _ O
the -X- _ O
tweet's -X- _ O
hostility -X- _ O
type -X- _ O
within -X- _ O
the -X- _ O
annotator's -X- _ O
sentiment, -X- _ O
we -X- _ O
improve -X- _ O
the -X- _ O
macro -X- _ B-MetricName
F-score -X- _ I-MetricName
of -X- _ O
Arabic -X- _ O
by -X- _ O
0.02. -X- _ B-MetricValue

In -X- _ O
this -X- _ O
paper, -X- _ O
we -X- _ O
propose -X- _ O
Weight -X- _ B-MethodName
Distillation -X- _ I-MethodName
to -X- _ O
transfer -X- _ O
the -X- _ O
knowledge -X- _ O
in -X- _ O
parameters -X- _ O
of -X- _ O
a -X- _ O
large -X- _ O
neural -X- _ O
network -X- _ O
to -X- _ O
a -X- _ O
small -X- _ O
neural -X- _ O
network -X- _ O
through -X- _ O
a -X- _ O
parameter -X- _ O
generator. -X- _ O

Then -X- _ O
wiki -X- _ O
links -X- _ O
are -X- _ O
restored -X- _ O
using -X- _ O
the -X- _ O
DBpedia -X- _ B-DatasetName
Spotlight -X- _ I-DatasetName
API -X- _ I-DatasetName
14 -X- _ O
(Daiber -X- _ O
et -X- _ O
al, -X- _ O
2013), -X- _ O
commonly -X- _ O
used -X- _ O
in -X- _ O
English -X- _ B-TaskName
AMR -X- _ I-TaskName
parsing -X- _ I-TaskName
(van -X- _ O
Noord -X- _ O
and -X- _ O
Bos, -X- _ O
2017;Ge -X- _ O
et -X- _ O
al, -X- _ O
2019). -X- _ O

The -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
is -X- _ O
scheduled -X- _ O
using -X- _ O
inverse_sqrt -X- _ O
with -X- _ O
a -X- _ O
maximum -X- _ O
learning -X- _ O
rate -X- _ O
0.0005, -X- _ B-HyperparameterValue
and -X- _ O
10,000 -X- _ B-HyperparameterValue
warmup -X- _ B-HyperparameterName
steps -X- _ I-HyperparameterName
except -X- _ O
for -X- _ O
TRANSFORMER -X- _ B-MethodName
which -X- _ O
sets -X- _ O
warmup -X- _ B-HyperparameterName
steps -X- _ I-HyperparameterName
as -X- _ O
4000. -X- _ B-HyperparameterValue

In -X- _ O
contrast, -X- _ O
lateinteraction -X- _ O
methods -X- _ O
such -X- _ O
as -X- _ O
SCAN -X- _ B-MethodName
(Lee -X- _ O
et -X- _ O
al, -X- _ O
2018) -X- _ O
and -X- _ O
VisualSparta -X- _ B-MethodName
) -X- _ O
achieve -X- _ O
a -X- _ O
good -X- _ O
trade-off -X- _ O
between -X- _ O
accuracy -X- _ B-MetricName
and -X- _ O
efficiency. -X- _ O

We -X- _ O
set -X- _ O
n -X- _ B-HyperparameterName
= -X- _ O
2. -X- _ B-HyperparameterValue

To -X- _ O
find -X- _ O
the -X- _ O
accuracy -X- _ B-MetricName
of -X- _ O
this -X- _ O
technique, -X- _ O
we -X- _ O
manually -X- _ O
examined -X- _ O
115 -X- _ O
English -X- _ O
language -X- _ O
website -X- _ O
landing -X- _ O
pages -X- _ O
and -X- _ O
their -X- _ O
privacy -X- _ O
policy -X- _ O
URLs -X- _ O
from -X- _ O
the -X- _ O
OPP-115 -X- _ B-DatasetName
Corpus -X- _ O
since -X- _ O
it -X- _ O
was -X- _ O
built -X- _ O
to -X- _ O
cover -X- _ O
the -X- _ O
diverse -X- _ O
distribution -X- _ O
of -X- _ O
privacy -X- _ O
policies -X- _ O
on -X- _ O
the -X- _ O
web, -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
website -X- _ O
popularity -X- _ O
and -X- _ O
sector -X- _ O
of -X- _ O
commerce. -X- _ O

Following -X- _ O
the -X- _ O
annotation -X- _ O
guidelines -X- _ O
of -X- _ O
MS-AMR, -X- _ B-DatasetName
we -X- _ O
manually -X- _ O
annotate -X- _ O
the -X- _ O
AMR -X- _ B-TaskName
coreference -X- _ I-TaskName
resolution -X- _ I-TaskName
information -X- _ O
over -X- _ O
the -X- _ O
development -X- _ O
and -X- _ O
test -X- _ O
data -X- _ O
of -X- _ B-DatasetName
the -X- _ I-DatasetName
Little -X- _ I-DatasetName
Prince -X- _ I-DatasetName
(LP) -X- _ B-DatasetName
AMR -X- _ O
corpus -X- _ O
4 -X- _ O
and -X- _ O
use -X- _ O
it -X- _ O
as -X- _ O
an -X- _ O
out-of-domain -X- _ O
test -X- _ O
set. -X- _ O

For -X- _ O
instance, -X- _ O
the -X- _ O
Recall@1 -X- _ B-MetricName
of -X- _ O
text-to-image -X- _ O
retrieval -X- _ O
gets -X- _ O
improved -X- _ O
from -X- _ O
58.2 -X- _ B-MetricValue
to -X- _ O
60.9 -X- _ B-MetricValue
on -X- _ O
Flickr30K. -X- _ B-DatasetName

• -X- _ O
Creation -X- _ O
and -X- _ O
release -X- _ O
of -X- _ O
diverse -X- _ O
quality -X- _ O
silver -X- _ O
data -X- _ O
for -X- _ O
cross-lingual -X- _ B-TaskName
AMR -X- _ I-TaskName
parsing. -X- _ I-TaskName

In -X- _ O
all -X- _ O
4 -X- _ O
benchmarks, -X- _ O
our -X- _ O
base -X- _ O
CMLM -X- _ B-MethodName
reaches -X- _ O
within -X- _ O
0.5-1.2 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
points -X- _ O
from -X- _ O
a -X- _ O
welltuned -X- _ O
base -X- _ O
transformer, -X- _ O
a -X- _ O
relative -X- _ O
decrease -X- _ O
of -X- _ O
less -X- _ O
than -X- _ O
4% -X- _ B-MetricValue
in -X- _ O
translation -X- _ B-MetricName
quality. -X- _ I-MetricName

The -X- _ O
authors -X- _ O
only -X- _ O
test -X- _ O
whether -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
applied -X- _ O
to -X- _ O
a -X- _ O
different -X- _ O
task -X- _ O
by -X- _ O
experimenting -X- _ O
on -X- _ O
the -X- _ B-DatasetName
WebNLG -X- _ I-DatasetName
(data-to-text) -X- _ O
dataset -X- _ O
(Gardent -X- _ O
et -X- _ O
al, -X- _ O
2017). -X- _ O

The -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
is -X- _ O
initialized -X- _ O
to -X- _ O
10 -X- _ B-HyperparameterValue
−3 -X- _ I-HyperparameterValue
and -X- _ O
annealed -X- _ O
in -X- _ O
the -X- _ O
range -X- _ O
of -X- _ O
[10 -X- _ B-HyperparameterValue
−3 -X- _ I-HyperparameterValue
, -X- _ O
10 -X- _ B-HyperparameterValue
−5 -X- _ I-HyperparameterValue
] -X- _ O
with -X- _ O
a -X- _ O
decay -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
0.5. -X- _ B-HyperparameterValue

We -X- _ O
introduce -X- _ O
a -X- _ O
prefix -X- _ O
of -X- _ O
length -X- _ B-MetricName
16 -X- _ B-MetricValue
and -X- _ O
train -X- _ O
a -X- _ O
reparameterization -X- _ O
network -X- _ O
that -X- _ O
updates -X- _ O
0.2% -X- _ B-MetricValue
of -X- _ O
GPT2's -X- _ B-MethodName
parameters -X- _ O
for -X- _ O
commonsense-based -X- _ B-TaskName
question -X- _ I-TaskName
answering. -X- _ I-TaskName

2 -X- _ O
Since -X- _ O
we -X- _ O
change -X- _ O
the -X- _ O
letter -X- _ O
case -X- _ O
in -X- _ O
the -X- _ O
test -X- _ O
data, -X- _ O
we -X- _ O
always -X- _ O
report -X- _ O
case-insensitive -X- _ B-MetricName
BLEU -X- _ I-MetricName
with -X- _ O
'13a' -X- _ O
tokenization -X- _ O
using -X- _ O
sacreBLEU -X- _ B-MethodName
(Post, -X- _ O
2018). -X- _ O

We -X- _ O
report -X- _ O
the -X- _ O
accuracy -X- _ B-MetricName
and -X- _ O
the -X- _ O
F1-score -X- _ B-MetricName
on -X- _ O
six -X- _ O
emotion -X- _ O
categories: -X- _ O
angry, -X- _ O
disgusted, -X- _ O
fear, -X- _ O
happy, -X- _ O
sad -X- _ O
and -X- _ O
surprised. -X- _ O

Some -X- _ O
studies -X- _ O
(Søgaard -X- _ O
et -X- _ O
al, -X- _ O
2018;Ormazabal -X- _ O
et -X- _ O
al, -X- _ O
2019) -X- _ O
claim -X- _ O
that -X- _ O
the -X- _ O
accuracy -X- _ O
of -X- _ O
cross-lingual -X- _ B-TaskName
alignments -X- _ I-TaskName
depends -X- _ O
on -X- _ O
the -X- _ O
similarity -X- _ O
of -X- _ O
word -X- _ O
embeddings -X- _ O
spaces -X- _ O
of -X- _ O
different -X- _ O
languages, -X- _ O
and -X- _ O
this -X- _ O
similarity -X- _ O
in -X- _ O
turn -X- _ O
depends -X- _ O
on -X- _ O
the -X- _ O
similarity -X- _ O
between -X- _ O
the -X- _ O
training -X- _ O
corpora. -X- _ O

We -X- _ O
select -X- _ O
the -X- _ O
dropout -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
from -X- _ O
0.3, -X- _ B-HyperparameterValue
0.2, -X- _ B-HyperparameterValue
and -X- _ O
0.1 -X- _ B-HyperparameterValue
based -X- _ O
on -X- _ O
the -X- _ O
validation -X- _ O
performance. -X- _ O

For -X- _ O
grid -X- _ O
search, -X- _ O
we -X- _ O
take -X- _ O
learning -X- _ B-HyperparameterName
rates -X- _ I-HyperparameterName
from -X- _ O
{1e-5, -X- _ B-HyperparameterValue
2e-5, -X- _ B-HyperparameterValue
5e-5} -X- _ B-HyperparameterValue
and -X- _ O
batch -X- _ B-HyperparameterName
sizes -X- _ I-HyperparameterName
from -X- _ O
{2, -X- _ B-HyperparameterValue
4, -X- _ B-HyperparameterValue
8}. -X- _ B-HyperparameterValue
These -X- _ O
12 -X- _ O
https://www.quora.com/q/quoradata/ -X- _ O
numbers -X- _ O
are -X- _ O
picked -X- _ O
by -X- _ O
pilot -X- _ O
experiments -X- _ O
on -X- _ O
the -X- _ O
SST-2 -X- _ B-DatasetName
and -X- _ B-DatasetName
SNLI -X- _ I-DatasetName
datasets. -X- _ O

The -X- _ O
ELECTRA-small -X- _ B-MethodName
model -X- _ O
we -X- _ O
implemented -X- _ O
follow -X- _ O
all -X- _ O
official -X- _ O
settings -X- _ O
11 -X- _ O
except -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
fully-trained -X- _ O
on -X- _ O
one -X- _ O
GTX -X- _ O
1080Ti -X- _ O
GPU -X- _ O
for -X- _ O
6 -X- _ B-HyperparameterValue
days. -X- _ O

Specifically, -X- _ O
the -X- _ O
major -X- _ O
contributions -X- _ O
are -X- _ O
as -X- _ O
follows. -X- _ O
(1) -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
method -X- _ O
to -X- _ O
create -X- _ O
machine -X- _ O
learning -X- _ O
models -X- _ O
that -X- _ O
are -X- _ O
efficient -X- _ O
and -X- _ O
customized -X- _ O
to -X- _ O
a -X- _ O
given -X- _ O
dataset -X- _ O
for -X- _ O
the -X- _ O
tasks -X- _ O
of -X- _ O
extractive -X- _ B-TaskName
and -X- _ I-TaskName
abstractive -X- _ I-TaskName
summarization, -X- _ I-TaskName
using -X- _ O
a -X- _ O
combination -X- _ O
of -X- _ O
neural -X- _ O
architecture -X- _ O
search -X- _ O
and -X- _ O
task-specific -X- _ O
knowledge -X- _ O
distillation -X- _ O
from -X- _ O
large -X- _ O
language -X- _ O
models. -X- _ O

Current -X- _ O
research -X- _ O
on -X- _ O
hate -X- _ B-TaskName
speech -X- _ I-TaskName
analysis -X- _ I-TaskName
is -X- _ O
typically -X- _ O
oriented -X- _ O
towards -X- _ O
monolingual -X- _ O
and -X- _ O
single -X- _ O
classification -X- _ O
tasks. -X- _ O

Then -X- _ O
we -X- _ O
have -X- _ O
d -X- _ B-HyperparameterName
c -X- _ I-HyperparameterName
= -X- _ O
768, -X- _ B-HyperparameterValue
d -X- _ B-HyperparameterName
l -X- _ I-HyperparameterName
= -X- _ O
d -X- _ B-HyperparameterName
s -X- _ I-HyperparameterName
= -X- _ O
32, -X- _ B-HyperparameterValue
h -X- _ B-HyperparameterName
p -X- _ I-HyperparameterName
= -X- _ O
h -X- _ B-HyperparameterName
s -X- _ I-HyperparameterName
= -X- _ O
768. -X- _ B-HyperparameterValue

As -X- _ O
for -X- _ O
the -X- _ O
balance -X- _ B-HyperparameterName
coefficient -X- _ I-HyperparameterName
α -X- _ B-HyperparameterName
in -X- _ O
the -X- _ O
loss -X- _ O
function, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
α -X- _ B-HyperparameterName
= -X- _ O
0.4 -X- _ B-HyperparameterValue
can -X- _ O
achieve -X- _ O
the -X- _ O
best -X- _ O
performance, -X- _ O
indicating -X- _ O
that -X- _ O
the -X- _ O
margin -X- _ O
loss -X- _ O
plays -X- _ O
a -X- _ O
more -X- _ O
significant -X- _ O
role -X- _ O
in -X- _ O
training -X- _ O
ZS-BERT. -X- _ B-MethodName

In -X- _ O
this -X- _ O
work -X- _ O
we -X- _ O
adopt -X- _ O
the -X- _ O
15 -X- _ B-HyperparameterValue
fine-grained -X- _ O
discourse -X- _ O
relation -X- _ O
sense -X- _ O
types -X- _ O
from -X- _ O
the -X- _ O
annotation -X- _ O
scheme -X- _ O
of -X- _ O
the -X- _ O
Penn -X- _ B-DatasetName
Discourse -X- _ I-DatasetName
Tree -X- _ I-DatasetName
Bank -X- _ I-DatasetName
(PDTB) -X- _ B-DatasetName
(Prasad -X- _ O
et -X- _ O
al, -X- _ O
2008). -X- _ O

We -X- _ O
set -X- _ O
the -X- _ O
max -X- _ B-HyperparameterName
sequence -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
to -X- _ O
128 -X- _ B-MetricValue
and -X- _ O
follow -X- _ O
the -X- _ O
preprocess -X- _ O
and -X- _ O
WordPiece -X- _ O
tokenization -X- _ O
of -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
(2018). -X- _ O

For -X- _ O
textual -X- _ O
entailment -X- _ O
on -X- _ B-DatasetName
RTE -X- _ I-DatasetName
dataset, -X- _ O
we -X- _ O
refer -X- _ O
to -X- _ O
the -X- _ O
guideline -X- _ O
from -X- _ O
the -X- _ O
original -X- _ O
guide -X- _ O
line -X- _ O
of -X- _ O
RTE-4 -X- _ B-DatasetName
13 -X- _ O
to -X- _ O
explain -X- _ O
the -X- _ O
textual -X- _ O
entailment -X- _ O
task -X- _ O
itself -X- _ O
with -X- _ O
examples. -X- _ O

We -X- _ O
thus -X- _ O
propose -X- _ O
an -X- _ O
approach, -X- _ O
named -X- _ O
as -X- _ O
ARSJOINT, -X- _ B-MethodName
that -X- _ O
jointly -X- _ O
learns -X- _ O
the -X- _ O
modules -X- _ O
for -X- _ O
the -X- _ O
three -X- _ O
tasks -X- _ O
with -X- _ O
a -X- _ O
machine -X- _ B-TaskName
reading -X- _ I-TaskName
comprehension -X- _ I-TaskName
framework -X- _ O
by -X- _ O
including -X- _ O
claim -X- _ O
information. -X- _ O

We -X- _ O
show -X- _ O
further -X- _ O
gains -X- _ O
(84.9 -X- _ B-MetricValue
to -X- _ O
85.2 -X- _ B-MetricValue
for -X- _ O
DIET-REL) -X- _ B-DatasetName
by -X- _ O
moving -X- _ O
segment -X- _ O
features -X- _ O
to -X- _ O
perhead. -X- _ O

For -X- _ O
XLM-RoBERTa-base -X- _ B-MethodName
model, -X- _ O
the -X- _ O
average -X- _ O
runtime -X- _ O
for -X- _ O
each -X- _ O
epoch -X- _ O
is -X- _ O
approximately -X- _ O
3.3 -X- _ O
minutes -X- _ O
hour -X- _ O
for -X- _ O
training -X- _ O
and -X- _ O
0.5 -X- _ O
minute -X- _ O
for -X- _ O
evaluating -X- _ O
and -X- _ O
testing. -X- _ O

In -X- _ O
this -X- _ O
paper, -X- _ O
we -X- _ O
model -X- _ O
bridging -X- _ B-TaskName
anaphora -X- _ I-TaskName
resolution -X- _ I-TaskName
as -X- _ O
a -X- _ B-TaskName
question -X- _ I-TaskName
answering -X- _ I-TaskName
problem -X- _ O
and -X- _ O
propose -X- _ O
a -X- _ O
QA -X- _ O
system -X- _ O
(BARQA) -X- _ B-MethodName
to -X- _ O
solve -X- _ O
the -X- _ O
task. -X- _ O

Hi-MAP -X- _ B-MethodName
(Fabbri -X- _ O
et -X- _ O
al, -X- _ O
2019) -X- _ O
expands -X- _ O
the -X- _ O
pointer-generator -X- _ O
network -X- _ O
model -X- _ O
into -X- _ O
a -X- _ O
hierarchical -X- _ O
network -X- _ O
and -X- _ O
integrates -X- _ O
an -X- _ O
MMR -X- _ O
module -X- _ O
to -X- _ O
calculate -X- _ O
sentence-level -X- _ O
scores, -X- _ O
which -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ B-DatasetName
Multi-News -X- _ I-DatasetName
corpus. -X- _ O

For -X- _ O
the -X- _ O
FewShotWeather/SGD -X- _ B-DatasetName
datasets, -X- _ O
we -X- _ O
consider -X- _ O
models -X- _ O
trained -X- _ O
with -X- _ O
1shot-250/5-shot -X- _ O
splits -X- _ O
and -X- _ O
compare -X- _ O
them -X- _ O
with -X- _ O
models -X- _ O
fine-tuned -X- _ O
on -X- _ O
the -X- _ O
full -X- _ O
dataset. -X- _ O

The -X- _ O
activation -X- _ O
functions -X- _ O
used -X- _ O
by -X- _ O
the -X- _ O
hidden -X- _ O
layers -X- _ O
are -X- _ O
the -X- _ O
Rectified -X- _ B-MethodName
Linear -X- _ I-MethodName
Unit -X- _ I-MethodName
(ReLU), -X- _ B-MethodName
which -X- _ O
outputs -X- _ O
max{0, -X- _ O
x} -X- _ O
for -X- _ O
an -X- _ O
input -X- _ O
x. -X- _ O
All -X- _ O
layers -X- _ O
are -X- _ O
fully -X- _ O
connected -X- _ O
and -X- _ O
none -X- _ O
of -X- _ O
them -X- _ O
use -X- _ O
dropout. -X- _ O

Though -X- _ O
the -X- _ O
majority -X- _ O
of -X- _ O
the -X- _ O
experiments -X- _ O
presented -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
use -X- _ O
the -X- _ O
dual -X- _ O
encoder -X- _ O
architecture -X- _ O
(Lowe -X- _ O
et -X- _ O
al, -X- _ O
2015), -X- _ O
MGT -X- _ B-MethodName
is -X- _ O
applied -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
the -X- _ O
state-of-theart -X- _ O
architecture -X- _ O
for -X- _ O
Ubuntu: -X- _ O
the -X- _ O
Deep -X- _ B-MethodName
Attention -X- _ I-MethodName
Matching -X- _ I-MethodName
Network -X- _ I-MethodName
(DAM) -X- _ B-MethodName
(Zhou -X- _ O
et -X- _ O
al, -X- _ O
2018). -X- _ O

According -X- _ O
to -X- _ O
the -X- _ O
types -X- _ O
of -X- _ O
visual -X- _ O
encoders, -X- _ O
e.g. -X- _ O
ResNet -X- _ B-MethodName
or -X- _ O
ViT, -X- _ B-MethodName
CLIP -X- _ B-MethodName
models -X- _ O
have -X- _ O
different -X- _ O
variants, -X- _ O
resulting -X- _ O
in -X- _ O
a -X- _ O
significant -X- _ O
difference -X- _ O
in -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
learnable -X- _ O
bias -X- _ O
and -X- _ O
normalization -X- _ O
parameters. -X- _ O

The -X- _ O
LSTM -X- _ B-MethodName
with -X- _ O
only -X- _ O
word -X- _ O
embeddings -X- _ O
obtains -X- _ O
worse -X- _ O
results -X- _ O
predicting -X- _ O
possession -X- _ O
durations -X- _ O
(0.77 -X- _ B-MetricValue
vs. -X- _ O
0.82 -X- _ B-MetricValue
weighted -X- _ B-MetricName
Fmeasure), -X- _ I-MetricName
and -X- _ O
virtually -X- _ O
the -X- _ O
same -X- _ O
results -X- _ O
predicting -X- _ O
co-possessions -X- _ O
(0.72 -X- _ B-MetricValue
vs. -X- _ O
0.73 -X- _ B-MetricValue
weighted -X- _ B-MetricName
Fmeasure). -X- _ I-MetricName

We -X- _ O
generate -X- _ O
the -X- _ O
utterance-level -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
publicly -X- _ O
accesible -X- _ O
raw -X- _ B-DatasetName
CMU-MOSEI -X- _ I-DatasetName
dataset. -X- _ O

We -X- _ O
formulate -X- _ O
this -X- _ O
keyword -X- _ B-TaskName
prediction -X- _ I-TaskName
problem -X- _ O
similar -X- _ O
to -X- _ O
a -X- _ O
left-to-right -X- _ B-TaskName
language -X- _ I-TaskName
model -X- _ I-TaskName
where -X- _ O
the -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
string -X- _ O
of -X- _ O
concatenated -X- _ O
keywords: -X- _ O
p(K -X- _ O
i -X- _ O
|X -X- _ O
i−1 -X- _ O
) -X- _ O
= -X- _ O
q -X- _ O
j=1 -X- _ O
p(k -X- _ O
i -X- _ O
j -X- _ O
|X -X- _ O
i−1 -X- _ O
, -X- _ O
K -X- _ O
i -X- _ O
<j -X- _ O
), -X- _ O
(1) -X- _ O
where -X- _ O
K -X- _ O
<j -X- _ O
denotes -X- _ O
all -X- _ O
the -X- _ O
predicted -X- _ O
keywords -X- _ O
up -X- _ O
to -X- _ O
the -X- _ O
jth -X- _ O
keyword -X- _ O
and -X- _ O
p -X- _ O
is -X- _ O
the -X- _ O
probability -X- _ O
distribution. -X- _ O

For -X- _ B-TaskName
dependency -X- _ I-TaskName
parsing, -X- _ I-TaskName
we -X- _ O
follow -X- _ O
Kondratyuk -X- _ O
and -X- _ O
Straka -X- _ O
(2019) -X- _ O
and -X- _ O
use -X- _ O
mBERT -X- _ B-MethodName
embeddings -X- _ O
with -X- _ O
the -X- _ O
graph-based -X- _ O
bi-affine -X- _ O
attention -X- _ O
parser -X- _ O
(Dozat -X- _ O
and -X- _ O
Manning, -X- _ O
2017); -X- _ O
refer -X- _ O
Appendix -X- _ O
A -X- _ O
for -X- _ O
details. -X- _ O

The -X- _ O
Telco -X- _ B-DatasetName
dataset -X- _ O
contains -X- _ O
4,093 -X- _ O
exemplars -X- _ O
and -X- _ O
87 -X- _ O
intents. -X- _ O

Composite -X- _ B-DatasetName
Dataset -X- _ O
(Aditya -X- _ O
et -X- _ O
al, -X- _ O
2015) -X- _ O
contains -X- _ O
the -X- _ O
candidate -X- _ O
captions -X- _ O
of -X- _ O
images -X- _ O
from -X- _ O
MS-COCO, -X- _ B-DatasetName
Flickr8k, -X- _ B-DatasetName
and -X- _ O
Flickr30k. -X- _ B-DatasetName

For -X- _ O
each -X- _ O
image, -X- _ O
we -X- _ O
detect -X- _ O
100 -X- _ B-HyperparameterValue
bounding -X- _ B-HyperparameterName
boxes -X- _ I-HyperparameterName
using -X- _ O
Faster-RCNN -X- _ B-MethodName
pre-trained -X- _ O
on -X- _ O
Visual -X- _ B-DatasetName
Genome -X- _ I-DatasetName
(Krishna -X- _ O
et -X- _ O
al, -X- _ O
2017) -X- _ O
by -X- _ O
Anderson -X- _ O
et -X- _ O
al -X- _ O
(2018). -X- _ O

Empirically, -X- _ O
this -X- _ O
shows -X- _ O
the -X- _ O
superiority -X- _ O
of -X- _ O
the -X- _ O
FE2E -X- _ B-MethodName
model -X- _ O
over -X- _ O
the -X- _ O
two-phase -X- _ O
pipeline. -X- _ O

To -X- _ O
explore -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
neighborhood -X- _ O
sampling -X- _ O
strategies, -X- _ O
we -X- _ O
compare -X- _ O
our -X- _ O
NMN -X- _ B-MethodName
with -X- _ O
a -X- _ O
variant -X- _ O
that -X- _ O
uses -X- _ O
random -X- _ O
sampling -X- _ O
strategy -X- _ O
on -X- _ O
S-DBP15K -X- _ B-DatasetName
datasets. -X- _ O

The -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
is -X- _ O
warmed -X- _ O
up -X- _ O
over -X- _ O
the -X- _ O
first -X- _ O
100,000 -X- _ B-HyperparameterValue
steps -X- _ O
to -X- _ O
a -X- _ O
peak -X- _ O
value -X- _ O
of -X- _ O
1e-4, -X- _ B-HyperparameterValue
then -X- _ O
linearly -X- _ O
decayed. -X- _ O

5 -X- _ O
Few-shot -X- _ O
Learning -X- _ O
for -X- _ B-DatasetName
VQA -X- _ I-DatasetName
In -X- _ O
this -X- _ O
section, -X- _ O
We -X- _ O
aim -X- _ O
to -X- _ O
investigate -X- _ O
whether -X- _ O
the -X- _ B-MethodName
CLIP -X- _ I-MethodName
models -X- _ O
could -X- _ O
benefit -X- _ O
from -X- _ O
few-shot -X- _ O
learning, -X- _ O
where -X- _ O
we -X- _ O
work -X- _ O
on -X- _ O
the -X- _ B-TaskName
visual -X- _ I-TaskName
question -X- _ I-TaskName
answering -X- _ I-TaskName
task -X- _ O
to -X- _ O
study -X- _ O
it. -X- _ O

For -X- _ O
the -X- _ B-DatasetName
Natural -X- _ I-DatasetName
Questions -X- _ I-DatasetName
and -X- _ B-DatasetName
TriviaQA -X- _ I-DatasetName
experiments, -X- _ O
we -X- _ O
use -X- _ O
our -X- _ O
own -X- _ O
split -X- _ O
as -X- _ O
mentioned -X- _ O
in -X- _ O
the -X- _ O
above. -X- _ O

Table -X- _ O
3 -X- _ O
presents -X- _ O
a -X- _ O
comparison -X- _ O
of -X- _ O
these -X- _ O
three -X- _ O
architectures -X- _ O
on -X- _ B-DatasetName
KP20k -X- _ I-DatasetName
dataset. -X- _ O

We -X- _ O
pre-trained -X- _ O
several -X- _ O
masked -X- _ O
language -X- _ O
models -X- _ O
(GigaBERTs) -X- _ B-MethodName
for -X- _ O
Arabic-English -X- _ O
and -X- _ O
conducted -X- _ O
a -X- _ O
focused -X- _ O
study -X- _ O
on -X- _ B-TaskName
information -X- _ I-TaskName
extraction -X- _ I-TaskName
tasks -X- _ O
in -X- _ O
the -X- _ O
newswire -X- _ O
domain. -X- _ O

We -X- _ O
also -X- _ O
apply -X- _ O
the -X- _ O
main -X- _ O
idea -X- _ O
of -X- _ O
BFR-Graph -X- _ B-MethodName
to -X- _ O
the -X- _ B-DatasetName
WikiHop -X- _ I-DatasetName
dataset -X- _ O
(Welbl -X- _ O
et -X- _ O
al, -X- _ O
2018), -X- _ O
which -X- _ O
provides -X- _ O
candidate -X- _ O
answers -X- _ O
for -X- _ O
selection -X- _ O
while -X- _ O
Hot-potQA -X- _ B-DatasetName
dataset -X- _ O
needs -X- _ O
to -X- _ O
find -X- _ O
an -X- _ O
answer -X- _ O
span -X- _ O
over -X- _ O
all -X- _ O
paragraphs. -X- _ O

Compared -X- _ O
to -X- _ O
the -X- _ B-DatasetName
ECtHR -X- _ I-DatasetName
tasks, -X- _ O
the -X- _ O
gains -X- _ O
are -X- _ O
lower -X- _ O
in -X- _ O
SCOTUS, -X- _ B-DatasetName
a -X- _ O
topic -X- _ O
classification -X- _ O
task -X- _ O
where -X- _ O
long-range -X- _ O
reasoning -X- _ O
is -X- _ O
not -X- _ O
needed; -X- _ O
by -X- _ O
contrast, -X- _ O
for -X- _ O
ECtHR -X- _ B-DatasetName
multiple -X- _ O
distant -X- _ O
facts -X- _ O
need -X- _ O
to -X- _ O
be -X- _ O
combined. -X- _ O

Weighted -X- _ B-MetricName
Accuracy -X- _ I-MetricName
Similar -X- _ O
to -X- _ O
existing -X- _ O
works -X- _ O
(Zadeh -X- _ O
et -X- _ O
al, -X- _ O
2018b;Akhtar -X- _ O
et -X- _ O
al, -X- _ O
2019), -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
weighted -X- _ B-MetricName
accuracy -X- _ I-MetricName
(WAcc) -X- _ B-MetricName
(Tong -X- _ O
et -X- _ O
al, -X- _ O
2017) -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ B-DatasetName
CMU-MOSEI -X- _ I-DatasetName
dataset, -X- _ O
which -X- _ O
contains -X- _ O
many -X- _ O
more -X- _ O
negative -X- _ O
samples -X- _ O
than -X- _ O
positive -X- _ O
ones -X- _ O
on -X- _ O
each -X- _ O
emotion -X- _ O
category. -X- _ O

Results -X- _ O
using -X- _ O
two -X- _ O
NLI -X- _ B-TaskName
models -X- _ O
fine-tuned -X- _ O
on -X- _ B-DatasetName
MultiNLI -X- _ I-DatasetName
(Williams -X- _ O
et -X- _ O
al, -X- _ O
2018), -X- _ O
BERT -X- _ B-DatasetName
NLI, -X- _ I-DatasetName
and -X- _ O
ESIM -X- _ B-DatasetName
(Chen -X- _ O
et -X- _ O
al, -X- _ O
2017), -X- _ O
are -X- _ O
from -X- _ O
Falke -X- _ O
et -X- _ O
al -X- _ O
(2019). -X- _ O

To -X- _ O
address -X- _ O
the -X- _ O
issues, -X- _ O
we -X- _ O
propose -X- _ O
meta -X- _ B-MethodName
graph -X- _ I-MethodName
learning -X- _ I-MethodName
(MGL), -X- _ B-MethodName
a -X- _ O
meta -X- _ O
learning -X- _ O
framework -X- _ O
to -X- _ O
learn -X- _ O
how -X- _ O
to -X- _ B-TaskName
cross-lingual -X- _ I-TaskName
transfer -X- _ I-TaskName
for -X- _ O
mPLM. -X- _ O

Table -X- _ O
6 -X- _ O
shows -X- _ O
performance -X- _ O
improvement -X- _ O
on -X- _ O
small -X- _ O
(2k-15k) -X- _ O
datasets, -X- _ O
which -X- _ O
include -X- _ O
SICK, -X- _ B-DatasetName
STS-B, -X- _ B-DatasetName
MRPC, -X- _ B-DatasetName
RTE, -X- _ B-DatasetName
WikiQA, -X- _ B-DatasetName
and -X- _ O
PIT, -X- _ B-DatasetName
but -X- _ O
little -X- _ O
or -X- _ O
no -X- _ O
improvement -X- _ O
on -X- _ O
large -X- _ O
(40k-550k) -X- _ O
datasets, -X- _ O
such -X- _ O
as -X- _ O
SNLI, -X- _ B-DatasetName
MNLI, -X- _ B-DatasetName
and -X- _ O
QQP. -X- _ B-DatasetName

The -X- _ O
embeddings -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
is -X- _ O
300 -X- _ B-HyperparameterValue
which -X- _ O
are -X- _ O
initialized -X- _ O
with -X- _ O
pretrained -X- _ O
GloVe -X- _ B-MethodName
(Pennington -X- _ O
et -X- _ O
al, -X- _ O
2014) -X- _ O
vectors. -X- _ O

The -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
LSTM -X- _ B-MethodName
hidden -X- _ B-HyperparameterName
state -X- _ I-HyperparameterName
is -X- _ O
256. -X- _ B-HyperparameterValue

While -X- _ O
MetaLDA -X- _ B-MethodName
generated -X- _ O
higher -X- _ O
C -X- _ B-MetricName
NPMI-ABC -X- _ I-MetricName
scores -X- _ I-MetricName
than -X- _ O
LDA -X- _ B-MethodName
for -X- _ O
all -X- _ O
aggregates, -X- _ O
it -X- _ O
was -X- _ O
highly -X- _ O
dependent -X- _ O
on -X- _ O
dataset -X- _ O
heterogeneity -X- _ O
and -X- _ O
the -X- _ O
value -X- _ O
of -X- _ O
K. -X- _ B-HyperparameterName
This -X- _ O
should -X- _ O
indicate -X- _ O
that -X- _ O
MetaLDA -X- _ B-MethodName
is -X- _ O
more -X- _ O
adaptive -X- _ O
to -X- _ O
specialized -X- _ O
language, -X- _ O
an -X- _ O
effect -X- _ O
expected -X- _ O
in -X- _ O
other -X- _ O
topic -X- _ O
models -X- _ O
supported -X- _ O
by -X- _ O
word -X- _ O
embeddings. -X- _ O

It -X- _ O
is -X- _ O
worth -X- _ O
mentioning -X- _ O
that -X- _ O
our -X- _ O
NMT -X- _ B-MethodName
model -X- _ O
achieves -X- _ O
better -X- _ O
performance -X- _ O
with -X- _ O
less -X- _ O
training -X- _ O
parameters -X- _ O
-the -X- _ O
hidden -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
our -X- _ O
NMT -X- _ B-MethodName
model -X- _ O
is -X- _ O
768 -X- _ B-HyperparameterValue
but -X- _ O
1024 -X- _ B-HyperparameterValue
for -X- _ O
the -X- _ O
prior -X- _ O
existing -X- _ O
works. -X- _ O

We -X- _ O
present -X- _ O
RuleNN, -X- _ B-MethodName
a -X- _ O
neural -X- _ O
network -X- _ O
architecture -X- _ O
for -X- _ O
learning -X- _ O
transparent -X- _ O
models -X- _ O
for -X- _ O
sentence -X- _ B-TaskName
classification. -X- _ I-TaskName

In -X- _ O
this -X- _ O
paper, -X- _ O
we -X- _ O
presented -X- _ O
a -X- _ O
new -X- _ O
multimodal -X- _ O
dataset -X- _ O
for -X- _ B-TaskName
humor -X- _ I-TaskName
detection -X- _ I-TaskName
called -X- _ B-DatasetName
UR-FUNNY. -X- _ I-DatasetName

Unsurprisingly, -X- _ O
IT-MULTIPROVER -X- _ B-MethodName
takes -X- _ O
longer -X- _ O
to -X- _ O
train -X- _ O
but -X- _ O
encouragingly -X- _ O
for -X- _ O
p -X- _ B-HyperparameterName
≤ -X- _ O
4, -X- _ B-HyperparameterValue
still -X- _ O
has -X- _ O
a -X- _ O
comparable -X- _ O
running -X- _ O
time -X- _ O
to -X- _ O
PROVER. -X- _ B-MethodName

We -X- _ O
think -X- _ O
this -X- _ O
is -X- _ O
partly -X- _ O
because -X- _ O
of -X- _ O
the -X- _ O
relatively -X- _ O
low -X- _ O
performance -X- _ O
of -X- _ O
constituent -X- _ B-TaskName
parsing -X- _ I-TaskName
(93.55 -X- _ B-MetricValue
F1 -X- _ B-MetricName
score) -X- _ I-MetricName
compared -X- _ O
with -X- _ O
dependency -X- _ B-TaskName
parsing -X- _ I-TaskName
(95.7 -X- _ B-MetricValue
F1 -X- _ B-MetricName
score). -X- _ I-MetricName

The -X- _ O
comparison -X- _ O
shows -X- _ O
that -X- _ O
Atten-tionRank -X- _ B-MethodName
works -X- _ O
better -X- _ O
than -X- _ O
KeyGames -X- _ B-MethodName
(Saxena -X- _ O
et -X- _ O
al, -X- _ O
2020) -X- _ O
on -X- _ O
SemEval2010 -X- _ B-DatasetName
by -X- _ O
0.5%, -X- _ B-MetricValue
although -X- _ O
KayGames -X- _ B-MethodName
used -X- _ O
a -X- _ O
designed -X- _ O
candidate -X- _ O
selection -X- _ O
approach -X- _ O
to -X- _ O
remove -X- _ O
noise. -X- _ O

To -X- _ O
evaluate -X- _ O
the -X- _ O
robustness -X- _ O
of -X- _ O
the -X- _ O
ExCAR -X- _ B-MethodName
framework, -X- _ O
we -X- _ O
build -X- _ O
an -X- _ O
additional -X- _ O
Chinese -X- _ B-TaskName
commonsense -X- _ I-TaskName
causal -X- _ I-TaskName
reasoning -X- _ I-TaskName
dataset -X- _ O
C-COPA. -X- _ B-DatasetName

To -X- _ O
check -X- _ O
if -X- _ O
representations -X- _ O
are -X- _ O
sensitive -X- _ O
to -X- _ O
input -X- _ O
length, -X- _ O
we -X- _ O
truncated -X- _ O
the -X- _ O
articles -X- _ O
to -X- _ O
the -X- _ O
first -X- _ O
400 -X- _ B-MetricValue
or -X- _ O
750 -X- _ B-MetricValue
tokens -X- _ O
when -X- _ O
the -X- _ O
length -X- _ B-HyperparameterName
exceeds -X- _ O
that -X- _ O
limit. -X- _ O

To -X- _ O
tackle -X- _ O
the -X- _ O
learning -X- _ O
problem, -X- _ O
we -X- _ O
introduce -X- _ O
PLOTCODER, -X- _ B-MethodName
a -X- _ O
new -X- _ O
hierarchical -X- _ O
encoder-decoder -X- _ O
architecture -X- _ O
that -X- _ O
models -X- _ O
both -X- _ O
the -X- _ O
code -X- _ O
context -X- _ O
and -X- _ O
the -X- _ O
input -X- _ O
utterance. -X- _ O

For -X- _ O
x-axes -X- _ O
with -X- _ O
more -X- _ O
than -X- _ O
one -X- _ O
demographic -X- _ O
characteristic -X- _ O
under -X- _ O
consideration, -X- _ O
we -X- _ O
report -X- _ O
the -X- _ O
mean -X- _ O
ADI -X- _ B-MetricName
and -X- _ O
95% -X- _ B-MetricName
confidence -X- _ I-MetricName
intervals. -X- _ I-MetricName

However, -X- _ O
compared -X- _ O
with -X- _ O
BERT, -X- _ B-MethodName
STANKER -X- _ B-MethodName
gained -X- _ O
an -X- _ O
up -X- _ O
to -X- _ O
1.4% -X- _ B-MetricValue
accuracy -X- _ B-MetricName
improvement -X- _ O
on -X- _ O
Weibo -X- _ B-DatasetName
datasets -X- _ O
and -X- _ O
3.5% -X- _ B-MetricValue
accuracy -X- _ B-MetricName
improvement -X- _ O
on -X- _ O
Twitter -X- _ B-DatasetName
datasets. -X- _ O

Of -X- _ O
note -X- _ O
is -X- _ O
the -X- _ B-DatasetName
Broad -X- _ I-DatasetName
Twitter -X- _ I-DatasetName
Corpus -X- _ I-DatasetName
(Derczynski -X- _ O
et -X- _ O
al, -X- _ O
2016), -X- _ O
which -X- _ O
contains -X- _ O
tweets -X- _ O
collected -X- _ O
over -X- _ O
several -X- _ O
years, -X- _ O
from -X- _ O
2009 -X- _ O
to -X- _ O
2014. -X- _ O

The -X- _ O
encoder -X- _ O
is -X- _ O
made -X- _ O
up -X- _ O
of -X- _ O
five -X- _ B-HyperparameterValue
convolutional -X- _ B-HyperparameterName
layers, -X- _ I-HyperparameterName
the -X- _ O
quantizer -X- _ O
is -X- _ O
a -X- _ O
dictionary -X- _ O
of -X- _ O
possible -X- _ O
representations, -X- _ O
and -X- _ O
the -X- _ O
decoder -X- _ O
is -X- _ O
made -X- _ O
up -X- _ O
of -X- _ O
12 -X- _ B-HyperparameterValue
transformer -X- _ B-HyperparameterName
layers. -X- _ I-HyperparameterName

Methods -X- _ O
that -X- _ O
use -X- _ O
auxiliary -X- _ O
tasks -X- _ O
(Utt -X- _ O
Class -X- _ O
and -X- _ O
Utt -X- _ O
Gen) -X- _ O
outperform -X- _ O
other -X- _ O
methods -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
average -X- _ O
ranking -X- _ O
overall -X- _ O
and -X- _ O
per -X- _ O
game -X- _ O
while -X- _ O
also -X- _ O
maintaining -X- _ O
higher -X- _ O
accuracy -X- _ B-MetricName
and -X- _ O
F1-score -X- _ B-MetricName
for -X- _ O
each -X- _ O
class. -X- _ O

Secondly, -X- _ O
for -X- _ O
the -X- _ O
question -X- _ B-TaskName
disambiguation -X- _ I-TaskName
subtask, -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
mismatch -X- _ O
between -X- _ O
question -X- _ O
generation -X- _ O
pre-training -X- _ O
on -X- _ O
NQ-OPEN -X- _ B-DatasetName
and -X- _ O
question -X- _ O
disambiguation -X- _ O
finetuning -X- _ O
on -X- _ O
AMBIGQA -X- _ B-DatasetName
-there -X- _ O
is -X- _ O
no -X- _ O
question -X- _ O
to -X- _ O
disambiguate -X- _ O
in -X- _ O
question -X- _ O
generation -X- _ O
pre-training, -X- _ O
which -X- _ O
makes -X- _ O
the -X- _ O
pre-training -X- _ O
task -X- _ O
somewhat -X- _ O
misaligned -X- _ O
with -X- _ O
fine-tuning. -X- _ O

We -X- _ O
set -X- _ O
the -X- _ O
discount -X- _ B-HyperparameterValue
factor -X- _ I-HyperparameterValue
as -X- _ O
γ -X- _ B-HyperparameterValue
= -X- _ O
0.9. -X- _ B-HyperparameterName

To -X- _ O
this -X- _ O
end, -X- _ O
we -X- _ O
make -X- _ O
use -X- _ O
of -X- _ O
the -X- _ O
existing -X- _ O
gold -X- _ O
standard -X- _ O
datasets -X- _ O
for -X- _ B-TaskName
AMR -X- _ I-TaskName
parsing, -X- _ I-TaskName
i.e., -X- _ O
English -X- _ O
sentence-AMR -X- _ O
graph -X- _ O
pairs, -X- _ O
and -X- _ O
use -X- _ B-TaskName
machine -X- _ I-TaskName
translation -X- _ I-TaskName
systems -X- _ O
to -X- _ O
translate -X- _ O
the -X- _ O
training -X- _ O
sentences -X- _ O
into -X- _ O
the -X- _ O
target -X- _ O
language. -X- _ O

SimBA -X- _ B-MethodName
Given -X- _ O
a -X- _ O
target -X- _ O
record -X- _ O
r -X- _ O
t -X- _ O
, -X- _ O
SimBA -X- _ B-MethodName
scores -X- _ O
each -X- _ O
of -X- _ O
its -X- _ O
twins -X- _ O
by -X- _ O
the -X- _ O
CPS -X- _ B-MethodName
model -X- _ O
and -X- _ O
predicts -X- _ O
the -X- _ O
answer -X- _ O
for -X- _ O
q -X- _ O
t -X- _ O
, -X- _ O
using -X- _ O
Equation -X- _ O
3. -X- _ O

On -X- _ O
OVERNIGHT -X- _ B-DatasetName
with -X- _ O
memory -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
50, -X- _ B-HyperparameterValue
the -X- _ O
gap -X- _ O
between -X- _ O
DLFS -X- _ B-MethodName
and -X- _ O
GSS -X- _ B-MethodName
is -X- _ O
even -X- _ O
up -X- _ O
to -X- _ O
11% -X- _ B-MetricValue
and -X- _ O
2% -X- _ B-MetricValue
between -X- _ O
DLFS -X- _ B-MethodName
and -X- _ O
FSS, -X- _ B-MethodName
the -X- _ O
best -X- _ O
baseline. -X- _ O

Prof. -X- _ O
Benjamin -X- _ O
E. -X- _ O
Frey -X- _ O
is -X- _ O
a -X- _ O
proficient -X- _ O
second-language -X- _ O
Cherokee -X- _ O
speaker -X- _ O
and -X- _ O
a -X- _ O
citizen -X- _ O
of -X- _ O
the -X- _ O
Eastern -X- _ O
Band -X- _ O
of -X- _ O
Cherokee -X- _ O
Indians. -X- _ O
He -X- _ O
has -X- _ O
been -X- _ O
teaching -X- _ O
Cherokee -X- _ O
and -X- _ O
contributing -X- _ O
to -X- _ O
Cherokee -X- _ O
revitalization -X- _ O
for -X- _ O
more -X- _ O
than -X- _ O
10 -X- _ O
years. -X- _ O

Similar -X- _ O
to -X- _ O
prior -X- _ B-TaskName
code -X- _ I-TaskName
generation -X- _ I-TaskName
tasks, -X- _ O
we -X- _ O
use -X- _ O
Exact -X- _ B-MetricName
Match -X- _ I-MetricName
(EM) -X- _ I-MetricName
accuracy -X- _ I-MetricName
and -X- _ O
corpus-level -X- _ B-MetricName
BLEU -X- _ I-MetricName
score -X- _ I-MetricName
(Papineni -X- _ O
et -X- _ O
al, -X- _ O
2002) -X- _ O
as -X- _ O
performance -X- _ O
metrics -X- _ O
for -X- _ O
full -X- _ B-TaskName
code -X- _ I-TaskName
generation. -X- _ I-TaskName

For -X- _ B-MethodName
ARCT, -X- _ I-MethodName
the -X- _ O
best -X- _ O
scoring -X- _ O
model -X- _ O
is -X- _ O
RoBERTa-Large, -X- _ B-MethodName
having -X- _ O
an -X- _ O
encouraging -X- _ O
gap -X- _ O
of -X- _ O
only -X- _ O
0.094 -X- _ B-MetricValue
accuracy -X- _ B-MetricName
to -X- _ O
the -X- _ O
human -X- _ B-MethodName
upperbound. -X- _ I-MethodName

Rosenman -X- _ O
et -X- _ O
al -X- _ O
(2020) -X- _ O
list -X- _ O
several -X- _ O
"lazy" -X- _ O
strategies -X- _ O
employed -X- _ O
by -X- _ O
supervised -X- _ O
SOTA -X- _ O
models -X- _ O
in -X- _ O
the -X- _ B-DatasetName
TACRED -X- _ I-DatasetName
challenge, -X- _ O
including -X- _ O
the -X- _ O
"entity-type -X- _ O
heuristic" -X- _ O
which -X- _ O
relies -X- _ O
solely -X- _ O
on -X- _ O
entity -X- _ O
types, -X- _ O
ignoring -X- _ O
context. -X- _ O

We -X- _ O
also -X- _ O
observe -X- _ O
that -X- _ O
TANL -X- _ B-MethodName
scores -X- _ O
extremely -X- _ O
low -X- _ O
on -X- _ O
both -X- _ O
RE -X- _ B-TaskName
tasks, -X- _ O
where -X- _ O
58% -X- _ B-MetricValue
of -X- _ O
the -X- _ O
binary -X- _ O
relations -X- _ O
and -X- _ O
26 -X- _ B-MetricValue
% -X- _ I-MetricValue
of -X- _ O
the -X- _ O
4-ary -X- _ O
relations -X- _ O
in -X- _ O
the -X- _ O
decoding -X- _ O
targets -X- _ O
are -X- _ O
filtered -X- _ O
out -X- _ O
due -X- _ O
to -X- _ O
exceeding -X- _ O
maximum -X- _ O
sequence -X- _ O
length -X- _ O
of -X- _ O
BART. -X- _ B-MethodName

The -X- _ O
standard -X- _ O
approach -X- _ O
to -X- _ O
end-to-end -X- _ B-TaskName
open-domain -X- _ I-TaskName
QA -X- _ I-TaskName
is -X- _ O
(1) -X- _ O
use -X- _ O
an -X- _ O
efficient -X- _ O
filtering -X- _ O
approach -X- _ O
to -X- _ O
reduce -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
candidate -X- _ O
passages -X- _ O
to -X- _ O
the -X- _ O
top-k -X- _ O
of -X- _ O
the -X- _ O
most -X- _ O
relevant -X- _ O
ones -X- _ O
(usually -X- _ O
BM25 -X- _ B-MethodName
based -X- _ O
on -X- _ O
the -X- _ O
bag-of-words -X- _ O
representation); -X- _ O
and -X- _ O
then -X- _ O
(2) -X- _ O
re-rank -X- _ O
the -X- _ O
subset -X- _ O
of -X- _ O
the -X- _ O
top-k -X- _ O
relevant -X- _ O
passages -X- _ O
using -X- _ O
a -X- _ O
more -X- _ O
fine-grained -X- _ O
approach, -X- _ O
such -X- _ O
as -X- _ O
BERT -X- _ B-MethodName
based -X- _ O
on -X- _ O
vector -X- _ O
representations -X- _ O
. -X- _ O

From -X- _ O
the -X- _ O
result, -X- _ O
we -X- _ O
can -X- _ O
see -X- _ O
that -X- _ O
the -X- _ O
token-level -X- _ B-TaskName
intent -X- _ I-TaskName
detection -X- _ I-TaskName
obtains -X- _ O
better -X- _ O
performance -X- _ O
than -X- _ O
the -X- _ O
utterance-level -X- _ B-TaskName
intent -X- _ I-TaskName
detection. -X- _ I-TaskName

We -X- _ O
observe -X- _ O
a -X- _ O
marginal -X- _ O
performance -X- _ O
drop -X- _ O
of -X- _ B-MetricValue
less -X- _ I-MetricValue
than -X- _ I-MetricValue
0.1 -X- _ I-MetricValue
BLEU -X- _ B-MetricName
points, -X- _ O
indicating -X- _ O
that -X- _ O
our -X- _ O
approach -X- _ O
is -X- _ O
very -X- _ O
robust -X- _ O
for -X- _ O
input -X- _ O
variances. -X- _ O

We -X- _ O
train -X- _ O
the -X- _ O
three -X- _ O
considered -X- _ O
models -X- _ O
on -X- _ O
a -X- _ O
combination -X- _ O
of -X- _ O
MAWPS -X- _ B-MethodName
and -X- _ O
ASDiv-A -X- _ B-MethodName
and -X- _ O
test -X- _ O
them -X- _ O
on -X- _ B-DatasetName
SVAMP. -X- _ I-DatasetName

We -X- _ O
experiment -X- _ O
with -X- _ O
3 -X- _ O
popular -X- _ O
methods -X- _ O
from -X- _ O
the -X- _ O
literature: -X- _ B-DatasetName
MUSE -X- _ I-DatasetName
(Conneau -X- _ O
et -X- _ O
al, -X- _ O
2018a), -X- _ O
ICP -X- _ B-DatasetName
(Hoshen -X- _ O
and -X- _ O
Wolf, -X- _ O
2018) -X- _ O
and -X- _ O
VecMap -X- _ B-DatasetName
(Artetxe -X- _ O
et -X- _ O
al, -X- _ O
2018). -X- _ O

The -X- _ O
authors -X- _ O
adapt -X- _ O
a -X- _ O
transition-based -X- _ B-MethodName
English -X- _ I-MethodName
AMR -X- _ I-MethodName
parser -X- _ I-MethodName
(Damonte -X- _ O
et -X- _ O
al, -X- _ O
2017) -X- _ O
for -X- _ O
cross-lingual -X- _ B-TaskName
AMR -X- _ I-TaskName
parsing, -X- _ I-TaskName
which -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
silver -X- _ O
annotated -X- _ O
data. -X- _ O

We -X- _ O
adopt -X- _ O
the -X- _ O
MaxSAT -X- _ B-MethodName
semantics -X- _ O
to -X- _ O
model -X- _ O
logic -X- _ O
inference -X- _ O
process -X- _ O
and -X- _ O
smoothly -X- _ O
incorporate -X- _ O
a -X- _ O
weighted -X- _ O
version -X- _ O
of -X- _ O
MaxSAT -X- _ B-MethodName
that -X- _ O
connects -X- _ O
deep -X- _ O
neural -X- _ O
networks -X- _ O
and -X- _ O
a -X- _ O
graphical -X- _ O
model -X- _ O
in -X- _ O
a -X- _ O
joint -X- _ O
framework. -X- _ O

While -X- _ O
state-of-the-art -X- _ O
approaches -X- _ O
in -X- _ O
bidirectional -X- _ B-TaskName
image-sentence -X- _ I-TaskName
retrieval -X- _ I-TaskName
Yang -X- _ O
et -X- _ O
al, -X- _ O
2019b) -X- _ O
have -X- _ O
leveraged -X- _ O
visual-semantic -X- _ O
consistency -X- _ O
to -X- _ O
great -X- _ O
success -X- _ O
on -X- _ O
standard -X- _ O
datasets -X- _ O
such -X- _ O
as -X- _ O
MSCOCO -X- _ B-DatasetName
(Lin -X- _ O
et -X- _ O
al, -X- _ O
2014) -X- _ O
and -X- _ O
Flickr30K -X- _ B-DatasetName
(Plummer -X- _ O
et -X- _ O
al, -X- _ O
2015), -X- _ O
we -X- _ O
show -X- _ O
in -X- _ O
Appendix -X- _ O
D -X- _ O
they -X- _ O
are -X- _ O
not -X- _ O
able -X- _ O
to -X- _ O
reason -X- _ O
effectively -X- _ O
about -X- _ O
objects -X- _ O
in -X- _ O
an -X- _ O
image -X- _ O
and -X- _ O
named -X- _ O
entities -X- _ O
present -X- _ O
in -X- _ O
the -X- _ O
caption -X- _ O
or -X- _ O
article -X- _ O
body. -X- _ O

We -X- _ O
consider -X- _ O
n -X- _ B-MetricName
= -X- _ O
{3, -X- _ B-MetricValue
6} -X- _ B-MetricValue
to -X- _ O
conduct -X- _ O
experiments. -X- _ O

For -X- _ O
each -X- _ O
language -X- _ O
direction, -X- _ O
we -X- _ O
trained -X- _ O
a -X- _ O
baseline -X- _ O
CLIR -X- _ B-MethodName
model -X- _ O
on -X- _ O
the -X- _ O
base -X- _ O
train -X- _ O
set -X- _ O
and -X- _ O
kept -X- _ O
the -X- _ O
checkpoint -X- _ O
with -X- _ O
the -X- _ O
best -X- _ O
NDCG@10 -X- _ B-MetricName
performance -X- _ O
on -X- _ O
the -X- _ O
base -X- _ O
validation -X- _ O
set. -X- _ O

We -X- _ O
use -X- _ O
a -X- _ O
standard -X- _ O
1-layer -X- _ B-HyperparameterValue
BiLSTM -X- _ B-MethodName
partitioned -X- _ O
into -X- _ O
two -X- _ O
subspaces, -X- _ O
a -X- _ O
shared -X- _ O
subspace -X- _ O
and -X- _ O
a -X- _ O
private -X- _ O
one, -X- _ O
forced -X- _ O
to -X- _ O
be -X- _ O
orthogonal -X- _ O
through -X- _ O
a -X- _ O
regularization -X- _ O
penalty -X- _ O
term -X- _ O
in -X- _ O
the -X- _ O
loss -X- _ O
function -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
enable -X- _ O
the -X- _ O
multitask -X- _ O
network -X- _ O
to -X- _ O
learn -X- _ O
both -X- _ O
task-specific -X- _ O
and -X- _ O
shared -X- _ O
representations. -X- _ O

Figure -X- _ O
7 -X- _ O
shows -X- _ O
two -X- _ O
examples -X- _ O
from -X- _ O
the -X- _ O
TODSum -X- _ B-DatasetName
and -X- _ B-DatasetName
QMSum -X- _ I-DatasetName
respectively. -X- _ O

We -X- _ O
now -X- _ O
compare -X- _ O
the -X- _ O
efficiency -X- _ O
of -X- _ O
L2E -X- _ B-MethodName
against -X- _ O
that -X- _ O
of -X- _ O
the -X- _ O
baseline -X- _ O
explanation -X- _ O
algorithms -X- _ O
A -X- _ O
when -X- _ O
generating -X- _ O
explanations -X- _ O
for -X- _ O
test -X- _ O
documents. -X- _ O

Table -X- _ O
2: -X- _ O
Accuracy -X- _ O
on -X- _ B-DatasetName
SciQ -X- _ I-DatasetName
by -X- _ O
UnifiedQA -X- _ B-MethodName
fine-tuned -X- _ O
on -X- _ O
our -X- _ O
synthetic -X- _ O
datasets. -X- _ O
"SciQ -X- _ O
data" -X- _ O
refers -X- _ O
to -X- _ O
the -X- _ O
questions -X- _ O
generated -X- _ O
using -X- _ O
the -X- _ O
support -X- _ O
paragraphs -X- _ O
in -X- _ O
SciQ -X- _ B-DatasetName
while -X- _ O
"Wikipedia -X- _ O
data" -X- _ O
refers -X- _ O
to -X- _ O
questions -X- _ O
generated -X- _ O
using -X- _ O
sentences -X- _ O
harvested -X- _ O
from -X- _ O
Wikipedia. -X- _ B-DatasetName

The -X- _ O
proposed -X- _ O
methodology -X- _ O
shows -X- _ O
a -X- _ O
significant -X- _ O
accuracy -X- _ B-MetricName
improvement -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
stateof-the-art -X- _ O
approaches -X- _ O
on -X- _ O
various -X- _ O
chart -X- _ O
Q/A -X- _ O
datasets, -X- _ O
while -X- _ O
outperforming -X- _ O
even -X- _ O
human -X- _ O
baseline -X- _ O
on -X- _ O
the -X- _ O
DVQA -X- _ B-DatasetName
Dataset. -X- _ O

(3) -X- _ O
Knowledgeenhanced -X- _ O
by -X- _ O
Triplet -X- _ O
Sentence: -X- _ O
K-BERT -X- _ B-MethodName
(Liu -X- _ O
et -X- _ O
al, -X- _ O
2020b) -X- _ O
and -X- _ O
CoLAKE -X- _ B-MethodName
convert -X- _ O
triplets -X- _ O
into -X- _ O
sentences -X- _ O
and -X- _ O
insert -X- _ O
them -X- _ O
into -X- _ O
the -X- _ O
training -X- _ O
corpora -X- _ O
without -X- _ O
pre-trained -X- _ O
embedding. -X- _ O

With -X- _ O
the -X- _ O
best -X- _ O
configuration -X- _ O
we -X- _ O
obtain -X- _ O
a -X- _ O
new -X- _ O
state-of-theart -X- _ O
on -X- _ O
MIND-CA, -X- _ B-DatasetName
improving -X- _ O
Macro-F1 -X- _ B-MetricName
score -X- _ O
by -X- _ O
6 -X- _ B-MetricValue
points -X- _ O
and -X- _ O
F1-per-Question -X- _ B-HyperparameterValue
by -X- _ O
10.3 -X- _ B-MetricValue
points. -X- _ O

Towards -X- _ O
that -X- _ O
end, -X- _ O
we -X- _ O
formulate -X- _ O
a -X- _ O
vision-language -X- _ B-TaskName
question -X- _ I-TaskName
answering -X- _ I-TaskName
task -X- _ O
based -X- _ O
on -X- _ O
the -X- _ B-DatasetName
CLEVR -X- _ I-DatasetName
(Johnson -X- _ O
et -X- _ O
al., -X- _ O
2017a) -X- _ O
dataset. -X- _ O

As -X- _ O
for -X- _ O
our -X- _ O
model, -X- _ O
we -X- _ O
first -X- _ O
lower-case -X- _ O
and -X- _ O
tokenize -X- _ O
each -X- _ O
word -X- _ O
by -X- _ O
using -X- _ O
WordPiece -X- _ B-MethodName
(Wu -X- _ O
et -X- _ O
al, -X- _ O
2016) -X- _ O
with -X- _ O
a -X- _ O
vocabulary -X- _ O
of -X- _ O
30K -X- _ O
subwords -X- _ O
and -X- _ O
preprocess -X- _ O
them -X- _ O
by -X- _ O
stemming -X- _ O
and -X- _ O
removing -X- _ O
subwords -X- _ O
with -X- _ O
numerals. -X- _ O

On -X- _ O
CLINC-Full, -X- _ B-DatasetName
RCL -X- _ B-MethodName
achieves -X- _ O
4.73%, -X- _ B-MetricValue
4.57% -X- _ B-MetricValue
and -X- _ O
4.18% -X- _ B-MetricValue
improvements -X- _ O
over -X- _ O
SCL -X- _ B-MethodName
on -X- _ O
OOD -X- _ B-MetricName
F1 -X- _ I-MetricName
under -X- _ O
three -X- _ O
OOD -X- _ O
detection -X- _ O
settings -X- _ O
and -X- _ O
4.77%, -X- _ B-MetricValue
4.97% -X- _ B-MetricValue
and -X- _ O
4.69% -X- _ B-MetricValue
on -X- _ O
Snips -X- _ B-DatasetName
dataset, -X- _ O
respectively. -X- _ O

For -X- _ O
both -X- _ O
Transformers-based -X- _ O
models -X- _ O
in -X- _ O
Foreign→English -X- _ O
direction, -X- _ O
we -X- _ O
used -X- _ O
BPE -X- _ B-MethodName
with -X- _ O
10 -X- _ B-HyperparameterValue
merge -X- _ O
operations, -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
0.001 -X- _ B-HyperparameterValue
and -X- _ O
500 -X- _ B-HyperparameterValue
epochs; -X- _ O
while -X- _ O
for -X- _ O
the -X- _ O
standard -X- _ O
Transformer -X- _ B-MethodName
in -X- _ O
English→Foreign -X- _ O
direction, -X- _ O
BPE -X- _ B-MethodName
with -X- _ O
30 -X- _ B-HyperparameterValue
merge -X- _ O
operations -X- _ O
have -X- _ O
been -X- _ O
used. -X- _ O

First, -X- _ O
for -X- _ O
answer -X- _ O
selection -X- _ O
on -X- _ O
PAR, -X- _ B-DatasetName
we -X- _ O
find -X- _ O
91.0% -X- _ B-MetricValue
overall -X- _ O
agreement, -X- _ B-MetricName
with -X- _ O
Fleiss' -X- _ B-MetricName
freemarginal -X- _ I-MetricName
Kappa -X- _ I-MetricName
κ -X- _ B-MetricName
= -X- _ O
0.82. -X- _ B-MetricValue

They -X- _ O
stated -X- _ O
that -X- _ O
"we -X- _ O
hypothesize -X- _ O
that -X- _ O
this -X- _ O
3 -X- _ O
is -X- _ O
because -X- _ O
the -X- _ O
relatively -X- _ O
large -X- _ O
value -X- _ O
of -X- _ O
k -X- _ B-HyperparameterName
= -X- _ O
10 -X- _ B-HyperparameterValue
for -X- _ O
CAML -X- _ B-MethodName
leads -X- _ O
to -X- _ O
a -X- _ O
larger -X- _ O
network -X- _ O
that -X- _ O
is -X- _ O
more -X- _ O
suited -X- _ O
to -X- _ O
larger -X- _ O
datasets; -X- _ O
tuning -X- _ O
CAML's -X- _ B-MethodName
hyperparameters -X- _ O
on -X- _ O
this -X- _ O
dataset -X- _ O
would -X- _ O
be -X- _ O
expected -X- _ O
to -X- _ O
improve -X- _ O
performance -X- _ O
on -X- _ O
all -X- _ O
metrics." -X- _ O
However, -X- _ O
it -X- _ O
seems -X- _ O
no -X- _ O
subsequent -X- _ O
works -X- _ O
tried -X- _ O
to -X- _ O
tune -X- _ O
parameters -X- _ O
of -X- _ O
CNN -X- _ O
or -X- _ O
CAML -X- _ B-MethodName
on -X- _ O
MIMIC-III-50. -X- _ B-DatasetName

8 -X- _ O
In -X- _ O
both -X- _ O
cases, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
English-French -X- _ B-DatasetName
WMT14 -X- _ I-DatasetName
dataset -X- _ O
(Bojar -X- _ O
et -X- _ O
al, -X- _ O
2014) -X- _ O
as -X- _ O
our -X- _ O
parallel -X- _ O
corpus -X- _ O
for -X- _ O
training. -X- _ O

Data-to-text -X- _ B-TaskName
generation -X- _ I-TaskName
(Dušek -X- _ O
et -X- _ O
al, -X- _ O
2020;) -X- _ O
is -X- _ O
a -X- _ O
critical -X- _ O
component -X- _ O
in -X- _ O
today's -X- _ O
taskoriented -X- _ O
dialog -X- _ O
systems -X- _ O
for -X- _ O
producing -X- _ O
fluent -X- _ O
natural -X- _ O
language -X- _ O
responses -X- _ O
to -X- _ O
users' -X- _ O
requests. -X- _ O

For -X- _ O
example, -X- _ O
on -X- _ O
AudioCaps, -X- _ B-DatasetName
vip-AnT -X- _ B-MethodName
outperforms -X- _ O
VA-Rand -X- _ B-MethodName
by -X- _ O
4.5% -X- _ B-MetricValue
R@1 -X- _ B-MetricName
and -X- _ O
13.6% -X- _ B-MetricValue
R@10. -X- _ B-MetricName

As -X- _ O
in -X- _ O
literature -X- _ O
(Pan -X- _ O
et -X- _ O
al, -X- _ O
2019), -X- _ O
we -X- _ O
examine -X- _ B-DatasetName
RUN -X- _ I-DatasetName
using -X- _ O
the -X- _ O
widely -X- _ O
used -X- _ O
automatic -X- _ O
metrics -X- _ O
BLEU, -X- _ B-MetricName
ROUGE, -X- _ B-MetricName
EM -X- _ B-MetricName
and -X- _ O
Rewriting -X- _ B-MetricName
F-score. -X- _ I-MetricName
(i) -X- _ O
BLEU -X- _ B-MetricName
n -X- _ I-MetricName
(B -X- _ B-MetricName
n -X- _ I-MetricName
) -X- _ O
evaluates -X- _ O
how -X- _ O
similar -X- _ O
the -X- _ O
rewritten -X- _ O
utterances -X- _ O
are -X- _ O
to -X- _ O
the -X- _ O
golden -X- _ O
ones -X- _ O
via -X- _ O
the -X- _ O
cumulative -X- _ O
n-gram -X- _ O
BLEU -X- _ B-MetricName
score -X- _ O
(Papineni -X- _ O
et -X- _ O
al, -X- _ O
2002). -X- _ O

Han -X- _ O
et -X- _ O
al -X- _ O
(2018) -X- _ O
introduced -X- _ O
a -X- _ O
few-shot -X- _ O
learning -X- _ O
framework -X- _ O
for -X- _ B-TaskName
relation -X- _ I-TaskName
classification -X- _ I-TaskName
(FewRel), -X- _ B-MethodName
and -X- _ O
recently -X- _ O
several -X- _ O
systems -X- _ O
have -X- _ O
achieved -X- _ O
near-human -X- _ O
performance -X- _ O
on -X- _ O
this -X- _ O
task -X- _ O
-in -X- _ O
some -X- _ O
settings -X- _ O
even -X- _ O
exceeding -X- _ O
it. -X- _ O

As -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
feasible -X- _ O
to -X- _ O
report -X- _ O
and -X- _ O
compare -X- _ O
results -X- _ O
on -X- _ O
all -X- _ O
of -X- _ O
these -X- _ O
metrics -X- _ O
(nine -X- _ O
in -X- _ O
total), -X- _ O
we -X- _ O
compute -X- _ O
the -X- _ O
pair-wise -X- _ B-MetricName
Pearson -X- _ I-MetricName
correlation -X- _ I-MetricName
coefficient -X- _ O
between -X- _ O
them, -X- _ O
and -X- _ O
average -X- _ O
over -X- _ O
all -X- _ O
pairs -X- _ O
to -X- _ O
arrive -X- _ O
at -X- _ O
the -X- _ O
following -X- _ O
four -X- _ O
metrics -X- _ O
that -X- _ O
show -X- _ O
the -X- _ O
least -X- _ O
correlation -X- _ O
with -X- _ O
each -X- _ O
other: -X- _ O
BLEU−2, -X- _ B-MetricName
CharacTER, -X- _ B-MetricName
ChrF−3 -X- _ B-MetricName
and -X- _ O
exact -X- _ B-MetricName
match. -X- _ I-MetricName

The -X- _ O
dataset -X- _ O
has -X- _ O
been -X- _ O
automatically -X- _ O
constructed -X- _ O
from -X- _ O
DIAL -X- _ B-DatasetName
corpus -X- _ O
(Blodgett -X- _ O
et -X- _ O
al, -X- _ O
2016) -X- _ O
which -X- _ O
contained -X- _ O
race -X- _ O
annotations -X- _ O
over -X- _ O
50 -X- _ O
Million -X- _ O
of -X- _ O
tweets. -X- _ O

Following -X- _ O
prior -X- _ O
works -X- _ O
(Tsai -X- _ O
et -X- _ O
al, -X- _ O
2018;Wang -X- _ O
et -X- _ O
al, -X- _ O
2019;Tsai -X- _ O
et -X- _ O
al, -X- _ O
2019;Dai -X- _ O
et -X- _ O
al, -X- _ O
2020a), -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
accuracy -X- _ B-MetricName
and -X- _ O
F1-score -X- _ B-MetricName
to -X- _ O
evaluate -X- _ O
the -X- _ O
models -X- _ O
on -X- _ O
the -X- _ O
IEMOCAP -X- _ B-DatasetName
dataset. -X- _ O

For -X- _ O
Islamophobia, -X- _ O
the -X- _ O
disagreements -X- _ O
mostly -X- _ O
related -X- _ O
to -X- _ O
arguments -X- _ O
that -X- _ O
make -X- _ O
a -X- _ O
distinction -X- _ O
between -X- _ O
Muslims -X- _ O
and -X- _ O
the -X- _ O
religion -X- _ O
Islam, -X- _ O
e.g.: -X- _ O
[...] -X- _ O
I -X- _ O
have -X- _ O
no -X- _ O
issue -X- _ O
with -X- _ O
Islam, -X- _ O
or -X- _ O
any -X- _ O
religion -X- _ O
in -X- _ O
general, -X- _ O
if -X- _ O
you -X- _ O
leave -X- _ O
me -X- _ O
alone -X- _ O
I -X- _ O
leave -X- _ O
you -X- _ O
alone, -X- _ O
you -X- _ O
wondered -X- _ O
why -X- _ O
so -X- _ O
many -X- _ O
people -X- _ O
hate -X- _ O
Islam, -X- _ O
its -X- _ O
because -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
[...] -X- _ O
in -X- _ O
your -X- _ O
last -X- _ O
paragraph, -X- _ O
y'all -X- _ O
act -X- _ O
as -X- _ O
if -X- _ O
terrorism -X- _ O
is -X- _ O
100% -X- _ O
okay. -X- _ O

Table -X- _ O
6 -X- _ O
shows -X- _ O
adversarial -X- _ O
examples -X- _ O
for -X- _ O
GPT-2 -X- _ B-MethodName
on -X- _ O
AG -X- _ B-DatasetName
News, -X- _ I-DatasetName
generated -X- _ O
with -X- _ O
and -X- _ O
without -X- _ O
the -X- _ O
fluency -X- _ O
constraint. -X- _ O

Extensive -X- _ O
experiments -X- _ O
involving -X- _ O
five -X- _ O
low-resource -X- _ O
languages -X- _ O
and -X- _ O
fine-grained -X- _ O
food -X- _ O
domain -X- _ O
demonstrate -X- _ O
our -X- _ O
superior -X- _ O
performance -X- _ O
(6% -X- _ B-MetricValue
and -X- _ O
7.8% -X- _ B-MetricValue
F1 -X- _ B-HyperparameterName
gains -X- _ O
on -X- _ O
average) -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
efficiency -X- _ O
1 -X- _ O
. -X- _ O

• -X- _ O
To -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
our -X- _ O
knowledge, -X- _ O
we -X- _ O
are -X- _ O
the -X- _ O
first -X- _ O
to -X- _ O
apply -X- _ O
a -X- _ O
fully -X- _ O
end-to-end -X- _ O
trainable -X- _ O
model -X- _ O
for -X- _ O
the -X- _ O
multimodal -X- _ B-TaskName
emotion -X- _ I-TaskName
recognition -X- _ I-TaskName
task. -X- _ O

The -X- _ O
student -X- _ O
models -X- _ O
with -X- _ O
our -X- _ O
method -X- _ O
(λ -X- _ B-HyperparameterName
= -X- _ O
1.5 -X- _ B-HyperparameterValue
and -X- _ O
λ -X- _ B-HyperparameterName
= -X- _ O
2.0) -X- _ B-HyperparameterValue
slightly -X- _ O
outperform -X- _ O
the -X- _ O
student -X- _ O
with -X- _ O
regular -X- _ O
pseudo-labeling -X- _ O
method -X- _ O
(λ -X- _ B-HyperparameterName
= -X- _ O
1.0). -X- _ B-HyperparameterName

Third, -X- _ O
when -X- _ O
comparing -X- _ O
these -X- _ O
two -X- _ O
datasets, -X- _ O
the -X- _ O
performance -X- _ O
gains -X- _ O
from -X- _ O
our -X- _ O
full -X- _ O
model -X- _ O
over -X- _ O
three -X- _ O
baselines -X- _ O
on -X- _ O
OpenI -X- _ B-DatasetName
are -X- _ O
more -X- _ O
prominent -X- _ O
than -X- _ O
that -X- _ O
on -X- _ B-DatasetName
MIMIC-CXR. -X- _ I-DatasetName

We -X- _ O
extend -X- _ O
our -X- _ O
experiments -X- _ O
to -X- _ O
the -X- _ B-DatasetName
XSum -X- _ I-DatasetName
dataset -X- _ O
to -X- _ O
see -X- _ O
whether -X- _ O
the -X- _ O
reliability -X- _ O
of -X- _ O
the -X- _ O
protocols -X- _ O
changes -X- _ O
as -X- _ O
the -X- _ O
characteristics -X- _ O
of -X- _ O
the -X- _ O
dataset -X- _ O
change. -X- _ O

• -X- _ O
HoC -X- _ O
(Baker -X- _ O
and -X- _ O
Korhonen, -X- _ O
2017): -X- _ O
The -X- _ B-DatasetName
Hallmarks -X- _ I-DatasetName
of -X- _ I-DatasetName
Cancer -X- _ I-DatasetName
corpus -X- _ O
was -X- _ O
extracted -X- _ O
from -X- _ O
1852 -X- _ O
PubMed -X- _ O
publication -X- _ O
abstracts -X- _ O
by -X- _ O
Baker -X- _ O
and -X- _ O
Korhonen -X- _ O
(2017), -X- _ O
and -X- _ O
the -X- _ O
class -X- _ O
labels -X- _ O
were -X- _ O
manually -X- _ O
annotated -X- _ O
by -X- _ O
experts -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
Hallmarks -X- _ O
of -X- _ O
Cancer -X- _ O
taxonomy. -X- _ O

The -X- _ O
performance -X- _ O
contributions -X- _ O
in -X- _ O
the -X- _ O
multilingual -X- _ O
setting -X- _ O
are -X- _ O
particularly -X- _ O
significant -X- _ O
(49.3 -X- _ B-MetricValue
for -X- _ O
mBERT -X- _ B-MethodName
and -X- _ O
53.1 -X- _ B-MetricValue
for -X- _ O
XLM-R) -X- _ B-MethodName
and -X- _ O
comparable -X- _ O
to -X- _ O
those -X- _ O
for -X- _ O
the -X- _ O
SimCSE -X- _ O
models. -X- _ B-MethodName

The -X- _ O
transferred -X- _ B-MethodName
GPT-2 -X- _ I-MethodName
models -X- _ O
are -X- _ O
evaluated -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
Language -X- _ B-MetricName
Modelling -X- _ I-MetricName
Perplexity -X- _ I-MetricName
(PPL) -X- _ B-MetricName
on -X- _ O
a -X- _ O
held-out -X- _ O
set. -X- _ O

To -X- _ O
enable -X- _ O
progress -X- _ O
in -X- _ O
this -X- _ O
area, -X- _ O
many -X- _ O
datasets -X- _ O
(Welbl -X- _ O
et -X- _ O
al, -X- _ O
2018;Talmor -X- _ O
and -X- _ O
Berant, -X- _ O
2018;Yang -X- _ O
et -X- _ O
al, -X- _ O
2018;Khot -X- _ O
et -X- _ O
al, -X- _ O
2020) -X- _ O
and -X- _ O
models -X- _ O
(Min -X- _ O
et -X- _ O
al, -X- _ O
2019b;Xiao -X- _ O
et -X- _ O
al, -X- _ O
2019;Tu -X- _ O
et -X- _ O
al, -X- _ O
2020) -X- _ O
focuses -X- _ O
on -X- _ B-DatasetName
HotpotQA -X- _ I-DatasetName
(Yang -X- _ O
et -X- _ O
al, -X- _ O
2018), -X- _ O
which -X- _ O
contains -X- _ O
105,257 -X- _ O
multi-hop -X- _ O
questions -X- _ O
derived -X- _ O
from -X- _ O
two -X- _ O
Wikipedia -X- _ O
paragraphs, -X- _ O
where -X- _ O
the -X- _ O
correct -X- _ O
answer -X- _ O
is -X- _ O
a -X- _ O
span -X- _ O
in -X- _ O
these -X- _ O
paragraphs -X- _ O
or -X- _ O
yes/no. -X- _ O

For -X- _ O
these -X- _ O
classes, -X- _ O
at -X- _ O
least, -X- _ O
we -X- _ O
expect -X- _ O
that -X- _ O
there -X- _ O
is -X- _ O
further -X- _ O
room -X- _ O
for -X- _ O
modeling -X- _ O
improvement -X- _ O
through: -X- _ O
(1) -X- _ O
annotating -X- _ O
more -X- _ O
data, -X- _ O
(2) -X- _ O
incorporating -X- _ O
more -X- _ O
auxiliary -X- _ O
tasks -X- _ O
in -X- _ O
the -X- _ O
multitask -X- _ O
setup, -X- _ O
or -X- _ O
(3) -X- _ O
learning -X- _ O
from -X- _ O
unlabeled -X- _ O
data, -X- _ O
by -X- _ O
fine-tuning -X- _ O
RoBERTa -X- _ B-MethodName
(Mosbach -X- _ O
et -X- _ O
al, -X- _ O
2021), -X- _ O
using -X- _ O
an -X- _ O
adapter-based -X- _ O
method -X- _ O
or -X- _ O
another -X- _ O
semi-supervised -X- _ O
algorithm -X- _ O
(one -X- _ O
candidate -X- _ O
besides -X- _ O
UDA -X- _ O
is -X- _ O
Berthelot -X- _ O
et -X- _ O
al -X- _ O
(2019)). -X- _ O

We -X- _ O
report -X- _ O
both -X- _ O
the -X- _ O
micro -X- _ O
and -X- _ O
macro-F1 -X- _ B-MetricName
scores -X- _ O
of -X- _ O
the -X- _ O
different -X- _ O
classification -X- _ O
tasks -X- _ O
in -X- _ O
Tables -X- _ O
3 -X- _ O
and -X- _ O
4. -X- _ O

We -X- _ O
asked -X- _ O
trained -X- _ B-MethodName
human -X- _ I-MethodName
annotators -X- _ I-MethodName
to -X- _ O
evaluate -X- _ O
generated -X- _ O
SOAP -X- _ B-MethodName
notes -X- _ O
for -X- _ O
45 -X- _ O
conversations. -X- _ O

The -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
1) -X- _ O
CoBERT -X- _ B-MethodName
performs -X- _ O
reasonably -X- _ O
well -X- _ O
on -X- _ O
examples -X- _ O
with -X- _ O
unseen -X- _ O
personas, -X- _ O
suggesting -X- _ O
that -X- _ O
CoBERT -X- _ B-MethodName
can -X- _ O
generalize -X- _ O
well -X- _ O
to -X- _ O
unseen -X- _ O
personas -X- _ O
and -X- _ O
retrieve -X- _ O
the -X- _ O
right -X- _ O
response -X- _ O
for -X- _ O
new -X- _ O
speakers -X- _ O
accurately; -X- _ O
2) -X- _ O
CoBERT -X- _ B-MethodName
performs -X- _ O
worse -X- _ O
on -X- _ O
examples -X- _ O
with -X- _ O
unseen -X- _ O
personas -X- _ O
than -X- _ O
seen -X- _ O
personas; -X- _ O
3) -X- _ O
leveraging -X- _ O
personas -X- _ O
during -X- _ O
model -X- _ O
training -X- _ O
and -X- _ O
testing -X- _ O
improves -X- _ O
CoBERT -X- _ B-MethodName
on -X- _ O
examples -X- _ O
with -X- _ O
either -X- _ O
seen -X- _ O
or -X- _ O
unseen -X- _ O
personas; -X- _ O
and -X- _ O
4) -X- _ O
the -X- _ O
persona -X- _ O
improvement -X- _ O
is -X- _ O
more -X- _ O
noticeable -X- _ O
for -X- _ O
examples -X- _ O
with -X- _ O
seen -X- _ O
personas -X- _ O
than -X- _ O
unseen -X- _ O
personas. -X- _ O

To -X- _ O
have -X- _ O
an -X- _ O
in-depth -X- _ O
understanding -X- _ O
of -X- _ O
the -X- _ O
effects -X- _ O
of -X- _ O
Nucleus -X- _ B-MethodName
Sampling -X- _ I-MethodName
on -X- _ O
the -X- _ O
MESM, -X- _ B-MethodName
we -X- _ O
perform -X- _ O
more -X- _ O
experiments -X- _ O
with -X- _ O
different -X- _ O
top-p -X- _ B-HyperparameterName
values -X- _ O
ranging -X- _ O
from -X- _ O
0 -X- _ B-HyperparameterValue
to -X- _ I-HyperparameterValue
1, -X- _ I-HyperparameterValue
with -X- _ O
a -X- _ O
step -X- _ O
of -X- _ O
0.1. -X- _ O

We -X- _ O
evaluated -X- _ O
M -X- _ B-MethodName
2 -X- _ I-MethodName
OIE -X- _ I-MethodName
(as -X- _ O
the -X- _ O
only -X- _ O
multilingual -X- _ O
model -X- _ O
in -X- _ O
our -X- _ O
evaluation) -X- _ O
on -X- _ O
the -X- _ O
Chinese -X- _ O
and -X- _ O
German -X- _ O
versions -X- _ O
of -X- _ O
BenchIE. -X- _ B-DatasetName

In -X- _ O
the -X- _ O
additional -X- _ O
experiments -X- _ O
(Sections -X- _ O
5.2-5.5), -X- _ O
we -X- _ O
also -X- _ O
use -X- _ O
random -X- _ O
subsets -X- _ O
of -X- _ O
the -X- _ O
WMT14 -X- _ B-DatasetName
English-French -X- _ O
data; -X- _ O
in -X- _ O
this -X- _ O
case, -X- _ O
we -X- _ O
specify -X- _ O
dataset -X- _ O
size -X- _ O
for -X- _ O
each -X- _ O
experiment. -X- _ O

We -X- _ O
employ -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
1e -X- _ B-HyperparameterValue
− -X- _ I-HyperparameterValue
5 -X- _ I-HyperparameterValue
for -X- _ O
the -X- _ O
models -X- _ O
with -X- _ O
the -X- _ O
BERT-based -X- _ B-MethodName
PLM -X- _ I-MethodName
(i.e., -X- _ O
using -X- _ O
bert-large-cased -X- _ B-MethodName
and -X- _ O
bert-multilingual-cased) -X- _ B-MethodName
and -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
5e -X- _ B-HyperparameterValue
− -X- _ I-HyperparameterValue
6 -X- _ I-HyperparameterValue
for -X- _ O
the -X- _ O
RoBERTa-based -X- _ B-MethodName
PLM -X- _ I-MethodName
(i.e., -X- _ O
using -X- _ O
roberta-large -X- _ B-MethodName
and -X- _ O
xlm-robertalarge). -X- _ B-MethodName

The -X- _ O
missing -X- _ O
word -X- _ O
in -X- _ O
the -X- _ O
story -X- _ O
should -X- _ O
be: -X- _ O
" -X- _ O
Collapsing -X- _ O
token -X- _ O
sets: -X- _ O
None, -X- _ O
all -X- _ O
tokens -X- _ O
are -X- _ O
considered -X- _ O
Prompt -X- _ O
10 -X- _ O
(MI: -X- _ B-MetricName
2.632, -X- _ B-MetricValue
Acc: -X- _ B-MetricName
0.474): -X- _ B-MetricName
"I -X- _ O
would -X- _ O
speak -X- _ O
to -X- _ O
you -X- _ O
privately," -X- _ O
Bowen -X- _ O
said, -X- _ O
casting -X- _ O
a -X- _ O
glance -X- _ O
around -X- _ O
at -X- _ O
the -X- _ O
others -X- _ O
milling -X- _ O
about. -X- _ O

To -X- _ O
better -X- _ O
understand -X- _ O
the -X- _ O
zero-shot -X- _ O
abilities -X- _ O
of -X- _ O
pretrained -X- _ O
multilingual -X- _ O
models -X- _ O
for -X- _ O
semantic -X- _ B-TaskName
tasks -X- _ I-TaskName
in -X- _ I-TaskName
unseen -X- _ I-TaskName
languages, -X- _ I-TaskName
we -X- _ O
present -X- _ O
AmericasNLI, -X- _ B-DatasetName
a -X- _ O
parallel -X- _ O
NLI -X- _ O
dataset -X- _ O
covering -X- _ O
10 -X- _ O
low-resource -X- _ O
lan-guages -X- _ O
indigenous -X- _ O
to -X- _ O
the -X- _ O
Americas. -X- _ O

Various -X- _ O
datasets -X- _ O
that -X- _ O
require -X- _ O
a -X- _ O
wide -X- _ O
range -X- _ O
of -X- _ O
background -X- _ O
knowledge -X- _ O
and -X- _ O
different -X- _ O
types -X- _ O
of -X- _ O
reasoning -X- _ O
abilities -X- _ O
have -X- _ O
been -X- _ O
introduced, -X- _ O
such -X- _ O
as -X- _ B-DatasetName
ARC -X- _ I-DatasetName
(Clark -X- _ O
et -X- _ O
al, -X- _ O
2018), -X- _ B-DatasetName
GQA -X- _ I-DatasetName
(Hudson -X- _ O
and -X- _ O
Manning, -X- _ O
2019), -X- _ B-DatasetName
GLUE -X- _ I-DatasetName
benchmarks -X- _ O
(Wang -X- _ O
et -X- _ O
al, -X- _ O
2018) -X- _ O
and -X- _ B-DatasetName
SWAG -X- _ I-DatasetName
(Zellers -X- _ O
et -X- _ O
al, -X- _ O
2018). -X- _ O

In -X- _ O
order -X- _ O
to -X- _ O
check -X- _ O
if -X- _ O
a -X- _ O
particular -X- _ O
edge -X- _ O
was -X- _ O
stably -X- _ O
transferred -X- _ O
from -X- _ O
the -X- _ O
corresponding -X- _ O
source -X- _ O
sentence, -X- _ O
we -X- _ O
use -X- _ O
an -X- _ O
extended -X- _ O
version -X- _ O
of -X- _ O
the -X- _ O
manually -X- _ O
aligned -X- _ O
subset -X- _ O
of -X- _ O
the -X- _ O
Parallel -X- _ B-DatasetName
UD -X- _ I-DatasetName
dataset -X- _ O
(Zeman -X- _ O
et -X- _ O
al, -X- _ O
2017a;Nikolaev -X- _ O
et -X- _ O
al, -X- _ O
2020), -X- _ O
which -X- _ O
provides -X- _ O
word-aligned -X- _ O
translations -X- _ O
of -X- _ O
circa -X- _ O
1000 -X- _ O
English -X- _ O
sentences -X- _ O
into -X- _ O
six -X- _ O
languages -X- _ O
with -X- _ O
different -X- _ O
typological -X- _ O
profiles. -X- _ O

Built -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
strong -X- _ O
base -X- _ O
models, -X- _ O
our -X- _ O
learning -X- _ O
method -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
achieve -X- _ O
state-of-the-art -X- _ O
on -X- _ O
NARRATIVEQA, -X- _ B-DatasetName
TRIVIAQA-OPEN, -X- _ B-DatasetName
NATURALQUESTIONS-OPEN, -X- _ B-DatasetName
DROP -X- _ B-DatasetName
num -X- _ I-DatasetName
and -X- _ O
WIKISQL. -X- _ B-DatasetName

The -X- _ O
hidden -X- _ O
layer -X- _ O
has -X- _ O
a -X- _ O
dimension -X- _ B-HyperparameterName
of -X- _ O
200, -X- _ B-HyperparameterValue
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
is -X- _ O
initially -X- _ O
set -X- _ O
to -X- _ O
0.1 -X- _ B-HyperparameterValue
with -X- _ O
a -X- _ O
learning -X- _ O
rate -X- _ O
decay, -X- _ O
and -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
DyNet -X- _ B-MethodName
(Neubig -X- _ O
et -X- _ O
al, -X- _ O
2017) -X- _ O
automatic -X- _ O
minibatch -X- _ O
function -X- _ O
to -X- _ O
speed-up -X- _ O
the -X- _ O
computation. -X- _ O

effects -X- _ O
of -X- _ O
traditional -X- _ O
generation -X- _ O
methods -X- _ O
such -X- _ O
as -X- _ O
Seq2Seq -X- _ B-MethodName
and -X- _ O
Transformer, -X- _ B-MethodName
and -X- _ O
the -X- _ O
lower -X- _ O
part -X- _ O
shows -X- _ O
the -X- _ O
latest -X- _ O
pretrained-based -X- _ O
methods -X- _ O
including -X- _ O
DialoGPT -X- _ B-MethodName
and -X- _ O
T5. -X- _ B-MethodName

Comparing -X- _ O
to -X- _ O
a -X- _ O
model -X- _ O
trained -X- _ O
purely -X- _ O
via -X- _ O
visually -X- _ O
grounded -X- _ O
learning, -X- _ O
extending -X- _ O
the -X- _ O
loss -X- _ O
with -X- _ O
a -X- _ O
language -X- _ O
modeling -X- _ O
objective -X- _ O
improves -X- _ O
the -X- _ O
overall -X- _ O
F1 -X- _ B-MetricName
from -X- _ O
50.5% -X- _ B-MetricValue
to -X- _ O
59.4%. -X- _ B-MetricValue

The -X- _ O
best -X- _ O
model, -X- _ O
a -X- _ O
finetuned -X- _ O
T5, -X- _ B-MethodName
writes -X- _ O
advice -X- _ O
that -X- _ O
is -X- _ O
at -X- _ O
least -X- _ O
as -X- _ O
helpful -X- _ O
as -X- _ O
human-written -X- _ B-MethodName
advice -X- _ I-MethodName
in -X- _ O
only -X- _ O
14% -X- _ B-MetricValue
of -X- _ O
cases; -X- _ O
a -X- _ O
much -X- _ O
larger -X- _ O
non-finetunable -X- _ O
GPT3 -X- _ B-MethodName
model -X- _ O
does -X- _ O
even -X- _ O
worse -X- _ O
at -X- _ O
4%. -X- _ B-MetricValue

Continual -X- _ O
Fine-Tuning -X- _ O
There -X- _ O
are -X- _ O
two -X- _ O
major -X- _ O
hps: -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
and -X- _ O
the -X- _ O
num_epochs, -X- _ B-HyperparameterName
we -X- _ O
searched -X- _ O
over -X- _ O
{1e -X- _ B-HyperparameterValue
− -X- _ I-HyperparameterValue
5, -X- _ I-HyperparameterValue
2e -X- _ B-HyperparameterValue
− -X- _ I-HyperparameterValue
5, -X- _ I-HyperparameterValue
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
5e -X- _ B-HyperparameterValue
− -X- _ I-HyperparameterValue
5} -X- _ I-HyperparameterValue
and -X- _ O
{5, -X- _ B-HyperparameterValue
10, -X- _ B-HyperparameterValue
15, -X- _ B-HyperparameterValue
20, -X- _ B-HyperparameterValue
30} -X- _ B-HyperparameterValue
for -X- _ O
the -X- _ O
num_epochs -X- _ B-HyperparameterName
at -X- _ O
each -X- _ O
episode. -X- _ O

SentEval -X- _ B-MetricValue
(Conneau -X- _ O
and -X- _ O
Kiela, -X- _ O
2018) -X- _ O
is -X- _ O
a -X- _ O
popular -X- _ O
toolkit -X- _ O
for -X- _ O
evaluating -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
universal -X- _ B-TaskName
sentence -X- _ I-TaskName
embeddings -X- _ I-TaskName
that -X- _ O
aggregates -X- _ O
various -X- _ O
tasks, -X- _ O
including -X- _ O
binary -X- _ O
and -X- _ O
multi-class -X- _ O
classification, -X- _ O
natural -X- _ O
language -X- _ O
inference, -X- _ O
and -X- _ O
sentence -X- _ O
similarity. -X- _ O

The -X- _ O
evaluation -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
CoSHC -X- _ B-MethodName
can -X- _ O
preserve -X- _ O
more -X- _ O
than -X- _ O
99% -X- _ O
performance -X- _ O
of -X- _ O
most -X- _ O
baseline -X- _ O
models. -X- _ O

In -X- _ O
unlimited -X- _ O
games -X- _ O
setting -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2, -X- _ O
all -X- _ O
three -X- _ O
agents -X- _ O
produce -X- _ O
an -X- _ O
accuracy -X- _ B-MetricName
of -X- _ O
0.5; -X- _ B-MetricValue
in -X- _ O
zero-shot -X- _ O
test -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
4, -X- _ O
no -X- _ O
agent -X- _ O
performs -X- _ O
significantly -X- _ O
better -X- _ O
than -X- _ O
random. -X- _ O

DPE -X- _ B-MethodName
achieves -X- _ O
an -X- _ O
average -X- _ O
improvement -X- _ O
of -X- _ O
0.9 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
over -X- _ O
greedy -X- _ B-MethodName
BPE -X- _ I-MethodName
(Sennrich -X- _ O
et -X- _ B-MetricValue
al, -X- _ I-MetricValue
2016) -X- _ O
and -X- _ O
an -X- _ O
average -X- _ O
improvement -X- _ O
of -X- _ O
0.55 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
over -X- _ O
stochastic -X- _ B-MethodName
BPE -X- _ I-MethodName
dropout -X- _ I-MethodName
(Provilkov -X- _ O
et -X- _ O
al, -X- _ O
2019) -X- _ O
1 -X- _ O
. -X- _ O

For -X- _ O
RE-Text, -X- _ B-DatasetName
we -X- _ O
pass -X- _ O
the -X- _ O
summary -X- _ O
paragraphs -X- _ O
from -X- _ O
50,000 -X- _ B-HyperparameterValue
random -X- _ O
Wikipedia -X- _ O
pages -X- _ O
to -X- _ O
Stanford's -X- _ B-MethodName
OpenIE -X- _ I-MethodName
extractor -X- _ O
(Manning -X- _ O
et -X- _ O
al, -X- _ O
2014), -X- _ O
creating -X- _ O
2 -X- _ O
million -X- _ O
triples. -X- _ O

Flickr30K -X- _ B-DatasetName
contains -X- _ O
31, -X- _ O
783 -X- _ O
images, -X- _ O
and -X- _ O
each -X- _ O
one -X- _ O
has -X- _ O
5 -X- _ O
annotated -X- _ O
textual -X- _ O
descriptions. -X- _ O

Particularly, -X- _ O
the -X- _ O
annotation -X- _ O
process -X- _ O
of -X- _ B-DatasetName
MATRES -X- _ I-DatasetName
has -X- _ O
defined -X- _ O
four -X- _ O
axes -X- _ O
for -X- _ O
the -X- _ O
actions -X- _ O
of -X- _ O
events, -X- _ O
i.e. -X- _ O
main, -X- _ O
intention, -X- _ O
opinion, -X- _ O
and -X- _ O
hypothetical -X- _ O
axes. -X- _ O

Zhang -X- _ O
et -X- _ O
al -X- _ O
(2019) -X- _ O
improve -X- _ O
pronoun -X- _ B-TaskName
coreference -X- _ I-TaskName
resolution -X- _ I-TaskName
by -X- _ O
2.2 -X- _ B-MetricValue
F1 -X- _ B-MetricName
using -X- _ O
linguistic -X- _ O
features -X- _ O
(gender, -X- _ O
animacy -X- _ O
and -X- _ O
plurality) -X- _ O
and -X- _ O
a -X- _ O
frequency -X- _ O
based -X- _ O
predicateargument -X- _ O
selection -X- _ O
preference -X- _ O
as -X- _ O
external -X- _ O
knowledge. -X- _ O

The -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
is -X- _ O
1 -X- _ B-HyperparameterValue
and -X- _ O
the -X- _ O
maximum -X- _ O
training -X- _ B-HyperparameterName
epoch -X- _ I-HyperparameterName
is -X- _ O
100. -X- _ B-HyperparameterValue

They -X- _ O
can -X- _ O
be -X- _ O
systematically -X- _ O
represented -X- _ O
with -X- _ O
the -X- _ O
Valence-Arousal-Dominance -X- _ B-MethodName
(VAD) -X- _ B-MethodName
model -X- _ O
which -X- _ O
maps -X- _ O
emotional -X- _ O
states -X- _ O
to -X- _ O
3-dimensional -X- _ O
continuous -X- _ O
VAD -X- _ B-MethodName
space. -X- _ O

Abstract -X- _ B-DatasetName
Meaning -X- _ I-DatasetName
Representation -X- _ I-DatasetName
(AMR) -X- _ B-DatasetName
is -X- _ O
a -X- _ O
popular -X- _ O
formalism -X- _ O
for -X- _ O
natural -X- _ O
language -X- _ O
(Banarescu -X- _ O
et -X- _ O
al, -X- _ O
2013). -X- _ O

Provided -X- _ O
both -X- _ O
gold -X- _ O
paragraph -X- _ O
and -X- _ O
answer -X- _ O
type -X- _ O
("Gold -X- _ O
T&P"), -X- _ O
the -X- _ O
model's -X- _ O
short -X- _ O
answer -X- _ O
F1 -X- _ B-MetricName
score -X- _ O
reaches -X- _ O
10% -X- _ B-MetricValue
above -X- _ O
that -X- _ O
of -X- _ O
a -X- _ O
single -X- _ B-MethodName
annotator, -X- _ I-MethodName
while -X- _ O
slightly -X- _ O
behind -X- _ O
super -X- _ B-MethodName
human -X- _ I-MethodName
performance. -X- _ O

Dataset: -X- _ O
We -X- _ O
use -X- _ O
FB15k-237 -X- _ B-DatasetName
(Toutanova -X- _ O
and -X- _ O
Chen, -X- _ O
2015) -X- _ O
7 -X- _ O
and -X- _ O
WN18RR -X- _ B-DatasetName
(Dettmers -X- _ O
et -X- _ O
al, -X- _ O
2018) -X- _ O
8 -X- _ O
datasets -X- _ O
in -X- _ O
the -X- _ O
experiments. -X- _ O

Moreover, -X- _ O
when -X- _ O
compared -X- _ O
with -X- _ O
DenseCap -X- _ B-MethodName
which -X- _ O
has -X- _ O
a -X- _ O
similar -X- _ O
transformer -X- _ O
architecture -X- _ O
and -X- _ O
parameters, -X- _ O
our -X- _ O
model -X- _ O
exhibits -X- _ O
better -X- _ O
evaluation -X- _ O
scores, -X- _ O
verifying -X- _ O
it -X- _ O
as -X- _ O
a -X- _ O
strong -X- _ O
baseline -X- _ O
model -X- _ O
for -X- _ O
the -X- _ O
V2C -X- _ B-TaskName
task. -X- _ O

We -X- _ O
terminate -X- _ O
the -X- _ O
training -X- _ O
when -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
observe -X- _ O
any -X- _ O
performance -X- _ O
improvements -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
set -X- _ O
for -X- _ O
5 -X- _ B-HyperparameterValue
epochs -X- _ O
for -X- _ B-DatasetName
WIQA -X- _ I-DatasetName
and -X- _ O
10 -X- _ B-HyperparameterValue
epochs -X- _ O
for -X- _ B-DatasetName
QuaRel, -X- _ I-DatasetName
respectively. -X- _ O

Data -X- _ O
and -X- _ O
Metrics -X- _ O
We -X- _ O
consider -X- _ O
two -X- _ O
standard -X- _ O
neural -X- _ O
generation -X- _ O
benchmarks: -X- _ O
E2E -X- _ B-DatasetName
(Novikova -X- _ O
et -X- _ O
al, -X- _ O
2017) -X- _ O
and -X- _ O
WikiBio -X- _ B-DatasetName
(Lebret -X- _ O
et -X- _ O
al, -X- _ O
2016a) -X- _ O
datasets, -X- _ O
with -X- _ O
examples -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1. -X- _ O

We -X- _ O
use -X- _ O
a -X- _ O
list -X- _ O
of -X- _ O
first -X- _ O
names -X- _ O
labeled -X- _ O
by -X- _ O
gender -X- _ O
and -X- _ O
racial -X- _ O
group -X- _ O
based -X- _ O
on -X- _ O
U.S. -X- _ B-DatasetName
Social -X- _ I-DatasetName
Security -X- _ I-DatasetName
Administration -X- _ I-DatasetName
data -X- _ O
and -X- _ O
the -X- _ O
names -X- _ O
dataset -X- _ O
of -X- _ O
Tzioumis -X- _ O
(2018) -X- _ O
to -X- _ O
analyze -X- _ O
how -X- _ O
name -X- _ O
frequency -X- _ O
affects -X- _ O
minority -X- _ O
social -X- _ O
groups -X- _ O
in -X- _ O
four -X- _ O
neural -X- _ O
language -X- _ O
models: -X- _ O
BERT, -X- _ B-MethodName
GPT-2, -X- _ B-MethodName
XLNet, -X- _ B-MethodName
and -X- _ O
T5. -X- _ B-MethodName

While -X- _ O
personalized -X- _ B-TaskName
text -X- _ I-TaskName
generation -X- _ I-TaskName
has -X- _ O
seen -X- _ O
success -X- _ O
in -X- _ O
conveying -X- _ O
user -X- _ O
writing -X- _ O
styles -X- _ O
in -X- _ O
the -X- _ O
product -X- _ O
review -X- _ O
(Ni -X- _ O
et -X- _ O
al, -X- _ O
2017;Ni -X- _ O
and -X- _ O
McAuley, -X- _ O
2018) -X- _ O
and -X- _ O
dialogue -X- _ O
) -X- _ O
spaces, -X- _ O
we -X- _ O
are -X- _ O
the -X- _ O
first -X- _ O
to -X- _ O
consider -X- _ O
it -X- _ O
for -X- _ O
the -X- _ O
problem -X- _ O
of -X- _ O
recipe -X- _ B-TaskName
generation, -X- _ I-TaskName
where -X- _ O
output -X- _ O
quality -X- _ O
is -X- _ O
heavily -X- _ O
dependent -X- _ O
on -X- _ O
the -X- _ O
content -X- _ O
of -X- _ O
the -X- _ O
instructions-such -X- _ O
as -X- _ O
ingredients -X- _ O
and -X- _ O
cooking -X- _ O
techniques. -X- _ O

The -X- _ O
encoder -X- _ O
and -X- _ O
decoder -X- _ O
of -X- _ O
the -X- _ O
node -X- _ O
prediction -X- _ O
module -X- _ O
are -X- _ O
composed -X- _ O
of -X- _ O
2 -X- _ B-HyperparameterValue
layers -X- _ B-HyperparameterName
of -X- _ O
512 -X- _ B-HyperparameterValue
and -X- _ O
1024 -X- _ B-HyperparameterValue
LSTM -X- _ B-HyperparameterName
units -X- _ I-HyperparameterName
each, -X- _ O
respectively. -X- _ O

We -X- _ O
define -X- _ O
the -X- _ O
information -X- _ O
gain -X- _ O
of -X- _ O
an -X- _ O
example -X- _ O
as -X- _ O
the -X- _ O
improvement -X- _ O
on -X- _ O
a -X- _ O
validation -X- _ O
metric -X- _ O
after -X- _ O
training -X- _ O
on -X- _ O
that -X- _ O
example. -X- _ O

Finally, -X- _ O
our -X- _ O
embeddings -X- _ O
perform -X- _ O
competitively -X- _ O
on -X- _ O
the -X- _ B-DatasetName
SentEval -X- _ I-DatasetName
sentence -X- _ B-TaskName
embedding -X- _ I-TaskName
transfer -X- _ I-TaskName
learning -X- _ I-TaskName
benchmark -X- _ O
(Conneau -X- _ O
and -X- _ O
Kiela, -X- _ O
2018). -X- _ O

We -X- _ O
conduct -X- _ O
extensive -X- _ O
experiments -X- _ O
on -X- _ O
the -X- _ B-DatasetName
MS -X- _ I-DatasetName
MARCO -X- _ I-DatasetName
dataset, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
large-scale -X- _ O
benchmark -X- _ O
from -X- _ O
search -X- _ O
engine -X- _ O
Bing. -X- _ O

This -X- _ O
section -X- _ O
analyzes -X- _ O
quality -X- _ O
degradation -X- _ O
with -X- _ O
the -X- _ O
growing -X- _ O
beam -X- _ O
size -X- _ O
of -X- _ O
two -X- _ O
systems: -X- _ O
Neural -X- _ B-TaskName
Machine -X- _ I-TaskName
Translation -X- _ I-TaskName
(NMT) -X- _ B-TaskName
and -X- _ O
Automatic -X- _ B-TaskName
Speech -X- _ I-TaskName
Recognition -X- _ I-TaskName
(ASR). -X- _ B-TaskName

In -X- _ O
order -X- _ O
to -X- _ O
conduct -X- _ O
a -X- _ O
large-scale -X- _ O
analysis -X- _ O
and -X- _ O
compare -X- _ O
how -X- _ O
often -X- _ O
negation -X- _ O
is -X- _ O
present -X- _ O
in -X- _ O
English -X- _ O
and -X- _ O
existing -X- _ B-TaskName
natural -X- _ I-TaskName
language -X- _ I-TaskName
inference -X- _ I-TaskName
benchmarks, -X- _ O
we -X- _ O
employ -X- _ O
a -X- _ O
negation -X- _ O
cue -X- _ O
detector -X- _ O
using -X- _ O
a -X- _ O
Bi-LSTM -X- _ B-MethodName
neural -X- _ O
architecture -X- _ O
with -X- _ O
an -X- _ B-HyperparameterValue
additional -X- _ O
CRF -X- _ B-HyperparameterName
layer -X- _ I-HyperparameterName
(Hossain -X- _ O
et -X- _ O
al, -X- _ O
2020). -X- _ O

CCM -X- _ B-MethodName
is -X- _ O
the -X- _ O
current -X- _ O
state-of-the-art -X- _ O
approach -X- _ O
in -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
response -X- _ B-TaskName
generation -X- _ I-TaskName
with -X- _ I-TaskName
commonsense -X- _ I-TaskName
knowledge -X- _ I-TaskName
. -X- _ O

The -X- _ O
second -X- _ O
convolutional -X- _ O
layer -X- _ O
consists -X- _ O
of -X- _ O
3 -X- _ B-HyperparameterValue
filters -X- _ B-HyperparameterName
of -X- _ O
size -X- _ B-HyperparameterName
3 -X- _ B-HyperparameterValue
× -X- _ I-HyperparameterValue
3. -X- _ I-HyperparameterValue

It -X- _ O
clearly -X- _ O
shows -X- _ O
that -X- _ O
in -X- _ O
VQA2.0, -X- _ B-DatasetName
33% -X- _ O
of -X- _ O
the -X- _ O
questions -X- _ O
are -X- _ O
assigned -X- _ O
the -X- _ O
same -X- _ O
answer -X- _ O
string -X- _ O
by -X- _ O
all -X- _ O
annotators -X- _ O
(i.e., -X- _ O
in -X- _ O
1/3 -X- _ O
questions, -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
perfect -X- _ O
agreement -X- _ O
between -X- _ O
them); -X- _ O
as -X- _ O
for -X- _ B-DatasetName
VizWiz, -X- _ I-DatasetName
this -X- _ O
percentage -X- _ O
drops -X- _ O
to -X- _ O
only -X- _ O
3%. -X- _ O

We -X- _ O
find -X- _ O
in -X- _ O
this -X- _ O
case -X- _ O
that -X- _ O
PreCo -X- _ B-MethodName
outperforms -X- _ O
OntoNotes -X- _ B-MethodName
even -X- _ O
more -X- _ O
on -X- _ O
QBCoref, -X- _ B-DatasetName
LitBank, -X- _ B-DatasetName
as -X- _ O
well -X- _ O
as -X- _ O
ARRAU -X- _ B-DatasetName
RST -X- _ I-DatasetName
. -X- _ O

All -X- _ O
the -X- _ O
models -X- _ O
are -X- _ O
trained -X- _ O
using -X- _ O
Adam -X- _ B-MethodName
optimizer -X- _ O
(Kingma -X- _ O
and -X- _ O
Ba, -X- _ O
2015) -X- _ O
with -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
0.001, -X- _ B-HyperparameterValue
for -X- _ O
120 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
and -X- _ O
the -X- _ O
best -X- _ O
model -X- _ O
hyperparameters -X- _ O
are -X- _ O
chosen -X- _ O
on -X- _ O
the -X- _ O
basis -X- _ O
of -X- _ O
development -X- _ O
set -X- _ O
accuracy. -X- _ B-MetricName

We -X- _ O
finetuned -X- _ O
the -X- _ O
models -X- _ O
on -X- _ O
the -X- _ O
gold -X- _ O
paragraphs -X- _ O
(without -X- _ O
the -X- _ O
distractor -X- _ O
paragraphs) -X- _ O
for -X- _ O
2 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
with -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
5e -X- _ B-HyperparameterValue
−5 -X- _ I-HyperparameterValue
and -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
16. -X- _ B-HyperparameterValue

Duan -X- _ O
et -X- _ O
al -X- _ O
(2019) -X- _ O
propose -X- _ B-DatasetName
CJRC, -X- _ I-DatasetName
a -X- _ O
legal -X- _ B-TaskName
reading -X- _ I-TaskName
comprehension -X- _ I-TaskName
dataset -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
format -X- _ O
as -X- _ O
SQUAD -X- _ B-DatasetName
2.0 -X- _ I-DatasetName
(Rajpurkar -X- _ O
et -X- _ O
al, -X- _ O
2018), -X- _ O
which -X- _ O
includes -X- _ O
span -X- _ O
extraction, -X- _ O
yes/no -X- _ O
questions, -X- _ O
and -X- _ O
unanswerable -X- _ O
questions. -X- _ O

We -X- _ O
train -X- _ O
our -X- _ O
Contrastive-Probe -X- _ B-MethodName
based -X- _ O
on -X- _ O
10k -X- _ O
sentences -X- _ O
which -X- _ O
are -X- _ O
randomly -X- _ O
sampled -X- _ O
from -X- _ O
the -X- _ O
PubMed -X- _ B-DatasetName
texts -X- _ O
5 -X- _ O
using -X- _ O
a -X- _ O
mask -X- _ B-HyperparameterName
ratio -X- _ I-HyperparameterName
of -X- _ O
0.5. -X- _ B-HyperparameterValue

Table -X- _ O
5 -X- _ O
shows -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
achieves -X- _ O
competitive -X- _ O
dependency -X- _ B-TaskName
parsing -X- _ I-TaskName
performance -X- _ O
while -X- _ O
comparing -X- _ O
to -X- _ O
other -X- _ O
models -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
require -X- _ O
gold -X- _ O
POS -X- _ O
tags. -X- _ O

When -X- _ O
unlabeled -X- _ O
data -X- _ O
was -X- _ O
introduced -X- _ O
in -X- _ O
UDA, -X- _ B-MethodName
it -X- _ O
outperformed -X- _ O
TMix -X- _ B-MethodName
such -X- _ O
as -X- _ O
from -X- _ O
58.6% -X- _ B-MetricValue
to -X- _ O
63.2% -X- _ B-MetricValue
on -X- _ O
Yahoo! -X- _ B-DatasetName
with -X- _ O
10 -X- _ O
labeled -X- _ O
data, -X- _ O
because -X- _ O
more -X- _ O
data -X- _ O
was -X- _ O
used -X- _ O
and -X- _ O
consistency -X- _ O
regularization -X- _ O
loss -X- _ O
was -X- _ O
added. -X- _ O

Since -X- _ O
module -X- _ O
outputs -X- _ O
are -X- _ O
constrained -X- _ O
by -X- _ O
the -X- _ O
bounding -X- _ O
boxes -X- _ O
proposed -X- _ O
by -X- _ O
Faster-RCNN -X- _ B-MethodName
( -X- _ O
§2.1), -X- _ O
while -X- _ O
annotated -X- _ O
boxes -X- _ O
are -X- _ O
not, -X- _ O
perfect -X- _ O
faithfulness -X- _ O
could -X- _ O
only -X- _ O
be -X- _ O
achieved -X- _ O
by -X- _ O
a -X- _ O
model -X- _ O
if -X- _ O
there -X- _ O
are -X- _ O
suitable -X- _ O
bounding -X- _ O
boxes. -X- _ O

To -X- _ O
handle -X- _ O
this -X- _ O
problem, -X- _ O
this -X- _ O
paper -X- _ O
proposes -X- _ O
"Extract -X- _ B-MethodName
and -X- _ I-MethodName
Generate" -X- _ I-MethodName
(EAG), -X- _ B-MethodName
a -X- _ O
two-step -X- _ O
approach -X- _ O
to -X- _ O
construct -X- _ B-TaskName
large-scale -X- _ I-TaskName
and -X- _ I-TaskName
high-quality -X- _ I-TaskName
multi-way -X- _ I-TaskName
aligned -X- _ I-TaskName
corpus -X- _ I-TaskName
from -X- _ I-TaskName
bilingual -X- _ I-TaskName
data. -X- _ I-TaskName

Another -X- _ O
future -X- _ O
direction -X- _ O
is -X- _ O
to -X- _ O
investigate -X- _ O
the -X- _ O
generated -X- _ O
document-level -X- _ O
AMRs -X- _ O
on -X- _ O
more -X- _ O
downstream -X- _ O
tasks, -X- _ O
like -X- _ B-TaskName
question -X- _ I-TaskName
answering -X- _ I-TaskName
and -X- _ B-TaskName
dialogue -X- _ I-TaskName
understanding. -X- _ I-TaskName

Even -X- _ O
if -X- _ O
the -X- _ O
instructions -X- _ O
clearly -X- _ O
specify -X- _ O
that -X- _ O
a -X- _ O
DA -X- _ B-MetricName
score -X- _ I-MetricName
below -X- _ B-MetricValue
70 -X- _ I-MetricValue
should -X- _ O
be -X- _ O
assigned -X- _ O
to -X- _ O
inadequate -X- _ O
translations, -X- _ O
4 -X- _ O
annotators -X- _ O
tended -X- _ O
to -X- _ O
give -X- _ O
higher -X- _ O
scores -X- _ O
if -X- _ O
the -X- _ O
sentence -X- _ O
was -X- _ O
fluent -X- _ O
and -X- _ O
appeared -X- _ O
logical. -X- _ O

In -X- _ O
order -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
extent -X- _ O
to -X- _ O
which -X- _ O
models -X- _ O
are -X- _ O
capable -X- _ O
of -X- _ O
this -X- _ O
type -X- _ O
of -X- _ O
reasoning, -X- _ O
we -X- _ O
introduce -X- _ B-DatasetName
Moral -X- _ I-DatasetName
Stories -X- _ I-DatasetName
-a -X- _ O
novel, -X- _ O
crowd-sourced -X- _ O
dataset -X- _ O
of -X- _ O
structured -X- _ O
narratives -X- _ O
that -X- _ O
describe -X- _ O
normative -X- _ O
and -X- _ O
norm-divergent -X- _ O
(or -X- _ O
divergent, -X- _ O
for -X- _ O
short) -X- _ O
actions -X- _ O
taken -X- _ O
by -X- _ O
individuals -X- _ O
to -X- _ O
accomplish -X- _ O
certain -X- _ O
intentions -X- _ O
in -X- _ O
concrete -X- _ O
situations, -X- _ O
and -X- _ O
their -X- _ O
respective -X- _ O
consequences, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1. -X- _ O

Treating -X- _ O
hate -X- _ B-TaskName
speech -X- _ I-TaskName
classification -X- _ I-TaskName
as -X- _ O
a -X- _ O
binary -X- _ O
task -X- _ O
may -X- _ O
not -X- _ O
be -X- _ O
enough -X- _ O
to -X- _ O
inspect -X- _ O
the -X- _ O
motivation -X- _ O
and -X- _ O
the -X- _ O
behavior -X- _ O
of -X- _ O
the -X- _ O
users -X- _ O
promoting -X- _ O
it -X- _ O
and, -X- _ O
how -X- _ O
people -X- _ O
would -X- _ O
react -X- _ O
to -X- _ O
it. -X- _ O

For -X- _ O
both -X- _ O
summarization -X- _ O
tasks, -X- _ O
we -X- _ O
fine-tune -X- _ O
BART -X- _ B-MethodName
using -X- _ O
a -X- _ O
polynomial -X- _ B-HyperparameterName
decay -X- _ I-HyperparameterName
learning -X- _ I-HyperparameterName
rate -X- _ I-HyperparameterName
scheduler -X- _ I-HyperparameterName
with -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
3 -X- _ B-HyperparameterValue
× -X- _ I-HyperparameterValue
10 -X- _ I-HyperparameterValue
−5 -X- _ I-HyperparameterValue
, -X- _ O
using -X- _ O
the -X- _ O
Adam -X- _ B-MethodName
optimizer -X- _ O
(Kingma -X- _ O
and -X- _ O
Ba, -X- _ O
2015). -X- _ O

Dependency -X- _ O
Tree -X- _ O
Probing -X- _ O
Besides -X- _ B-DatasetName
GLUE -X- _ I-DatasetName
and -X- _ B-DatasetName
PAWS, -X- _ I-DatasetName
Sinha -X- _ O
et -X- _ O
al -X- _ O
(2021)'s -X- _ O
analysis -X- _ O
also -X- _ O
includes -X- _ O
several -X- _ O
probing -X- _ O
experiments, -X- _ O
wherein -X- _ O
they -X- _ O
attempt -X- _ O
to -X- _ O
decode -X- _ O
dependency -X- _ O
tree -X- _ O
structure -X- _ O
from -X- _ O
model -X- _ O
representations. -X- _ O

YahooCQA -X- _ B-DatasetName
(Tay -X- _ O
et -X- _ O
al, -X- _ O
2017) -X- _ O
is -X- _ O
a -X- _ O
filtered -X- _ O
and -X- _ O
pre-processed -X- _ O
subset -X- _ O
of -X- _ O
the -X- _ O
large-scale -X- _ O
Yahoo! -X- _ O
Answers -X- _ O
Manner -X- _ O
Questions -X- _ O
dataset -X- _ O
(Surdeanu -X- _ O
et -X- _ O
al, -X- _ O
2008). -X- _ O

Our -X- _ O
reimplemented -X- _ O
BERT -X- _ B-MethodName
baseline -X- _ O
is -X- _ O
even -X- _ O
stronger -X- _ O
than -X- _ O
the -X- _ O
originally -X- _ O
reported -X- _ O
results -X- _ O
in -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
(2019) -X- _ O
T5) -X- _ B-MethodName
and -X- _ O
other -X- _ O
ensemble -X- _ O
models -X- _ O
(e.g., -X- _ O
ALBERT, -X- _ B-MethodName
ALICE), -X- _ B-MethodName
SMART, -X- _ B-MethodName
which -X- _ O
is -X- _ O
a -X- _ O
single -X- _ O
model, -X- _ O
still -X- _ O
sets -X- _ O
new -X- _ O
state-of-the-art -X- _ O
results -X- _ O
on -X- _ O
SST-2, -X- _ B-DatasetName
MRPC -X- _ B-DatasetName
and -X- _ O
STS-B. -X- _ B-DatasetName
By -X- _ O
combining -X- _ O
with -X- _ O
the -X- _ O
Multi-task -X- _ B-TaskName
Learning -X- _ I-TaskName
framework -X- _ O
(MT-DNN), -X- _ B-MethodName
MT-DNN-SMART -X- _ B-MethodName
obtains -X- _ O
new -X- _ O
state-of-the-art -X- _ O
on -X- _ B-DatasetName
GLUE, -X- _ I-DatasetName
pushing -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
benchmark -X- _ O
to -X- _ O
89.9%. -X- _ B-MetricValue

The -X- _ O
parameters -X- _ O
in -X- _ O
VAE -X- _ B-MethodName
are -X- _ O
updated -X- _ O
in -X- _ O
each -X- _ O
mini-batch, -X- _ O
and -X- _ O
the -X- _ O
probabilistic -X- _ O
vector -X- _ O
P -X- _ O
for -X- _ O
action -X- _ O
selection -X- _ O
is -X- _ O
updated -X- _ O
every -X- _ O
2,000 -X- _ B-HyperparameterValue
mini-batches. -X- _ B-HyperparameterName

Thirdly, -X- _ O
cross-domain -X- _ B-TaskName
sentiment -X- _ I-TaskName
analysis -X- _ I-TaskName
also -X- _ O
arises -X- _ O
a -X- _ O
new -X- _ O
challenge -X- _ O
for -X- _ O
BERT -X- _ B-MethodName
to -X- _ O
distinguish -X- _ O
the -X- _ O
characteristic -X- _ O
of -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
domain -X- _ O
to -X- _ O
keep -X- _ O
the -X- _ O
transferable -X- _ O
features -X- _ O
and -X- _ O
abandon -X- _ O
domain-specific -X- _ O
information. -X- _ O

Specifically, -X- _ O
we -X- _ O
first -X- _ O
convert -X- _ O
regular -X- _ O
expressions -X- _ O
into -X- _ O
a -X- _ O
special -X- _ O
form -X- _ O
of -X- _ O
finite-state -X- _ B-MethodName
transducers, -X- _ I-MethodName
then -X- _ O
unfold -X- _ O
its -X- _ O
approximate -X- _ O
inference -X- _ O
algorithm -X- _ O
as -X- _ O
a -X- _ O
bidirectional -X- _ O
recurrent -X- _ O
neural -X- _ O
model -X- _ O
that -X- _ O
performs -X- _ B-TaskName
slot -X- _ I-TaskName
filling -X- _ I-TaskName
via -X- _ O
sequence -X- _ B-TaskName
labeling. -X- _ I-TaskName

For -X- _ O
CMLMs, -X- _ B-MethodName
we -X- _ O
vary -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
mask-predict -X- _ B-HyperparameterName
iterations -X- _ I-HyperparameterName
(T -X- _ B-HyperparameterName
= -X- _ O
4, -X- _ B-HyperparameterValue
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
10) -X- _ B-HyperparameterValue
and -X- _ O
length -X- _ B-HyperparameterName
candidates -X- _ I-HyperparameterName
( -X- _ O
= -X- _ O
1, -X- _ B-HyperparameterValue
2, -X- _ B-HyperparameterValue
3). -X- _ B-HyperparameterValue

Moreover, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
T-A -X- _ B-MethodName
performs -X- _ O
better -X- _ O
than -X- _ O
T-T -X- _ B-MethodName
on -X- _ O
almost -X- _ O
all -X- _ O
metrics -X- _ O
except -X- _ O
Recall -X- _ B-MetricName
and -X- _ O
that -X- _ O
BiLSTM-A -X- _ B-MethodName
is -X- _ O
worse -X- _ O
than -X- _ O
BiLSTM-T -X- _ B-MethodName
on -X- _ O
Pre -X- _ B-MetricName
and -X- _ O
F1. -X- _ B-MetricName

On -X- _ O
the -X- _ O
other -X- _ O
hand, -X- _ O
domain-specific -X- _ O
ontologies -X- _ O
and -X- _ O
knowledge -X- _ O
bases -X- _ O
(KBs) -X- _ O
can -X- _ O
be -X- _ O
easily -X- _ O
accessed, -X- _ O
constructed, -X- _ O
or -X- _ O
integrated, -X- _ O
which -X- _ O
makes -X- _ O
distant -X- _ O
supervision -X- _ O
realistic -X- _ O
for -X- _ O
fine-grained -X- _ B-TaskName
chemistry -X- _ I-TaskName
NER. -X- _ I-TaskName

This -X- _ O
paper -X- _ O
collects -X- _ O
an -X- _ O
easy-to-use -X- _ O
free-form -X- _ O
natural -X- _ O
language -X- _ O
knowledge -X- _ O
corpus -X- _ O
for -X- _ B-TaskName
VQA -X- _ I-TaskName
tasks -X- _ O
with -X- _ O
external -X- _ O
knowledge. -X- _ O

To -X- _ O
model -X- _ O
the -X- _ O
complexity -X- _ O
of -X- _ O
response -X- _ O
strategy -X- _ O
as -X- _ O
discussed -X- _ O
before, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
employ -X- _ O
the -X- _ O
distribution -X- _ O
p -X- _ O
g -X- _ O
and -X- _ O
model -X- _ O
a -X- _ O
mixture -X- _ O
of -X- _ O
strategies -X- _ O
for -X- _ B-TaskName
response -X- _ I-TaskName
generation. -X- _ I-TaskName

S2ORC -X- _ B-DatasetName
can -X- _ O
be -X- _ O
used -X- _ O
for -X- _ O
many -X- _ O
NLP -X- _ O
and -X- _ O
analysis -X- _ O
tasks -X- _ O
over -X- _ O
academic -X- _ O
text. -X- _ O

Furthermore, -X- _ O
it -X- _ O
could -X- _ O
be -X- _ O
especially -X- _ O
useful -X- _ O
to -X- _ O
integrate -X- _ O
cross-lingual -X- _ O
semantic -X- _ O
structures -X- _ O
in -X- _ O
multilingual -X- _ O
applications -X- _ O
of -X- _ B-TaskName
natural -X- _ I-TaskName
language -X- _ I-TaskName
understanding. -X- _ I-TaskName

Inspired -X- _ O
by -X- _ O
KD -X- _ O
applied -X- _ O
in -X- _ O
neural -X- _ B-TaskName
machine -X- _ I-TaskName
translation -X- _ I-TaskName
(NMT) -X- _ B-TaskName
(Kim -X- _ O
and -X- _ O
Rush, -X- _ O
2016) -X- _ O
and -X- _ O
multilingual -X- _ B-TaskName
NMT -X- _ I-TaskName
(Tan -X- _ O
et -X- _ O
al, -X- _ O
2019), -X- _ O
our -X- _ O
approach -X- _ O
contains -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
monolingual -X- _ O
teacher -X- _ O
models, -X- _ O
one -X- _ O
for -X- _ O
each -X- _ O
language, -X- _ O
and -X- _ O
a -X- _ O
single -X- _ O
multilingual -X- _ O
student -X- _ O
model. -X- _ O

According -X- _ O
to -X- _ O
the -X- _ O
two -X- _ O
reasons, -X- _ O
we -X- _ O
respectively -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
reassigned -X- _ B-MethodName
contrastive -X- _ I-MethodName
learning -X- _ I-MethodName
(RCL) -X- _ B-MethodName
to -X- _ O
discriminate -X- _ O
IND -X- _ O
intents -X- _ O
for -X- _ O
over-confident -X- _ O
OOD -X- _ O
and -X- _ O
an -X- _ O
adaptive -X- _ O
class-dependent -X- _ O
local -X- _ O
threshold -X- _ O
mechanism -X- _ O
to -X- _ O
separate -X- _ O
similar -X- _ O
IND -X- _ O
and -X- _ O
OOD -X- _ O
intents -X- _ O
for -X- _ O
over-confident -X- _ O
IND. -X- _ O

In -X- _ O
this -X- _ O
paper, -X- _ O
we -X- _ O
employ -X- _ O
GPT-2 -X- _ B-MethodName
(Radford -X- _ O
et -X- _ O
al, -X- _ O
2019) -X- _ O
as -X- _ O
the -X- _ O
backbone -X- _ O
for -X- _ B-TaskName
response -X- _ I-TaskName
generation, -X- _ I-TaskName
where -X- _ O
the -X- _ O
model -X- _ O
successively -X- _ O
encodes -X- _ O
the -X- _ O
user -X- _ O
utterance -X- _ O
x -X- _ O
t -X- _ O
and -X- _ O
sequence -X- _ O
dialog -X- _ O
act -X- _ O
A -X- _ O
t -X- _ O
as -X- _ O
input, -X- _ O
and -X- _ O
then -X- _ O
decodes -X- _ O
the -X- _ O
response -X- _ O
y -X- _ O
t -X- _ O
in -X- _ O
an -X- _ O
auto-regressive -X- _ O
generation -X- _ O
process. -X- _ O

To -X- _ O
embed -X- _ O
the -X- _ O
sentences -X- _ O
we -X- _ O
use -X- _ O
LASER -X- _ B-MethodName
(Artetxe -X- _ O
and -X- _ O
Schwenk, -X- _ O
2019b), -X- _ O
a -X- _ O
state-ofthe-art -X- _ O
model -X- _ O
for -X- _ B-TaskName
sentence -X- _ I-TaskName
embeddings. -X- _ I-TaskName

Recent -X- _ O
datasets -X- _ O
such -X- _ O
as -X- _ B-DatasetName
DROP -X- _ I-DatasetName
(Dua -X- _ O
et -X- _ O
al, -X- _ O
2019), -X- _ O
EQUATE -X- _ B-DatasetName
, -X- _ O
or -X- _ O
Mathematics -X- _ B-DatasetName
Questions -X- _ I-DatasetName
(Saxton -X- _ O
et -X- _ O
al, -X- _ O
2019) -X- _ O
test -X- _ O
numerical -X- _ O
reasoning; -X- _ O
they -X- _ O
contain -X- _ O
examples -X- _ O
which -X- _ O
require -X- _ O
comparing, -X- _ O
sorting, -X- _ O
and -X- _ O
adding -X- _ O
numbers -X- _ O
in -X- _ O
natural -X- _ O
language -X- _ O
(e.g., -X- _ O
Figure -X- _ O
2). -X- _ O

Through -X- _ O
experiments, -X- _ O
we -X- _ O
demonstrate -X- _ O
that -X- _ O
evaluating -X- _ O
systems -X- _ O
via -X- _ O
response -X- _ O
selection -X- _ O
with -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
developed -X- _ O
by -X- _ O
our -X- _ O
method -X- _ O
correlates -X- _ O
more -X- _ O
strongly -X- _ O
with -X- _ O
human -X- _ B-MethodName
evaluation, -X- _ I-MethodName
compared -X- _ O
with -X- _ O
widely -X- _ O
used -X- _ O
automatic -X- _ O
evaluation -X- _ O
metrics -X- _ O
such -X- _ O
as -X- _ O
BLEU. -X- _ B-MetricName

Conditional -X- _ B-TaskName
text -X- _ I-TaskName
generation -X- _ I-TaskName
is -X- _ O
formulated -X- _ O
as -X- _ O
sequence -X- _ O
transformation -X- _ O
from -X- _ O
a -X- _ O
source -X- _ O
input -X- _ O
x -X- _ O
to -X- _ O
target -X- _ O
output -X- _ O
y -X- _ O
= -X- _ O
(y -X- _ O
1 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
y -X- _ O
n -X- _ O
) -X- _ O
via -X- _ O
a -X- _ O
neural -X- _ O
text -X- _ O
generation -X- _ O
model -X- _ O
parameterized -X- _ O
by -X- _ O
θ. -X- _ O

We -X- _ O
run -X- _ O
35 -X- _ B-HyperparameterValue
times -X- _ O
for -X- _ O
each -X- _ O
baseline -X- _ O
except -X- _ O
xlmr-1 -X- _ B-MethodName
and -X- _ O
xlmr-10 -X- _ B-MethodName
which -X- _ O
are -X- _ O
run -X- _ O
20 -X- _ B-HyperparameterValue
times -X- _ O
and -X- _ O
the -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
is -X- _ O
100. -X- _ B-HyperparameterValue

We -X- _ O
define -X- _ O
the -X- _ O
QA -X- _ O
pair -X- _ O
as -X- _ O
valid -X- _ O
if -X- _ O
(1) -X- _ O
the -X- _ O
question -X- _ O
is -X- _ O
interpretable, -X- _ O
(2) -X- _ O
the -X- _ O
question -X- _ O
does -X- _ O
not -X- _ O
have -X- _ O
presuppositions -X- _ O
rejected -X- _ O
by -X- _ O
the -X- _ O
answer, -X- _ O
(3) -X- _ O
the -X- _ O
question -X- _ O
does -X- _ O
not -X- _ O
contain -X- _ O
more -X- _ O
than -X- _ O
one -X- _ O
sub-question, -X- _ O
and -X- _ O
( -X- _ O
4) -X- _ O
the -X- _ O
proposed -X- _ O
answer -X- _ O
properly -X- _ O
addresses -X- _ O
the -X- _ O
question. -X- _ O

For -X- _ O
training -X- _ O
stage, -X- _ O
we -X- _ O
use -X- _ O
Adam -X- _ B-MethodName
(Kingma -X- _ O
and -X- _ O
Ba, -X- _ O
2014) -X- _ O
for -X- _ O
fine-tuning -X- _ O
with -X- _ O
β -X- _ B-HyperparameterName
1 -X- _ I-HyperparameterName
as -X- _ O
0.9, -X- _ B-HyperparameterValue
β -X- _ B-HyperparameterName
2 -X- _ I-HyperparameterName
as -X- _ O
0.999. -X- _ B-HyperparameterValue

First, -X- _ O
with -X- _ O
a -X- _ O
similar -X- _ O
discard -X- _ O
rate, -X- _ O
our -X- _ O
approach -X- _ O
outperforms -X- _ O
both -X- _ O
BERT -X- _ B-MethodName
base -X- _ O
and -X- _ O
STANCY -X- _ B-MethodName
(the -X- _ O
difference -X- _ O
is -X- _ O
statistically -X- _ O
significant -X- _ O
with -X- _ O
a -X- _ O
p-value -X- _ B-MetricName
of -X- _ O
0.0379 -X- _ B-MetricValue
as -X- _ O
per -X- _ O
paired -X- _ O
t-test -X- _ O
between -X- _ O
Tribrid -X- _ B-MethodName
l -X- _ I-MethodName
and -X- _ O
STANCY -X- _ B-MethodName
and -X- _ O
0.0441 -X- _ B-MetricValue
between -X- _ O
Tribrid -X- _ B-MethodName
d -X- _ I-MethodName
and -X- _ O
STANCY). -X- _ B-MethodName

Following -X- _ O
Guo -X- _ O
et -X- _ O
al -X- _ O
(2020), -X- _ O
we -X- _ O
mask -X- _ O
the -X- _ O
information -X- _ O
of -X- _ O
the -X- _ O
adjacency -X- _ O
matrix -X- _ O
P -X- _ O
(Equation -X- _ O
6) -X- _ O
that -X- _ O
is -X- _ O
beyond -X- _ O
first-order -X- _ O
(k=1) -X- _ O
and -X- _ O
secondorder -X- _ O
(k=2) -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
aspect -X- _ O
for -X- _ O
Ku-maGCN+BERT -X- _ B-MethodName
and -X- _ O
our -X- _ O
ACLT -X- _ B-MethodName
model. -X- _ O

Additionally, -X- _ B-TaskName
text -X- _ I-TaskName
style -X- _ I-TaskName
transfer -X- _ I-TaskName
with -X- _ O
generative -X- _ B-MethodName
adversarial -X- _ I-MethodName
networks -X- _ I-MethodName
(GANs) -X- _ B-MethodName
has -X- _ O
been -X- _ O
used -X- _ O
for -X- _ O
oversampling, -X- _ O
too -X- _ O
(Fu -X- _ O
et -X- _ O
al, -X- _ O
2018;Guo -X- _ O
et -X- _ O
al, -X- _ O
2018;Nie -X- _ O
et -X- _ O
al, -X- _ O
2019). -X- _ O

To -X- _ O
this -X- _ O
end, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
contrastive -X- _ O
learning -X- _ O
framework -X- _ O
for -X- _ O
unsupervised -X- _ B-TaskName
OOD -X- _ I-TaskName
detection, -X- _ I-TaskName
which -X- _ O
is -X- _ O
composed -X- _ O
of -X- _ O
a -X- _ O
contrastive -X- _ O
loss -X- _ O
and -X- _ O
an -X- _ O
OOD -X- _ O
scoring -X- _ O
function. -X- _ O

During -X- _ O
continual -X- _ O
pretraining, -X- _ O
in -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
pretraining -X- _ O
objective, -X- _ O
we -X- _ O
add -X- _ O
a -X- _ O
unsupervised -X- _ B-TaskName
contrastive -X- _ I-TaskName
learning -X- _ I-TaskName
objective, -X- _ O
namely -X- _ O
the -X- _ O
SimCSE -X- _ B-MethodName
(Gao -X- _ O
et -X- _ O
al, -X- _ O
2021) -X- _ O
objective, -X- _ O
so -X- _ O
that -X- _ O
the -X- _ O
similarity -X- _ O
in -X- _ O
the -X- _ O
sentence -X- _ O
representation -X- _ O
better -X- _ O
reflects -X- _ O
the -X- _ O
semantic -X- _ O
similarity -X- _ O
in -X- _ O
the -X- _ O
sentence. -X- _ O

For -X- _ O
encoding -X- _ O
the -X- _ O
textual -X- _ O
modality, -X- _ O
a -X- _ O
Bi-LSTM -X- _ B-HyperparameterName
layer -X- _ I-HyperparameterName
with -X- _ O
200 -X- _ B-HyperparameterValue
memory -X- _ B-HyperparameterName
cells -X- _ I-HyperparameterName
was -X- _ O
used -X- _ O
followed -X- _ O
by -X- _ O
a -X- _ O
dropout -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
0.1. -X- _ B-HyperparameterValue

To -X- _ O
create -X- _ O
MANPLTS -X- _ B-DatasetName
dataset, -X- _ O
we -X- _ O
first -X- _ O
fine-tune -X- _ O
the -X- _ O
BART -X- _ B-MethodName
model -X- _ O
with -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
8 -X- _ B-HyperparameterValue
for -X- _ O
three -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
on -X- _ O
pairs -X- _ O
of -X- _ O
ground-truth -X- _ O
plots -X- _ O
and -X- _ O
stories -X- _ O
from -X- _ O
ROC_LM -X- _ B-DatasetName
and -X- _ O
WP_LM -X- _ B-DatasetName
data -X- _ O
with -X- _ O
the -X- _ O
resulting -X- _ O
perplexity -X- _ B-MetricName
of -X- _ O
3.44 -X- _ B-MetricValue
and -X- _ O
6.79 -X- _ B-MetricValue
for -X- _ O
the -X- _ O
validation -X- _ O
sets. -X- _ O

We -X- _ O
can -X- _ O
improve -X- _ B-TaskName
information -X- _ I-TaskName
extraction -X- _ I-TaskName
from -X- _ O
dialogue -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
knowledge -X- _ O
hidden -X- _ O
states -X- _ O
for -X- _ B-TaskName
response -X- _ I-TaskName
generation -X- _ I-TaskName
by -X- _ O
using -X- _ O
the -X- _ O
encoded -X- _ O
weighted -X- _ O
dialogue -X- _ O
context -X- _ O
as -X- _ O
the -X- _ O
initial -X- _ O
query -X- _ O
vector -X- _ O
q -X- _ O
t -X- _ O
. -X- _ O

For -X- _ O
image -X- _ O
(I), -X- _ O
Q1 -X- _ O
leads -X- _ O
to -X- _ O
different -X- _ O
answers -X- _ O
for -X- _ B-DatasetName
CLEVR -X- _ I-DatasetName
and -X- _ O
CLEVR_HYP, -X- _ B-DatasetName
making -X- _ O
sure -X- _ O
that -X- _ O
one -X- _ O
needs -X- _ O
to -X- _ O
correctly -X- _ O
incorporate -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
T. -X- _ O
Q2 -X- _ O
is -X- _ O
invalid -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
imageaction -X- _ O
text -X- _ O
pair -X- _ O
in -X- _ O
the -X- _ O
CLEVR_HYP -X- _ B-DatasetName
as -X- _ O
one -X- _ O
can -X- _ O
answer -X- _ O
it -X- _ O
correctly -X- _ O
without -X- _ O
understanding -X- _ O
T. -X- _ O

For -X- _ O
Hits@1, -X- _ B-MetricName
JoBi -X- _ B-HyperparameterName
Complex -X- _ I-HyperparameterName
outperforms -X- _ O
baseline -X- _ O
ComplEx -X- _ B-HyperparameterName
by -X- _ O
4% -X- _ B-MetricValue
on -X- _ O
FB15K-237, -X- _ B-DatasetName
6.4% -X- _ B-MetricValue
on -X- _ O
FB15K -X- _ B-DatasetName
and -X- _ O
5.6% -X- _ B-MetricValue
on -X- _ O
YAGO3-10. -X- _ B-DatasetName

Comparing -X- _ O
RCL -X- _ B-MethodName
and -X- _ O
local -X- _ O
threshold, -X- _ O
RCL -X- _ B-MethodName
targets -X- _ O
at -X- _ O
IND->OOD -X- _ O
errors -X- _ B-MetricName
(from -X- _ O
156 -X- _ B-MetricValue
to -X- _ O
122) -X- _ B-MetricValue
for -X- _ O
over-confident -X- _ O
OOD, -X- _ O
while -X- _ O
local -X- _ O
threshold -X- _ O
helps -X- _ O
reduce -X- _ O
OOD->IND -X- _ O
errors -X- _ B-MetricName
(from -X- _ O
576 -X- _ B-MetricValue
to -X- _ O
378) -X- _ B-MetricValue
for -X- _ O
over-confident -X- _ O
IND. -X- _ O

When -X- _ O
averaged -X- _ O
across -X- _ O
all -X- _ O
languages, -X- _ O
translate-train -X- _ O
outperforms -X- _ O
the -X- _ O
English -X- _ O
zero-shot -X- _ O
model -X- _ O
by -X- _ O
10.64 -X- _ B-MetricValue
points, -X- _ O
and -X- _ O
translate-test -X- _ O
by -X- _ O
8.9 -X- _ B-MetricValue
points. -X- _ O

Our -X- _ O
EASE -X- _ B-MethodName
models -X- _ O
outperform -X- _ O
the -X- _ O
SimCSE -X- _ B-MethodName
baselines -X- _ O
across -X- _ O
the -X- _ O
languages, -X- _ O
demonstrating -X- _ O
that -X- _ O
the -X- _ O
entity -X- _ O
contrastive -X- _ O
objective -X- _ O
improves -X- _ O
the -X- _ O
alignment -X- _ B-TaskName
of -X- _ I-TaskName
the -X- _ I-TaskName
multilingual -X- _ I-TaskName
sentence -X- _ I-TaskName
embeddings -X- _ I-TaskName
without -X- _ O
a -X- _ O
parallel -X- _ O
corpora. -X- _ O

Specifically, -X- _ O
we -X- _ O
propose -X- _ O
Multi-tier -X- _ B-MethodName
Knowledge -X- _ I-MethodName
Projection -X- _ I-MethodName
Network -X- _ I-MethodName
(MKPNet) -X- _ B-MethodName
which -X- _ O
can -X- _ O
effectively -X- _ O
leverage -X- _ O
multi-tier -X- _ O
discourse -X- _ O
knowledge -X- _ O
for -X- _ O
implicit -X- _ B-TaskName
event -X- _ I-TaskName
relation -X- _ I-TaskName
extraction. -X- _ I-TaskName

It -X- _ O
also -X- _ O
outperforms -X- _ O
the -X- _ O
baselines -X- _ O
on -X- _ O
Hits@3 -X- _ B-MetricName
and -X- _ O
Hits@10. -X- _ B-MetricName

We -X- _ O
evaluate -X- _ O
the -X- _ O
causal -X- _ O
reasoning -X- _ O
ability -X- _ O
of -X- _ O
several -X- _ O
SOTA -X- _ O
pretrained -X- _ O
language -X- _ O
models, -X- _ O
including -X- _ O
discriminative -X- _ O
pretrained -X- _ O
language -X- _ O
models -X- _ O
BERT -X- _ B-MethodName
(Devlin -X- _ O
et -X- _ O
al, -X- _ O
2019), -X- _ O
RoBERTa -X- _ B-MethodName
(Liu -X- _ O
et -X- _ O
al, -X- _ O
2019), -X- _ O
XLNet -X- _ B-MethodName
(Yang -X- _ O
et -X- _ O
al, -X- _ O
2019), -X- _ O
and -X- _ O
ALBERT -X- _ B-MethodName
(Lan -X- _ O
et -X- _ O
al, -X- _ O
2019); -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
autoregressive -X- _ O
generative -X- _ O
pretrained -X- _ O
language -X- _ O
models -X- _ O
GPT2 -X- _ B-MethodName
(Radford -X- _ O
et -X- _ O
al, -X- _ O
2019) -X- _ O
and -X- _ O
BART -X- _ B-MethodName
(Lewis -X- _ O
et -X- _ O
al, -X- _ O
2020), -X- _ O
which -X- _ O
can -X- _ O
also -X- _ O
be -X- _ O
adapted -X- _ O
to -X- _ O
the -X- _ O
predictive -X- _ B-TaskName
causal -X- _ I-TaskName
reasoning -X- _ I-TaskName
task. -X- _ O

Recent -X- _ O
years -X- _ O
have -X- _ O
witnessed -X- _ O
increasing -X- _ O
attention -X- _ O
in -X- _ O
conversation-based -X- _ O
tasks, -X- _ O
such -X- _ O
as -X- _ B-TaskName
conversational -X- _ I-TaskName
question -X- _ I-TaskName
answering -X- _ I-TaskName
(Choi -X- _ O
et -X- _ O
al, -X- _ O
2018;Reddy -X- _ O
et -X- _ O
al, -X- _ O
2019;, -X- _ O
dialogue -X- _ B-TaskName
response -X- _ I-TaskName
generation -X- _ I-TaskName
(Li -X- _ O
et -X- _ O
al, -X- _ O
2017;Zhang -X- _ O
et -X- _ O
al, -X- _ O
2018;, -X- _ O
dialogue -X- _ B-TaskName
state -X- _ I-TaskName
tracking -X- _ I-TaskName
(Eric -X- _ O
et -X- _ O
al, -X- _ O
2020;Zeng -X- _ O
et -X- _ O
al, -X- _ O
2021) -X- _ O
and -X- _ B-TaskName
dialogue -X- _ I-TaskName
understanding -X- _ I-TaskName
, -X- _ O
mainly -X- _ O
due -X- _ O
to -X- _ O
increasing -X- _ O
commercial -X- _ O
demands. -X- _ O

Leveraging -X- _ O
verbal -X- _ B-TaskName
QA-SRL, -X- _ I-TaskName
our -X- _ O
task -X- _ O
formulation -X- _ O
targets -X- _ O
verbal -X- _ B-TaskName
predicates, -X- _ I-TaskName
leaving -X- _ O
the -X- _ O
coverage -X- _ O
of -X- _ O
other -X- _ O
predicate -X- _ O
types, -X- _ O
including -X- _ O
nominalizations -X- _ O
, -X- _ O
for -X- _ O
future -X- _ O
work. -X- _ O

Belinkov -X- _ O
and -X- _ O
Bisk -X- _ O
(2018) -X- _ O
(Miyato -X- _ O
et -X- _ O
al, -X- _ O
2019) -X- _ O
to -X- _ B-TaskName
text -X- _ I-TaskName
classification -X- _ I-TaskName
tasks -X- _ O
by -X- _ O
applying -X- _ O
perturbations -X- _ O
to -X- _ O
word -X- _ O
embeddings -X- _ O
rather -X- _ O
than -X- _ O
discrete -X- _ O
input -X- _ O
symbols. -X- _ O

This -X- _ O
improved -X- _ O
speed -X- _ O
enables -X- _ O
us -X- _ O
to -X- _ O
scale -X- _ O
up -X- _ O
the -X- _ O
model -X- _ O
by -X- _ O
training -X- _ O
on -X- _ O
an -X- _ O
extended -X- _ O
training -X- _ O
set -X- _ O
that -X- _ O
is -X- _ O
5× -X- _ O
larger, -X- _ O
to -X- _ O
further -X- _ O
move -X- _ O
up -X- _ O
the -X- _ O
SOTA -X- _ O
by -X- _ O
an -X- _ O
additional -X- _ O
2.3% -X- _ B-MetricValue
BLEU -X- _ B-MetricName
and -X- _ O
0.9% -X- _ B-MetricValue
exact -X- _ B-MetricName
match. -X- _ I-MetricName

Furthermore, -X- _ O
our -X- _ O
MESM -X- _ B-MethodName
achieves -X- _ O
comparable -X- _ O
results -X- _ O
with -X- _ O
the -X- _ O
FE2E -X- _ B-MethodName
model, -X- _ O
while -X- _ O
requiring -X- _ O
much -X- _ O
less -X- _ O
computation -X- _ O
in -X- _ O
the -X- _ O
feature -X- _ B-TaskName
extraction. -X- _ I-TaskName

Extensive -X- _ O
evaluations -X- _ O
on -X- _ O
eight -X- _ O
benchmark -X- _ O
datasets -X- _ O
show -X- _ O
that -X- _ O
incorporating -X- _ O
structural -X- _ O
information -X- _ O
contributes -X- _ O
to -X- _ O
consistent -X- _ O
improvements -X- _ O
over -X- _ O
strong -X- _ O
baselines. -X- _ O

Syntactic -X- _ O
phrase -X- _ O
types -X- _ O
do -X- _ O
not -X- _ O
necessarily -X- _ O
translate -X- _ O
to -X- _ O
the -X- _ O
same -X- _ O
type -X- _ O
across -X- _ O
languages -X- _ O
(Koehn -X- _ O
and -X- _ O
Knight, -X- _ O
2003), -X- _ O
but -X- _ O
can -X- _ O
still -X- _ O
leverage -X- _ O
parallel -X- _ O
text -X- _ O
to -X- _ O
improve -X- _ O
unsupervised -X- _ B-TaskName
constituency -X- _ I-TaskName
parsing -X- _ I-TaskName
as -X- _ O
a -X- _ O
phrase -X- _ O
in -X- _ O
one -X- _ O
language -X- _ O
may -X- _ O
have -X- _ O
less -X- _ O
uncertain -X- _ O
structure -X- _ O
in -X- _ O
another -X- _ O
(Snyder -X- _ O
et -X- _ O
al, -X- _ O
2009). -X- _ O

This -X- _ O
demonstrates -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
incorporating -X- _ O
external -X- _ O
knowledge -X- _ O
for -X- _ O
biomedical -X- _ B-TaskName
information -X- _ I-TaskName
extraction. -X- _ I-TaskName

We -X- _ O
use -X- _ O
the -X- _ O
accuracy -X- _ B-MetricName
to -X- _ O
evaluate -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
intent -X- _ B-TaskName
prediction -X- _ I-TaskName
and -X- _ O
the -X- _ O
standard -X- _ O
BIO -X- _ O
structure -X- _ O
to -X- _ O
calculate -X- _ O
the -X- _ O
F1 -X- _ B-MetricName
score -X- _ I-MetricName
for -X- _ O
evaluating -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ B-TaskName
slot -X- _ I-TaskName
filling. -X- _ I-TaskName

Our -X- _ O
sampled -X- _ O
data -X- _ O
used -X- _ O
for -X- _ O
MDA -X- _ B-MethodName
only -X- _ O
takes -X- _ O
up -X- _ O
a -X- _ O
small -X- _ O
amount -X- _ O
of -X- _ O
the -X- _ O
original -X- _ O
training -X- _ O
dataset -X- _ O
(e.g., -X- _ O
less -X- _ O
than -X- _ O
1% -X- _ O
for -X- _ O
SST-2). -X- _ B-DatasetName

LAAM -X- _ B-MethodName
outperforms -X- _ O
the -X- _ O
state-of-the-art -X- _ O
lengthcontrollable -X- _ O
methods -X- _ O
on -X- _ B-DatasetName
CNN/Daily -X- _ I-DatasetName
Mail -X- _ I-DatasetName
and -X- _ O
XSUM -X- _ B-DatasetName
in -X- _ O
terms -X- _ O
of -X- _ O
ROUGE -X- _ B-MetricName
scores, -X- _ I-MetricName
length -X- _ B-MetricName
variance -X- _ I-MetricName
and -X- _ O
human -X- _ B-MetricName
evaluation -X- _ I-MetricName
(Table -X- _ O
5). -X- _ O

For -X- _ O
the -X- _ O
AskAPatient -X- _ B-MethodName
and -X- _ O
TwADR-L -X- _ B-MethodName
datasets, -X- _ O
which -X- _ O
use -X- _ O
10-fold -X- _ B-HyperparameterValue
cross -X- _ O
validation, -X- _ O
the -X- _ O
accuracy -X- _ B-MetricName
metrics -X- _ O
are -X- _ O
averaged -X- _ O
over -X- _ O
10 -X- _ B-HyperparameterValue
folds. -X- _ O

To -X- _ O
evaluate -X- _ O
semantic -X- _ B-TaskName
matching -X- _ I-TaskName
between -X- _ O
two -X- _ O
input/output -X- _ O
texts -X- _ O
(e.g. -X- _ O
a -X- _ O
document -X- _ O
and -X- _ O
its -X- _ O
summary), -X- _ O
QUESTEVAL -X- _ B-MethodName
(Scialom -X- _ O
et -X- _ O
al, -X- _ O
2021) -X- _ O
proceeds -X- _ O
in -X- _ O
two -X- _ O
steps: -X- _ O
1) -X- _ O
a -X- _ O
Question -X- _ O
Generation -X- _ O
system -X- _ O
generates -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
questions -X- _ O
and -X- _ O
(true) -X- _ O
answers -X- _ O
given -X- _ O
the -X- _ O
input -X- _ O
text; -X- _ O
2) -X- _ O
a -X- _ O
Question -X- _ O
Answering -X- _ O
system -X- _ O
predicts -X- _ O
the -X- _ O
(candidate) -X- _ O
answers -X- _ O
to -X- _ O
these -X- _ O
questions -X- _ O
relying -X- _ O
only -X- _ O
on -X- _ O
the -X- _ O
output -X- _ O
text -X- _ O
currently -X- _ O
evaluated. -X- _ O

The -X- _ O
reranking -X- _ B-MetricName
score -X- _ I-MetricName
is -X- _ O
a -X- _ O
linear -X- _ O
combination -X- _ O
of -X- _ O
the -X- _ O
original -X- _ O
beam -X- _ B-MetricName
score -X- _ I-MetricName
and -X- _ O
the -X- _ O
METEOR -X- _ B-MetricName
score -X- _ O
between -X- _ O
the -X- _ O
candidate -X- _ O
prediction -X- _ O
and -X- _ O
C -X- _ O
old -X- _ O
, -X- _ O
both -X- _ O
with -X- _ O
coefficient -X- _ O
0.5 -X- _ B-HyperparameterValue
(tuned -X- _ O
on -X- _ O
validation -X- _ O
data). -X- _ O

We -X- _ O
use -X- _ O
separate -X- _ O
learning -X- _ B-HyperparameterName
rates -X- _ I-HyperparameterName
for -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
encoder -X- _ O
(3e -X- _ B-HyperparameterValue
− -X- _ I-HyperparameterValue
5) -X- _ I-HyperparameterValue
and -X- _ O
other -X- _ O
parameters -X- _ O
(0.001) -X- _ B-HyperparameterValue
in -X- _ O
the -X- _ O
model -X- _ O
(Shaw -X- _ O
et -X- _ O
al, -X- _ O
2019). -X- _ O

For -X- _ O
evaluation, -X- _ O
we -X- _ O
picked -X- _ O
6 -X- _ O
language -X- _ O
pairs -X- _ O
(12 -X- _ O
translation -X- _ O
directions) -X- _ O
to -X- _ O
examine -X- _ O
zero-shot -X- _ O
performance, -X- _ O
including -X- _ O
pairs -X- _ O
of -X- _ O
both -X- _ O
high-resource -X- _ O
languages -X- _ O
(Fr-De -X- _ O
and -X- _ O
De-Cs), -X- _ O
pairs -X- _ O
of -X- _ O
high-and -X- _ O
low-resource -X- _ O
languages -X- _ O
(Ro-De -X- _ O
and -X- _ O
Et-Fr), -X- _ O
and -X- _ O
pairs -X- _ O
of -X- _ O
both -X- _ O
low-resource -X- _ O
languages -X- _ O
(Et-Ro -X- _ O
and -X- _ O
Gu-Tr). -X- _ O

More -X- _ O
importantly, -X- _ B-DatasetName
SGD -X- _ I-DatasetName
has -X- _ O
a -X- _ O
smaller -X- _ O
utterance -X- _ O
length, -X- _ O
making -X- _ O
it -X- _ O
more -X- _ O
difficult -X- _ O
to -X- _ O
map -X- _ O
to -X- _ O
the -X- _ O
correct -X- _ O
slot -X- _ O
type -X- _ O
without -X- _ O
considering -X- _ O
more -X- _ O
context. -X- _ O

We -X- _ O
use -X- _ O
Babylon -X- _ B-MethodName
embeddings -X- _ I-MethodName
since -X- _ O
they -X- _ O
appear -X- _ O
to -X- _ O
outperform -X- _ O
MUSE -X- _ B-MethodName
on -X- _ O
our -X- _ O
data. -X- _ O

To -X- _ O
identify -X- _ O
adversarial -X- _ B-TaskName
attacks, -X- _ I-TaskName
a -X- _ O
perturbation -X- _ O
discriminator -X- _ O
validates -X- _ O
how -X- _ O
likely -X- _ O
a -X- _ O
token -X- _ O
in -X- _ O
the -X- _ O
text -X- _ O
is -X- _ O
perturbed -X- _ O
and -X- _ O
provides -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
potential -X- _ O
perturbations. -X- _ O

For -X- _ O
the -X- _ O
negative -X- _ O
to -X- _ O
positive -X- _ O
attack, -X- _ O
prepending -X- _ O
"m&s∼" -X- _ O
drops -X- _ O
accuracy -X- _ B-MetricName
from -X- _ O
90.1% -X- _ B-MetricValue
to -X- _ O
52.2% -X- _ B-MetricValue
on -X- _ O
negative -X- _ O
examples. -X- _ O

We -X- _ O
used -X- _ O
the -X- _ O
Adagrad -X- _ B-MethodName
optimizer -X- _ O
with -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
64 -X- _ B-HyperparameterValue
to -X- _ O
minimize -X- _ O
the -X- _ O
loss. -X- _ O

We -X- _ O
chose -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
base -X- _ I-MethodName
model -X- _ I-MethodName
(cased) -X- _ I-MethodName
because -X- _ O
it -X- _ O
is -X- _ O
most -X- _ O
comparable -X- _ O
to -X- _ O
GPT-2 -X- _ B-MethodName
with -X- _ O
respect -X- _ O
to -X- _ O
number -X- _ O
of -X- _ O
layers -X- _ O
and -X- _ O
dimensionality -X- _ O
(BERT -X- _ B-MethodName
base -X- _ I-MethodName
model -X- _ I-MethodName
(cased) -X- _ I-MethodName
has -X- _ O
110M -X- _ B-HyperparameterValue
trainable -X- _ B-HyperparameterName
parameters, -X- _ I-HyperparameterName
GPT-2 -X- _ B-MethodName
has -X- _ O
117M). -X- _ B-HyperparameterValue

As -X- _ O
a -X- _ O
result, -X- _ O
we -X- _ O
obtained -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ B-DatasetName
CSQA -X- _ I-DatasetName
that -X- _ O
consists -X- _ O
of -X- _ O
7K, -X- _ O
0.5K -X- _ O
and -X- _ O
1K -X- _ O
conversations -X- _ O
for -X- _ O
training, -X- _ O
development -X- _ O
and -X- _ O
testing, -X- _ O
respectively. -X- _ O

8 -X- _ O
For -X- _ O
Chinese, -X- _ O
we -X- _ O
first -X- _ O
use -X- _ O
OpenCC -X- _ B-DatasetName
9 -X- _ O
to -X- _ O
convert -X- _ O
traditional -X- _ O
characters -X- _ O
to -X- _ O
simplified -X- _ O
characters -X- _ O
and -X- _ O
then -X- _ O
use -X- _ O
Jieba -X- _ B-MethodName
10 -X- _ O
to -X- _ O
perform -X- _ O
tokenization. -X- _ B-TaskName

We -X- _ O
focus -X- _ O
more -X- _ O
on -X- _ O
Mean -X- _ B-MetricName
Recall -X- _ I-MetricName
(MR; -X- _ B-MetricName
Tang -X- _ O
et -X- _ O
al -X- _ O
2020b) -X- _ O
and -X- _ O
Macro -X- _ B-MetricName
F1 -X- _ I-MetricName
(MF1), -X- _ B-MetricName
two -X- _ O
more -X- _ O
balanced -X- _ O
metrics -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
long-tailed -X- _ B-TaskName
IE -X- _ I-TaskName
tasks. -X- _ O

One -X- _ O
could -X- _ O
argue -X- _ O
that -X- _ O
a -X- _ O
QA -X- _ O
system -X- _ O
that -X- _ O
is -X- _ O
evaluated -X- _ O
on -X- _ O
NQ -X- _ B-DatasetName
does -X- _ O
indeed -X- _ O
give -X- _ O
a -X- _ O
good -X- _ O
estimation -X- _ O
of -X- _ O
real-world -X- _ O
utility; -X- _ O
a -X- _ O
system -X- _ O
evaluated -X- _ O
on -X- _ O
TyDi-QA -X- _ B-DatasetName
gives -X- _ O
a -X- _ O
distorted -X- _ O
notion -X- _ O
of -X- _ O
utility -X- _ O
(biased -X- _ O
towards -X- _ O
western-based -X- _ O
speakers -X- _ O
and -X- _ O
against -X- _ O
speakers -X- _ O
from -X- _ O
the -X- _ O
Global -X- _ B-DatasetName
TyDi-QA -X- _ I-DatasetName
( -X- _ O
11) -X- _ O
MLQA -X- _ B-DatasetName
( -X- _ O
1 -X- _ O
South); -X- _ O
a -X- _ O
system -X- _ O
evaluated -X- _ O
on -X- _ O
MLQA -X- _ B-DatasetName
will -X- _ O
give -X- _ O
an -X- _ O
estimation -X- _ O
as -X- _ O
good -X- _ O
as -X- _ O
one -X- _ O
evaluated -X- _ O
on -X- _ O
TyDi-QA, -X- _ B-DatasetName
but -X- _ O
only -X- _ O
on -X- _ O
the -X- _ O
English -X- _ O
portion. -X- _ O

We -X- _ O
visualize -X- _ O
the -X- _ O
efficiency -X- _ O
and -X- _ O
accuracy -X- _ O
comparisons -X- _ O
with -X- _ O
VisualSparta -X- _ B-MethodName
and -X- _ O
cross-BERT -X- _ O
model -X- _ O
including -X- _ O
Unicoder-VL -X- _ B-MethodName
(Li -X- _ O
et -X- _ O
al, -X- _ O
2020a) -X- _ O
and -X- _ O
12-in-1 -X- _ B-MethodName
(Lu -X- _ O
et -X- _ O
al, -X- _ O
2020) -X- _ O
in -X- _ O
Figure1. -X- _ O

In -X- _ O
addition, -X- _ O
in -X- _ B-DatasetName
WIQA, -X- _ I-DatasetName
a -X- _ O
question -X- _ O
q -X- _ O
consists -X- _ O
of -X- _ O
a -X- _ O
cause -X- _ O
c -X- _ O
and -X- _ O
an -X- _ O
effect -X- _ O
e, -X- _ O
and -X- _ O
we -X- _ O
can -X- _ O
operate -X- _ O
the -X- _ O
three -X- _ O
operations -X- _ O
(a) -X- _ O
replacement, -X- _ O
(b) -X- _ O
addition -X- _ O
and -X- _ O
(c) -X- _ O
removal -X- _ O
of -X- _ O
words. -X- _ O
When -X- _ O
we -X- _ O
add -X- _ O
the -X- _ O
operations -X- _ O
to -X- _ O
both -X- _ O
of -X- _ O
c -X- _ O
and -X- _ O
e, -X- _ O
it -X- _ O
would -X- _ O
convert -X- _ O
the -X- _ O
question -X- _ O
to -X- _ O
opposite -X- _ O
twice, -X- _ O
and -X- _ O
thus -X- _ O
the -X- _ O
original -X- _ O
answer -X- _ O
remains -X- _ O
same. -X- _ O

Both -X- _ O
to -X- _ O
illustrate -X- _ O
this -X- _ O
process, -X- _ O
and -X- _ O
to -X- _ O
provide -X- _ O
guidance -X- _ O
for -X- _ O
future -X- _ O
work, -X- _ O
we -X- _ O
demonstrate -X- _ O
these -X- _ O
approaches -X- _ O
below -X- _ O
using -X- _ O
data -X- _ O
from -X- _ O
two -X- _ O
widelyused -X- _ O
datasets -X- _ O
for -X- _ O
evaluating -X- _ O
NLP -X- _ O
models: -X- _ O
SQuAD -X- _ B-DatasetName
2.0 -X- _ I-DatasetName
(Rajpurkar -X- _ O
et -X- _ O
al, -X- _ O
2016(Rajpurkar -X- _ O
et -X- _ O
al, -X- _ O
, -X- _ O
2018 -X- _ O
and -X- _ O
the -X- _ B-DatasetName
GLUE -X- _ I-DatasetName
benchmark -X- _ O
(Wang -X- _ O
et -X- _ O
al, -X- _ O
2018). -X- _ O

Semantic -X- _ O
parsing -X- _ B-TaskName
Semantic -X- _ I-TaskName
parsing -X- _ I-TaskName
is -X- _ O
a -X- _ O
key -X- _ O
task -X- _ O
required -X- _ O
to -X- _ O
complete -X- _ O
the -X- _ O
puzzle -X- _ O
of -X- _ B-TaskName
Natural -X- _ I-TaskName
Language -X- _ I-TaskName
Understanding -X- _ I-TaskName
(Navigli, -X- _ O
2018), -X- _ O
and -X- _ O
one -X- _ O
which -X- _ O
is -X- _ O
receiving -X- _ O
growing -X- _ O
attention -X- _ O
in -X- _ O
the -X- _ O
scientific -X- _ O
community. -X- _ O

To -X- _ O
address -X- _ O
the -X- _ O
above -X- _ O
issues, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
end-to-end -X- _ O
trainable -X- _ O
model -X- _ O
called -X- _ O
PHMOSpell, -X- _ B-MethodName
which -X- _ O
promotes -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
CSC -X- _ B-TaskName
with -X- _ I-TaskName
multi-modal -X- _ I-TaskName
information. -X- _ O

In -X- _ O
the -X- _ O
future, -X- _ O
we -X- _ O
plan -X- _ O
to -X- _ O
apply -X- _ O
our -X- _ O
method -X- _ O
to -X- _ B-TaskName
aspect -X- _ I-TaskName
extraction. -X- _ I-TaskName

For -X- _ O
the -X- _ O
second -X- _ O
setting, -X- _ O
compared -X- _ O
to -X- _ O
XLM-ALIGN, -X- _ B-MethodName
XLM-E -X- _ B-MethodName
produces -X- _ O
an -X- _ O
absolute -X- _ O
0.4 -X- _ B-MetricValue
improvement -X- _ O
on -X- _ O
average. -X- _ O

We -X- _ O
extract -X- _ O
short -X- _ O
clips -X- _ O
from -X- _ O
the -X- _ O
dataset -X- _ O
using -X- _ O
Hierarchical -X- _ B-MethodName
Dynamic -X- _ I-MethodName
Clustering -X- _ I-MethodName
with -X- _ I-MethodName
Motion -X- _ I-MethodName
energy-based -X- _ I-MethodName
pooling -X- _ I-MethodName
(Zhang -X- _ O
et -X- _ O
al, -X- _ O
2018), -X- _ O
a -X- _ O
selfsupervised -X- _ O
action -X- _ O
segmentation -X- _ O
framework -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
summarized -X- _ O
as -X- _ O
follows: -X- _ O
1. -X- _ O

We -X- _ O
fine-tune -X- _ O
GPT-2 -X- _ B-HyperparameterName
and -X- _ O
UniLM -X- _ B-HyperparameterName
on -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
for -X- _ O
20 -X- _ B-HyperparameterValue
epochs. -X- _ B-HyperparameterName

Systematic -X- _ O
experiments -X- _ O
on -X- _ O
public -X- _ O
benchmarks, -X- _ O
including -X- _ O
MSCOCO1K -X- _ B-DatasetName
and -X- _ O
Flickr30K, -X- _ B-DatasetName
demonstrate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
inflating -X- _ O
and -X- _ O
shrinking -X- _ O
approach. -X- _ O

Typical -X- _ B-MetricName
machine -X- _ I-MetricName
translation -X- _ I-MetricName
metrics, -X- _ O
e.g., -X- _ O
BLEU, -X- _ B-MetricName
METEOR, -X- _ B-MetricName
rely -X- _ O
on -X- _ O
lexical -X- _ O
similarity, -X- _ O
which -X- _ O
could -X- _ O
lead -X- _ O
good -X- _ O
translations -X- _ O
being -X- _ O
discarded. -X- _ O

On -X- _ O
the -X- _ O
other -X- _ O
hand, -X- _ O
the -X- _ O
models -X- _ O
trained -X- _ O
with -X- _ O
augmented -X- _ O
data -X- _ O
achieve -X- _ O
better -X- _ O
performance -X- _ O
(from -X- _ O
0.242 -X- _ B-MetricValue
to -X- _ O
0.496 -X- _ B-MetricValue
for -X- _ O
SGD -X- _ B-DatasetName
and -X- _ O
from -X- _ O
0.488 -X- _ B-MetricValue
to -X- _ O
0.744 -X- _ B-MetricValue
for -X- _ O
MultiWOZ) -X- _ B-DatasetName
on -X- _ O
the -X- _ O
augmented -X- _ O
data, -X- _ O
which -X- _ O
means -X- _ O
those -X- _ O
models -X- _ O
learn -X- _ O
the -X- _ O
skill -X- _ O
to -X- _ O
complete -X- _ O
the -X- _ O
disambiguation -X- _ O
task. -X- _ O

Models: -X- _ O
We -X- _ O
evaluate -X- _ O
two -X- _ O
models: -X- _ O
(1) -X- _ O
XLNet-Base: -X- _ B-MethodName
Since -X- _ B-DatasetName
HotpotQA -X- _ I-DatasetName
contexts -X- _ O
are -X- _ O
10 -X- _ O
paragraphs -X- _ O
long, -X- _ O
we -X- _ O
use -X- _ O
XLNet, -X- _ B-MethodName
a -X- _ O
model -X- _ O
that -X- _ O
can -X- _ O
handle -X- _ O
contexts -X- _ O
longer -X- _ O
than -X- _ O
1024 -X- _ O
tokens. -X- _ O

In -X- _ O
Step -X- _ O
2, -X- _ O
according -X- _ O
to -X- _ O
four -X- _ O
important -X- _ O
components -X- _ O
in -X- _ O
each -X- _ O
simile, -X- _ O
we -X- _ O
generate -X- _ O
distractor -X- _ O
candidates -X- _ O
with -X- _ O
three -X- _ O
strategies. -X- _ O

We -X- _ O
remark -X- _ O
that -X- _ O
the -X- _ O
proposed -X- _ O
smoothnessinducing -X- _ B-MethodName
adversarial -X- _ I-MethodName
regularizer -X- _ I-MethodName
was -X- _ O
first -X- _ O
used -X- _ O
in -X- _ O
Miyato -X- _ O
et -X- _ O
al -X- _ O
(2018) -X- _ O
for -X- _ O
semi-supervised -X- _ O
learning -X- _ O
with -X- _ O
p -X- _ B-HyperparameterName
= -X- _ O
2, -X- _ B-HyperparameterValue
and -X- _ O
then -X- _ O
in -X- _ O
Shu -X- _ O
et -X- _ O
al -X- _ O
(2018) -X- _ O
for -X- _ O
unsupervised -X- _ O
domain -X- _ O
adaptation -X- _ O
with -X- _ O
p -X- _ B-HyperparameterName
= -X- _ O
2, -X- _ B-HyperparameterValue
and -X- _ O
more -X- _ O
recently -X- _ O
in -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
(2019) -X- _ O
for -X- _ O
harnessing -X- _ O
the -X- _ O
adversarial -X- _ O
examples -X- _ O
in -X- _ O
image -X- _ O
classification -X- _ O
with -X- _ O
p -X- _ B-HyperparameterName
= -X- _ O
∞. -X- _ B-HyperparameterValue
To -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
our -X- _ O
knowledge, -X- _ O
we -X- _ O
are -X- _ O
the -X- _ O
first -X- _ O
applying -X- _ O
such -X- _ O
a -X- _ O
regularizer -X- _ O
to -X- _ O
fine-tuning -X- _ O
of -X- _ O
pre-trained -X- _ O
language -X- _ O
models. -X- _ O

