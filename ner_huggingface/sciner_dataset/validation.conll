Our -X- _ O
experiments -X- _ O
on -X- _ O
two -X- _ O
major -X- _ O
triple-to-text -X- _ O
datasets-WebNLG -X- _ B-DatasetName
and -X- _ O
E2E-show -X- _ B-DatasetName
that -X- _ O
our -X- _ O
approach -X- _ O
enables -X- _ O
D2T -X- _ B-TaskName
generation -X- _ I-TaskName
from -X- _ O
RDF -X- _ O
triples -X- _ O
in -X- _ O
zero-shot -X- _ O
settings. -X- _ O

Compared -X- _ O
with -X- _ O
previous -X- _ O
methods, -X- _ O
our -X- _ O
method -X- _ O
achieves -X- _ O
state-of-the-art -X- _ O
performance -X- _ O
with -X- _ O
a -X- _ O
F1 -X- _ B-MetricName
improvement -X- _ O
from -X- _ O
40.2 -X- _ B-MetricValue
to -X- _ O
45.4 -X- _ B-MetricValue
on -X- _ O
test -X- _ O
set. -X- _ O

Anther -X- _ O
factor -X- _ O
that -X- _ O
makes -X- _ O
the -X- _ O
out-of-coverage -X- _ B-MetricName
PPL -X- _ I-MetricName
smaller -X- _ O
when -X- _ O
K -X- _ B-HyperparameterName
= -X- _ O
500 -X- _ B-HyperparameterValue
is -X- _ O
that -X- _ O
there -X- _ O
are -X- _ O
more -X- _ O
(simpler) -X- _ O
examples -X- _ O
in -X- _ O
the -X- _ O
set -X- _ O
compared -X- _ O
to -X- _ O
K -X- _ B-HyperparameterName
> -X- _ O
500, -X- _ B-HyperparameterValue
and -X- _ O
the -X- _ O
relatively -X- _ O
simple -X- _ O
utterances -X- _ O
will -X- _ O
also -X- _ O
bring -X- _ O
down -X- _ O
the -X- _ O
PPL. -X- _ B-MetricName

The -X- _ O
data -X- _ O
for -X- _ O
training -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
for -X- _ O
both -X- _ O
XGPT-C -X- _ B-MethodName
and -X- _ O
XPyMT5, -X- _ B-MethodName
and -X- _ O
consists -X- _ O
of -X- _ O
all -X- _ O
5+ -X- _ O
star -X- _ O
GitHub -X- _ O
repositories -X- _ O
which -X- _ O
are -X- _ O
primarily -X- _ O
Python, -X- _ O
filtered -X- _ O
by -X- _ O
files -X- _ O
which -X- _ O
were -X- _ O
either -X- _ O
Python -X- _ O
3 -X- _ O
compliant -X- _ O
or -X- _ O
were -X- _ O
successfully -X- _ O
fixed -X- _ O
by -X- _ O
lib2to3. -X- _ O

In -X- _ O
future -X- _ O
work, -X- _ O
we -X- _ O
want -X- _ O
to -X- _ O
further -X- _ O
test -X- _ O
our -X- _ O
proposed -X- _ O
typos-aware -X- _ O
training -X- _ O
with -X- _ O
more -X- _ O
real-world -X- _ O
typo -X- _ O
queries -X- _ O
by -X- _ O
acquiring -X- _ O
a -X- _ O
real -X- _ O
query -X- _ O
log -X- _ O
with -X- _ O
typos -X- _ O
and -X- _ O
perform -X- _ O
relevance -X- _ O
annotations -X- _ O
on -X- _ O
the -X- _ B-DatasetName
MS -X- _ I-DatasetName
MARCO -X- _ I-DatasetName
passage -X- _ O
collection. -X- _ O

For -X- _ O
the -X- _ O
audio -X- _ O
modality, -X- _ O
we -X- _ O
use -X- _ O
mel-spectrograms -X- _ O
with -X- _ O
a -X- _ O
window -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
25 -X- _ B-HyperparameterValue
ms -X- _ O
and -X- _ O
stride -X- _ B-HyperparameterName
of -X- _ O
12.5 -X- _ B-HyperparameterValue
ms -X- _ I-HyperparameterValue
and -X- _ O
then -X- _ O
chunk -X- _ O
the -X- _ O
spectrograms -X- _ O
per -X- _ O
400 -X- _ B-HyperparameterValue
ms -X- _ I-HyperparameterValue
time -X- _ B-HyperparameterName
window. -X- _ I-HyperparameterName

We -X- _ O
thus -X- _ O
explore -X- _ O
and -X- _ O
propose -X- _ O
alternative -X- _ O
evaluation -X- _ O
measures: -X- _ O
the -X- _ O
reported -X- _ O
humanevaluation -X- _ O
analysis -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
proposed -X- _ O
metrics, -X- _ O
based -X- _ O
on -X- _ B-TaskName
Question -X- _ I-TaskName
Answering, -X- _ I-TaskName
favorably -X- _ O
compares -X- _ O
to -X- _ O
ROUGE -X- _ B-MetricName
-with -X- _ O
the -X- _ O
additional -X- _ O
property -X- _ O
of -X- _ O
not -X- _ O
requiring -X- _ O
reference -X- _ O
summaries. -X- _ O

Text -X- _ B-TaskName
style -X- _ I-TaskName
transfer -X- _ I-TaskName
is -X- _ O
an -X- _ O
important -X- _ O
Natural -X- _ B-TaskName
Language -X- _ I-TaskName
Generation -X- _ I-TaskName
(NLG) -X- _ B-TaskName
task, -X- _ O
and -X- _ O
has -X- _ O
wideranging -X- _ O
applications -X- _ O
from -X- _ O
adapting -X- _ O
conversational -X- _ O
style -X- _ O
in -X- _ O
dialogue -X- _ O
agents -X- _ O
(Zhou -X- _ O
et -X- _ O
al, -X- _ O
2017), -X- _ O
obfuscating -X- _ O
personal -X- _ O
attributes -X- _ O
(such -X- _ O
as -X- _ O
gender) -X- _ O
to -X- _ O
prevent -X- _ O
privacy -X- _ O
intrusion -X- _ O
(Reddy -X- _ O
and -X- _ O
Knight, -X- _ O
2016), -X- _ O
altering -X- _ O
texts -X- _ O
to -X- _ O
be -X- _ O
more -X- _ O
formal -X- _ O
or -X- _ O
informal -X- _ O
(Rao -X- _ O
and -X- _ O
Tetreault, -X- _ O
2018), -X- _ O
to -X- _ O
generating -X- _ O
poetry -X- _ O
. -X- _ O

The -X- _ O
proposed -X- _ O
model -X- _ O
achieves -X- _ O
new -X- _ O
state-of-the-art -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
miniRCV1 -X- _ B-DatasetName
and -X- _ O
ODIC -X- _ B-DatasetName
dataset, -X- _ O
improving -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
(accuracy) -X- _ B-MetricName
by -X- _ O
2∼4%. -X- _ B-MetricValue

We -X- _ O
extend -X- _ O
these -X- _ O
rules -X- _ O
for -X- _ O
the -X- _ O
cross-lingual -X- _ B-TaskName
AMR -X- _ I-TaskName
parsing -X- _ I-TaskName
task -X- _ O
based -X- _ O
on -X- _ O
several -X- _ O
multilingual -X- _ O
resources -X- _ O
such -X- _ O
as -X- _ O
Wikipedia, -X- _ B-DatasetName
BabelNet -X- _ B-DatasetName
4.0 -X- _ I-DatasetName
(Navigli -X- _ O
and -X- _ O
Ponzetto, -X- _ O
2010), -X- _ B-DatasetName
DBpedia -X- _ I-DatasetName
Spotlight -X- _ O
API -X- _ O
(Daiber -X- _ O
et -X- _ O
al, -X- _ O
2013) -X- _ O
cation -X- _ O
in -X- _ O
all -X- _ O
languages -X- _ O
but -X- _ O
Chinese, -X- _ O
for -X- _ O
which -X- _ O
we -X- _ O
use -X- _ O
Babelfy -X- _ B-MethodName
(Moro -X- _ O
et -X- _ O
al, -X- _ O
2014) -X- _ O
instead, -X- _ O
Stanford -X- _ B-MethodName
CoreNLP -X- _ I-MethodName
for -X- _ O
English -X- _ O
preprocessing -X- _ O
pipeline, -X- _ O
the -X- _ O
Stanza -X- _ B-MethodName
Toolkit -X- _ I-MethodName
(Qi -X- _ O
et -X- _ O
al, -X- _ O
2020) -X- _ O
for -X- _ O
Chinese, -X- _ O
German -X- _ O
and -X- _ O
Spanish -X- _ O
sentences, -X- _ O
and -X- _ O
Tint -X- _ B-MethodName
3 -X- _ I-MethodName
(Aprosio -X- _ O
and -X- _ O
Moretti, -X- _ O
2016) -X- _ O
for -X- _ O
Italian. -X- _ O

For -X- _ O
the -X- _ O
negative -X- _ O
training -X- _ O
samples -X- _ O
collection, -X- _ O
we -X- _ O
randomly -X- _ O
select -X- _ O
generated -X- _ O
headlines -X- _ O
from -X- _ O
a -X- _ O
pointer -X- _ B-MethodName
generator -X- _ I-MethodName
(See -X- _ O
et -X- _ O
al, -X- _ O
2017) -X- _ O
model -X- _ O
trained -X- _ O
on -X- _ B-DatasetName
LCSTS -X- _ I-DatasetName
dataset -X- _ O
(Hu -X- _ O
et -X- _ O
al, -X- _ O
2015) -X- _ O
and -X- _ O
create -X- _ O
a -X- _ O
balanced -X- _ O
training -X- _ O
corpus -X- _ O
which -X- _ O
includes -X- _ O
351,508 -X- _ O
training -X- _ O
samples -X- _ O
and -X- _ O
9,022 -X- _ O
validation -X- _ O
samples. -X- _ O

The -X- _ O
training -X- _ O
process -X- _ O
is -X- _ O
iterated -X- _ O
upon -X- _ O
200 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
and -X- _ O
early -X- _ B-MethodName
stopping -X- _ I-MethodName
(Yuan -X- _ O
et -X- _ O
al, -X- _ O
2007) -X- _ O
is -X- _ O
applied -X- _ O
when -X- _ O
the -X- _ O
validation -X- _ O
loss -X- _ O
stops -X- _ O
decreasing -X- _ O
by -X- _ O
10 -X- _ B-HyperparameterValue
epochs. -X- _ B-HyperparameterName

They -X- _ O
are -X- _ O
partially -X- _ B-MethodName
observable -X- _ I-MethodName
Markov -X- _ I-MethodName
decision -X- _ I-MethodName
processes -X- _ I-MethodName
(POMDPs), -X- _ B-MethodName
represented -X- _ O
as -X- _ O
a -X- _ O
7-tuple -X- _ O
of -X- _ O
S, -X- _ O
T, -X- _ O
A, -X- _ O
Ω, -X- _ O
O, -X- _ O
R, -X- _ O
γ -X- _ O
representing -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
environment -X- _ O
states, -X- _ O
conditional -X- _ O
transition -X- _ O
probabilities -X- _ O
between -X- _ O
states, -X- _ O
the -X- _ O
vocabulary -X- _ O
or -X- _ O
words -X- _ O
used -X- _ O
to -X- _ O
compose -X- _ O
action -X- _ O
commands -X- _ O
or -X- _ O
dialogue -X- _ O
utterances -X- _ O
(e.g. -X- _ O
get -X- _ O
sword -X- _ O
or -X- _ O
Hey, -X- _ O
give -X- _ O
me -X- _ O
that -X- _ O
sword! -X- _ O
respectively), -X- _ O
observations -X- _ O
returned -X- _ O
by -X- _ O
the -X- _ O
game, -X- _ O
observation -X- _ O
conditional -X- _ O
probabilities, -X- _ O
reward -X- _ O
function, -X- _ O
and -X- _ O
the -X- _ O
discount -X- _ O
factor -X- _ O
respectively. -X- _ O

It -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
CLUECor-pusSmall -X- _ B-DatasetName
dataset -X- _ O
of -X- _ O
14GB -X- _ O
, -X- _ O
which -X- _ O
consists -X- _ O
of -X- _ O
Chinese -X- _ O
news, -X- _ O
Wikipedia, -X- _ O
online -X- _ O
forum -X- _ O
message, -X- _ O
and -X- _ O
consumer -X- _ O
comments. -X- _ O

In -X- _ O
this -X- _ O
work, -X- _ O
we -X- _ O
propose -X- _ O
two -X- _ O
additional -X- _ O
variations -X- _ O
of -X- _ O
stance -X- _ B-TaskName
detection: -X- _ I-TaskName
zero-shot -X- _ B-TaskName
stance -X- _ I-TaskName
detection -X- _ I-TaskName
(a -X- _ O
classifier -X- _ O
is -X- _ O
evaluated -X- _ O
on -X- _ O
a -X- _ O
large -X- _ O
number -X- _ O
of -X- _ O
completely -X- _ O
new -X- _ O
topics) -X- _ O
and -X- _ O
few-shot -X- _ B-TaskName
stance -X- _ I-TaskName
detection -X- _ I-TaskName
(a -X- _ O
classifier -X- _ O
is -X- _ O
evaluated -X- _ O
on -X- _ O
a -X- _ O
large -X- _ O
number -X- _ O
of -X- _ O
topics -X- _ O
for -X- _ O
which -X- _ O
it -X- _ O
has -X- _ O
very -X- _ O
few -X- _ O
training -X- _ O
examples). -X- _ O

Extensive -X- _ O
experimental -X- _ O
results -X- _ O
show -X- _ O
that, -X- _ O
the -X- _ O
proposed -X- _ O
method -X- _ O
achieves -X- _ O
consistent -X- _ O
improvement -X- _ O
over -X- _ O
the -X- _ O
stateof-the-art -X- _ O
baselines -X- _ O
including -X- _ O
kNN-MT, -X- _ B-MethodName
while -X- _ O
maintaining -X- _ O
the -X- _ O
same -X- _ O
training -X- _ O
and -X- _ O
decoding -X- _ O
speed -X- _ O
as -X- _ O
the -X- _ O
standard -X- _ O
NMT -X- _ B-TaskName
model. -X- _ O

Such -X- _ O
representations -X- _ O
are -X- _ O
actively -X- _ O
integrated -X- _ O
in -X- _ O
several -X- _ O
Natural -X- _ B-TaskName
Language -X- _ I-TaskName
Processing -X- _ I-TaskName
(NLP) -X- _ B-TaskName
applications, -X- _ O
inter -X- _ O
alia, -X- _ B-TaskName
information -X- _ I-TaskName
extraction -X- _ I-TaskName
(Rao -X- _ O
et -X- _ O
al, -X- _ O
2017), -X- _ B-TaskName
text -X- _ I-TaskName
summarization -X- _ I-TaskName
(Hardy -X- _ O
and -X- _ O
Vlachos, -X- _ O
2018;Liao -X- _ O
et -X- _ O
al, -X- _ O
2018), -X- _ O
paraphrase -X- _ B-TaskName
detection -X- _ I-TaskName
(Issa -X- _ O
et -X- _ O
al, -X- _ O
2018), -X- _ O
spoken -X- _ B-TaskName
language -X- _ I-TaskName
understanding -X- _ I-TaskName
(Damonte -X- _ O
et -X- _ O
al, -X- _ O
2019), -X- _ B-TaskName
machine -X- _ I-TaskName
translation -X- _ I-TaskName
(Song -X- _ O
et -X- _ O
al, -X- _ O
2019b) -X- _ O
and -X- _ O
human-robot -X- _ B-TaskName
interaction -X- _ I-TaskName
(Bonial -X- _ O
et -X- _ O
al, -X- _ O
2020). -X- _ O

In -X- _ O
particular, -X- _ O
PROC-B -X- _ B-DatasetName
(Glavaš -X- _ O
et -X- _ O
al, -X- _ O
2019), -X- _ O
a -X- _ O
supervised -X- _ O
CLWE -X- _ B-TaskName
framework -X- _ O
that -X- _ O
simply -X- _ O
applies -X- _ O
multiple -X- _ O
iterations -X- _ O
of -X- _ O
2 -X- _ O
OPA, -X- _ O
has -X- _ O
been -X- _ O
demonstrated -X- _ O
to -X- _ O
produce -X- _ O
very -X- _ O
competitive -X- _ O
performance -X- _ O
on -X- _ O
various -X- _ O
benchmark -X- _ O
tasks -X- _ O
including -X- _ O
BLI -X- _ B-TaskName
as -X- _ O
well -X- _ O
as -X- _ B-TaskName
cross-lingual -X- _ I-TaskName
transfer -X- _ I-TaskName
for -X- _ O
NLI -X- _ B-TaskName
and -X- _ B-TaskName
information -X- _ I-TaskName
retrieval. -X- _ I-TaskName

Moreover, -X- _ O
when -X- _ O
we -X- _ O
remove -X- _ O
the -X- _ O
state -X- _ O
transition -X- _ O
prediction -X- _ O
task -X- _ O
and -X- _ O
don't -X- _ O
fine-tune -X- _ O
our -X- _ O
model -X- _ O
with -X- _ O
adaptive -X- _ O
objective -X- _ O
(only -X- _ O
CHAN -X- _ O
remains), -X- _ O
the -X- _ O
joint -X- _ O
accuracy -X- _ B-MetricName
decreases -X- _ O
by -X- _ O
1.55%. -X- _ B-MetricValue

We -X- _ O
also -X- _ O
find, -X- _ O
however, -X- _ O
that -X- _ O
performance -X- _ O
is -X- _ O
heavily -X- _ O
influenced -X- _ O
by -X- _ O
word -X- _ O
frequency, -X- _ O
with -X- _ O
experiments -X- _ O
showing -X- _ O
that -X- _ O
both -X- _ O
the -X- _ O
absolute -X- _ O
frequency -X- _ O
of -X- _ O
a -X- _ O
verb -X- _ O
form, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
frequency -X- _ O
relative -X- _ O
to -X- _ O
the -X- _ O
alternate -X- _ O
inflection, -X- _ O
are -X- _ O
causally -X- _ O
implicated -X- _ O
in -X- _ O
the -X- _ O
predictions -X- _ O
BERT -X- _ B-MethodName
makes -X- _ O
at -X- _ O
inference -X- _ O
time. -X- _ O

In -X- _ O
terms -X- _ O
of -X- _ O
performance, -X- _ O
with -X- _ O
a -X- _ O
top-p -X- _ B-HyperparameterName
value -X- _ O
from -X- _ O
0.9 -X- _ B-HyperparameterValue
to -X- _ I-HyperparameterValue
0.5, -X- _ I-HyperparameterValue
there -X- _ O
is -X- _ O
no -X- _ O
significant -X- _ O
drop -X- _ O
in -X- _ O
the -X- _ O
evaluation -X- _ O
performance. -X- _ O

For -X- _ O
all -X- _ O
the -X- _ O
experiments, -X- _ O
we -X- _ O
use -X- _ O
pretrained -X- _ O
300-dimensional -X- _ B-HyperparameterValue
Glove -X- _ B-MethodName
3 -X- _ I-MethodName
vectors -X- _ O
(Pennington -X- _ O
et -X- _ O
al, -X- _ O
2014) -X- _ O
to -X- _ O
initialize -X- _ O
the -X- _ O
word -X- _ O
embeddings. -X- _ O

We -X- _ O
see -X- _ O
that -X- _ O
TACOLM -X- _ B-MethodName
improves -X- _ O
by -X- _ O
4% -X- _ B-MetricValue
and -X- _ O
8% -X- _ B-MetricValue
on -X- _ O
the -X- _ O
coreference -X- _ O
task -X- _ O
and -X- _ O
the -X- _ O
parent-child -X- _ O
tasks -X- _ O
over -X- _ O
BERT, -X- _ B-MethodName
respectively. -X- _ O

Still -X- _ O
surprisingly, -X- _ O
our -X- _ O
model -X- _ O
generalizes -X- _ O
reasonably -X- _ O
to -X- _ O
compositionally -X- _ O
novel -X- _ O
(outof-coverage) -X- _ O
splits, -X- _ O
registering -X- _ O
30%∼50% -X- _ B-MetricValue
accuracies, -X- _ B-MetricName
in -X- _ O
contrast -X- _ O
to -X- _ O
HB19 -X- _ O
reporting -X- _ O
accuracies -X- _ B-MetricName
smaller -X- _ O
than -X- _ O
10% -X- _ B-MetricValue
on -X- _ O
similar -X- _ O
benchmarks -X- _ O
for -X- _ O
OVERNIGHT. -X- _ B-MethodName

The -X- _ O
improvements -X- _ O
obtained -X- _ O
by -X- _ O
the -X- _ O
∞-former -X- _ B-MethodName
are -X- _ O
larger -X- _ O
on -X- _ O
the -X- _ O
PG19 -X- _ B-DatasetName
dataset, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
justified -X- _ O
by -X- _ O
the -X- _ O
nature -X- _ O
of -X- _ O
the -X- _ O
datasets: -X- _ O
books -X- _ O
have -X- _ O
more -X- _ O
long -X- _ O
range -X- _ O
dependencies -X- _ O
than -X- _ O
Wikipedia -X- _ B-DatasetName
articles -X- _ O
(Rae -X- _ O
et -X- _ O
al, -X- _ O
2019). -X- _ O

Parameters: -X- _ O
For -X- _ O
both -X- _ O
Reptile -X- _ O
and -X- _ O
our -X- _ O
method, -X- _ O
we -X- _ O
choose -X- _ O
K -X- _ B-HyperparameterName
by -X- _ O
searching -X- _ O
the -X- _ O
grid -X- _ O
{1, -X- _ B-HyperparameterValue
3, -X- _ B-HyperparameterValue
5, -X- _ B-HyperparameterValue
10}, -X- _ B-HyperparameterValue
η -X- _ B-HyperparameterName
by -X- _ O
{0.01, -X- _ B-HyperparameterValue
0.05, -X- _ B-HyperparameterValue
0.1, -X- _ B-HyperparameterValue
0.3, -X- _ B-HyperparameterValue
0.5} -X- _ B-HyperparameterValue
for -X- _ O
the -X- _ O
task -X- _ B-HyperparameterName
adaptation -X- _ I-HyperparameterName
step, -X- _ I-HyperparameterName
and -X- _ O
choose -X- _ O
τ -X- _ B-HyperparameterName
= -X- _ O
1 -X- _ B-HyperparameterValue
for -X- _ O
the -X- _ O
meta -X- _ B-HyperparameterName
update. -X- _ I-HyperparameterName

On -X- _ O
the -X- _ O
IWSLT'14 -X- _ B-DatasetName
De-En -X- _ I-DatasetName
dataset, -X- _ O
we -X- _ O
conduct -X- _ O
training -X- _ O
on -X- _ O
one -X- _ O
NVIDIA -X- _ O
GeForce -X- _ O
GTX -X- _ O
1080 -X- _ O
Ti -X- _ O
GPU -X- _ O
and -X- _ O
set -X- _ O
the -X- _ O
maximum -X- _ B-HyperparameterName
batch -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
to -X- _ O
be -X- _ O
4096. -X- _ B-HyperparameterValue

We -X- _ O
find -X- _ O
that -X- _ O
ESCHER -X- _ B-MethodName
predictions -X- _ O
have -X- _ O
an -X- _ O
average -X- _ O
Jaccard -X- _ B-MetricName
similarity -X- _ I-MetricName
with -X- _ O
the -X- _ O
gold -X- _ O
predictions -X- _ O
of -X- _ O
0.49, -X- _ B-MetricValue
whereas -X- _ O
the -X- _ O
random -X- _ B-MethodName
baseline -X- _ O
achieves -X- _ O
0.27. -X- _ B-MetricValue

We -X- _ O
focus -X- _ O
on -X- _ O
the -X- _ B-TaskName
text -X- _ I-TaskName
classification -X- _ I-TaskName
problem, -X- _ O
where -X- _ O
the -X- _ O
dominant -X- _ O
approach -X- _ O
to -X- _ O
using -X- _ O
these -X- _ O
nonneural -X- _ O
models -X- _ O
is -X- _ O
to -X- _ O
first -X- _ O
calculate -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
unique -X- _ O
terms -X- _ O
in -X- _ O
the -X- _ O
dataset -X- _ O
(the -X- _ O
vocabulary, -X- _ O
size -X- _ O
V -X- _ O
) -X- _ O
and -X- _ O
encode -X- _ O
each -X- _ O
instance -X- _ O
of -X- _ O
the -X- _ O
dataset -X- _ O
into -X- _ O
a -X- _ O
bag-of-words -X- _ O
(BoW) -X- _ O
representation -X- _ O
(Joachims, -X- _ O
1998;Zhang -X- _ O
et -X- _ O
al, -X- _ O
2010). -X- _ O

Therefore, -X- _ O
in -X- _ O
multimodal -X- _ O
affective -X- _ O
computing -X- _ O
tasks, -X- _ O
such -X- _ O
as -X- _ B-TaskName
emotion -X- _ I-TaskName
recognition, -X- _ I-TaskName
there -X- _ O
are -X- _ O
usually -X- _ O
three -X- _ O
modalities: -X- _ O
textual, -X- _ O
acoustic, -X- _ O
and -X- _ O
visual. -X- _ O

The -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
proposed -X- _ O
method -X- _ O
can -X- _ O
converge -X- _ O
and -X- _ O
outperform -X- _ O
several -X- _ O
state-of-the-art -X- _ O
multi-task -X- _ B-TaskName
text -X- _ I-TaskName
classification -X- _ I-TaskName
methods. -X- _ O

We -X- _ O
set -X- _ O
the -X- _ O
numbers -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
samples -X- _ I-HyperparameterName
as -X- _ O
N -X- _ B-HyperparameterName
= -X- _ O
100 -X- _ B-HyperparameterValue
and -X- _ O
M -X- _ B-HyperparameterName
= -X- _ O
512. -X- _ B-HyperparameterValue

In -X- _ O
which, -X- _ O
each -X- _ O
convolutional -X- _ O
layer -X- _ O
has -X- _ O
64 -X- _ B-HyperparameterValue
filters, -X- _ B-MethodName
each -X- _ O
kernel's -X- _ B-MethodName
size -X- _ I-MethodName
is -X- _ O
7, -X- _ B-HyperparameterValue
there -X- _ O
are -X- _ O
2 -X- _ B-HyperparameterValue
such -X- _ O
convolutional -X- _ O
layers -X- _ O
that -X- _ O
share -X- _ O
weights. -X- _ O

Instead -X- _ O
of -X- _ O
learning -X- _ O
g -X- _ O
V -X- _ O
and -X- _ O
g -X- _ O
T -X- _ O
from -X- _ O
scratch, -X- _ O
we -X- _ O
build -X- _ O
on -X- _ O
a -X- _ O
pre-trained -X- _ O
CLIP -X- _ B-MethodName
model, -X- _ O
which -X- _ O
has -X- _ O
been -X- _ O
pre-trained -X- _ O
on -X- _ O
We-bImageText -X- _ B-DatasetName
(WIT), -X- _ B-DatasetName
a -X- _ O
dataset -X- _ O
of -X- _ O
400 -X- _ O
million -X- _ O
imagetext -X- _ O
pairs -X- _ O
gathered -X- _ O
from -X- _ O
the -X- _ O
internet -X- _ O
(Radford -X- _ O
et -X- _ O
al, -X- _ O
2021). -X- _ O

This -X- _ O
result -X- _ O
shows -X- _ O
that -X- _ O
although -X- _ O
both -X- _ O
GBDA -X- _ B-MethodName
and -X- _ O
BAE -X- _ B-MethodName
produce -X- _ O
detectable -X- _ O
changes, -X- _ O
our -X- _ O
method -X- _ O
is -X- _ O
slightly -X- _ O
less -X- _ O
perceptible -X- _ O
than -X- _ O
BAE -X- _ B-MethodName
but -X- _ O
the -X- _ O
model -X- _ O
accuracy -X- _ B-MetricName
after -X- _ O
attack -X- _ O
is -X- _ O
significantly -X- _ O
lower -X- _ O
for -X- _ O
our -X- _ O
attack: -X- _ O
4.7% -X- _ B-MetricValue
for -X- _ O
GBDA -X- _ B-MethodName
compared -X- _ O
to -X- _ O
12.0% -X- _ B-MetricValue
for -X- _ O
BAE -X- _ B-MethodName
(cf. -X- _ O

HYPMIX -X- _ B-MethodName
shows -X- _ O
maximum -X- _ O
improvement -X- _ O
when -X- _ O
applied -X- _ O
on -X- _ O
extremely -X- _ O
low -X- _ O
training -X- _ O
data, -X- _ O
with -X- _ O
samples -X- _ O
in -X- _ O
order -X- _ O
of -X- _ O
n -X- _ B-HyperparameterName
= -X- _ O
10. -X- _ B-HyperparameterValue

Compared -X- _ O
to -X- _ O
the -X- _ O
KL -X- _ B-MethodName
analysis -X- _ I-MethodName
which -X- _ O
focuses -X- _ O
on -X- _ O
the -X- _ O
relative -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
algorithms, -X- _ O
the -X- _ O
human -X- _ B-MetricName
evaluation -X- _ I-MetricName
highlights -X- _ O
the -X- _ O
realizable -X- _ O
generation -X- _ O
quality -X- _ O
enabled -X- _ O
specifically -X- _ O
by -X- _ O
large -X- _ O
pretrained -X- _ O
language -X- _ O
models. -X- _ O

We -X- _ O
attribute -X- _ O
the -X- _ O
minor -X- _ O
improvement -X- _ O
over -X- _ O
BM25 -X- _ B-MethodName
on -X- _ B-DatasetName
TriviaQA -X- _ I-DatasetName
to -X- _ O
a -X- _ O
high -X- _ O
overlap -X- _ O
between -X- _ O
questions -X- _ O
and -X- _ O
passages, -X- _ O
which -X- _ O
gives -X- _ O
term-based -X- _ O
retriever -X- _ O
a -X- _ O
clear -X- _ O
advantage. -X- _ O

However, -X- _ O
no -X- _ O
previous -X- _ O
work -X- _ O
has -X- _ O
addressed -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
zero-shot -X- _ B-TaskName
NERC, -X- _ I-TaskName
which -X- _ O
additionally -X- _ O
requires -X- _ O
the -X- _ O
detection -X- _ O
of -X- _ O
which -X- _ O
tokens -X- _ O
make -X- _ O
up -X- _ O
an -X- _ O
entity -X- _ O
in -X- _ O
addition -X- _ O
to -X- _ O
its -X- _ O
type, -X- _ O
i.e. -X- _ B-TaskName
Named -X- _ I-TaskName
Entity -X- _ I-TaskName
Recognition -X- _ I-TaskName
(NER). -X- _ B-TaskName

This -X- _ O
paper -X- _ O
explores -X- _ O
a -X- _ O
novel -X- _ O
architecture -X- _ O
for -X- _ O
making -X- _ O
use -X- _ O
of -X- _ O
such -X- _ O
information -X- _ O
from -X- _ O
knowledge -X- _ O
bases -X- _ O
by -X- _ O
tying -X- _ O
a -X- _ B-TaskName
coreference -X- _ I-TaskName
resolution -X- _ I-TaskName
system -X- _ O
to -X- _ O
a -X- _ B-TaskName
relation -X- _ I-TaskName
extraction -X- _ I-TaskName
system, -X- _ O
enabling -X- _ O
us -X- _ O
to -X- _ O
reward -X- _ O
the -X- _ O
coreference -X- _ O
system -X- _ O
for -X- _ O
making -X- _ O
predictions -X- _ O
that -X- _ O
lead -X- _ O
us -X- _ O
to -X- _ O
infer -X- _ O
facts -X- _ O
that -X- _ O
are -X- _ O
consistent -X- _ O
with -X- _ O
such -X- _ O
knowledge -X- _ O
bases. -X- _ O

In -X- _ O
this -X- _ O
paper, -X- _ O
we -X- _ O
provide -X- _ O
a -X- _ O
bilingual -X- _ O
parallel -X- _ O
human-to-human -X- _ O
recommendation -X- _ O
dialog -X- _ O
dataset -X- _ O
(DuRecDial -X- _ B-DatasetName
2.0) -X- _ I-DatasetName
to -X- _ O
enable -X- _ O
researchers -X- _ O
to -X- _ O
explore -X- _ O
a -X- _ O
challenging -X- _ O
task -X- _ O
of -X- _ O
multilingual -X- _ B-TaskName
and -X- _ I-TaskName
cross-lingual -X- _ I-TaskName
conversational -X- _ I-TaskName
recommendation. -X- _ I-TaskName

For -X- _ B-DatasetName
SciERC, -X- _ I-DatasetName
we -X- _ O
use -X- _ O
the -X- _ O
indomain -X- _ O
scibert-scivocab-uncased -X- _ B-MethodName
(Beltagy -X- _ O
et -X- _ O
al, -X- _ O
2019) -X- _ O
encoder. -X- _ O

In -X- _ O
each -X- _ O
iteration, -X- _ O
we -X- _ O
train -X- _ O
the -X- _ O
semantic -X- _ O
parser -X- _ O
for -X- _ O
30 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
with -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
64. -X- _ B-HyperparameterValue

Precision@1 -X- _ B-MetricName
rises -X- _ O
from -X- _ O
11.5% -X- _ B-MetricValue
(XLMR+SAP -X- _ B-MethodName
en -X- _ I-MethodName
syn -X- _ I-MethodName
) -X- _ O
to -X- _ O
30.9% -X- _ B-MetricValue
↑19.4% -X- _ B-MetricValue
(XLMR+SAP -X- _ B-MethodName
all -X- _ I-MethodName
syn -X- _ I-MethodName
(+en-th -X- _ I-MethodName
wt+ -X- _ I-MethodName
muse)), -X- _ I-MethodName
achieved -X- _ O
through -X- _ O
the -X- _ O
synergistic -X- _ O
effect -X- _ O
of -X- _ O
both -X- _ O
knowledge -X- _ O
types: -X- _ O
1) -X- _ O
UMLS -X- _ B-TaskName
synonyms -X- _ I-TaskName
in -X- _ O
other -X- _ O
languages -X- _ O
push -X- _ O
the -X- _ O
scores -X- _ O
to -X- _ O
20.6% -X- _ B-MetricValue
↑9.1% -X- _ B-MetricValue
; -X- _ O
2) -X- _ O
translation -X- _ B-TaskName
knowledge -X- _ I-TaskName
increases -X- _ O
it -X- _ O
further -X- _ O
to -X- _ O
30.9% -X- _ B-MetricValue
↑10.3% -X- _ B-MetricValue
. -X- _ O

MASS -X- _ B-MethodName
has -X- _ O
achieved -X- _ O
significant -X- _ O
improvements -X- _ O
in -X- _ O
several -X- _ O
sequence-to-sequence -X- _ O
tasks, -X- _ O
such -X- _ O
as -X- _ O
neural -X- _ B-TaskName
machine -X- _ I-TaskName
translation -X- _ I-TaskName
and -X- _ B-TaskName
text -X- _ I-TaskName
summarization -X- _ I-TaskName
(Song -X- _ O
et -X- _ O
al, -X- _ O
2019). -X- _ O

We -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
original -X- _ O
Who's -X- _ B-DatasetName
Waldo -X- _ I-DatasetName
dataset -X- _ O
compiled -X- _ O
for -X- _ O
this -X- _ O
task -X- _ O
contains -X- _ O
a -X- _ O
large -X- _ O
number -X- _ O
of -X- _ O
biased -X- _ O
samples -X- _ O
that -X- _ O
are -X- _ O
solvable -X- _ O
simply -X- _ O
by -X- _ O
heuristic -X- _ O
methods; -X- _ O
for -X- _ O
instance, -X- _ O
in -X- _ O
many -X- _ O
cases -X- _ O
the -X- _ O
first -X- _ O
name -X- _ O
in -X- _ O
the -X- _ O
sentence -X- _ O
corresponds -X- _ O
to -X- _ O
the -X- _ O
largest -X- _ O
bounding -X- _ O
box, -X- _ O
or -X- _ O
the -X- _ O
sequence -X- _ O
of -X- _ O
names -X- _ O
in -X- _ O
the -X- _ O
sentence -X- _ O
corresponds -X- _ O
to -X- _ O
an -X- _ O
exact -X- _ O
left-to-right -X- _ O
order -X- _ O
in -X- _ O
the -X- _ O
image. -X- _ O

In -X- _ O
this -X- _ O
paper, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
model -X- _ O
of -X- _ O
Breadth -X- _ B-MethodName
First -X- _ I-MethodName
Reasoning -X- _ I-MethodName
Graph -X- _ I-MethodName
(BFR-Graph), -X- _ B-MethodName
which -X- _ O
presents -X- _ O
a -X- _ O
new -X- _ O
message -X- _ O
passing -X- _ O
way -X- _ O
that -X- _ O
better -X- _ O
conforms -X- _ O
to -X- _ O
the -X- _ O
reasoning -X- _ O
process. -X- _ O

We -X- _ O
cluster -X- _ O
100 -X- _ B-HyperparameterValue
bounding -X- _ B-HyperparameterName
boxes -X- _ I-HyperparameterName
into -X- _ O
32 -X- _ B-HyperparameterValue
clusters, -X- _ B-HyperparameterName
and -X- _ O
32 -X- _ B-HyperparameterValue
cluster -X- _ B-HyperparameterName
centers -X- _ I-HyperparameterName
are -X- _ O
the -X- _ O
input -X- _ O
of -X- _ O
the -X- _ O
image -X- _ O
encoder. -X- _ O

We -X- _ O
use -X- _ O
a -X- _ O
pre-processed -X- _ O
version -X- _ O
of -X- _ O
the -X- _ B-DatasetName
GAD -X- _ I-DatasetName
dataset -X- _ O
provided -X- _ O
by -X- _ O
BioBERT, -X- _ B-MethodName
which -X- _ O
is -X- _ O
split -X- _ O
for -X- _ O
10-fold -X- _ O
cross-validation. -X- _ O

For -X- _ O
NER, -X- _ B-TaskName
we -X- _ O
observe -X- _ O
improvements -X- _ O
over -X- _ O
monolingual -X- _ O
models -X- _ O
with -X- _ O
0.62% -X- _ B-MetricValue
and -X- _ O
0.26% -X- _ B-MetricValue
absolute -X- _ O
micro -X- _ B-MetricName
F1 -X- _ I-MetricName
score -X- _ O
improvement -X- _ O
for -X- _ O
French -X- _ O
and -X- _ O
German, -X- _ O
respectively. -X- _ O

First, -X- _ O
we -X- _ O
can -X- _ O
observe -X- _ O
that -X- _ O
query -X- _ B-MetricName
match -X- _ I-MetricName
accuracy -X- _ I-MetricName
on -X- _ O
test -X- _ O
data -X- _ O
can -X- _ O
be -X- _ O
improved -X- _ O
by -X- _ O
6.4% -X- _ B-MetricValue
at -X- _ O
most -X- _ O
and -X- _ O
1.1% -X- _ B-MetricValue
at -X- _ O
least. -X- _ O

For -X- _ O
Triframes -X- _ O
(Ustalov -X- _ O
et -X- _ O
al, -X- _ O
2018), -X- _ O
we -X- _ O
use -X- _ O
its -X- _ O
authors' -X- _ O
original -X- _ O
implementation -X- _ O
18 -X- _ O
, -X- _ O
and -X- _ O
tune -X- _ O
the -X- _ O
parameter -X- _ O
k -X- _ B-HyperparameterName
in -X- _ O
the -X- _ O
k-NN -X- _ B-MethodName
graph -X- _ O
construction -X- _ O
step -X- _ O
for -X- _ O
different -X- _ O
tasks -X- _ O
and -X- _ O
datasets -X- _ O
to -X- _ O
get -X- _ O
a -X- _ O
reasonable -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
clusters. -X- _ I-HyperparameterName

Particularly, -X- _ O
our -X- _ O
ranker -X- _ O
outperforms -X- _ O
the -X- _ O
conventional -X- _ O
dialog -X- _ O
perplexity -X- _ B-MetricName
baseline -X- _ O
with -X- _ O
a -X- _ O
large -X- _ O
margin -X- _ O
on -X- _ O
predicting -X- _ O
Reddit -X- _ O
feedback. -X- _ O

Back-translation -X- _ B-MethodName
(BT; -X- _ O
Bojar -X- _ O
and -X- _ O
Tamchyna -X- _ O
2011;Sennrich -X- _ O
et -X- _ O
al -X- _ O
2016a;Poncelas -X- _ O
et -X- _ O
al -X- _ O
2018a) -X- _ O
is -X- _ O
a -X- _ B-TaskName
data -X- _ I-TaskName
augmentation -X- _ I-TaskName
method -X- _ O
that -X- _ O
is -X- _ O
a -X- _ O
key -X- _ O
ingredient -X- _ O
for -X- _ O
improving -X- _ O
translation -X- _ O
quality -X- _ O
of -X- _ O
neural -X- _ B-TaskName
machine -X- _ I-TaskName
translation -X- _ I-TaskName
systems -X- _ O
(NMT; -X- _ B-TaskName
Sutskever -X- _ O
et -X- _ O
al -X- _ O
2014;Bahdanau -X- _ O
et -X- _ O
al -X- _ O
2015;Gehring -X- _ O
et -X- _ O
al -X- _ O
2017;Vaswani -X- _ O
et -X- _ O
al -X- _ O
2017). -X- _ O

As -X- _ O
an -X- _ O
example, -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
unique -X- _ O
program -X- _ O
templates -X- _ O
in -X- _ O
D -X- _ O
par -X- _ O
when -X- _ O
K -X- _ B-HyperparameterName
= -X- _ O
2, -X- _ B-HyperparameterValue
000 -X- _ I-HyperparameterValue
on -X- _ O
SCHOLAR -X- _ B-DatasetName
and -X- _ O
GEO -X- _ B-DatasetName
is -X- _ O
1.9K -X- _ O
and -X- _ O
1.7K, -X- _ O
resp, -X- _ O
compared -X- _ O
to -X- _ O
only -X- _ O
125 -X- _ O
and -X- _ O
187 -X- _ O
in -X- _ O
D -X- _ O
nat -X- _ O
. -X- _ O

To -X- _ O
construct -X- _ O
the -X- _ O
provenance -X- _ O
graph, -X- _ O
it -X- _ O
is -X- _ O
obvious -X- _ O
that -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
(1) -X- _ O
obtain -X- _ O
the -X- _ O
sources -X- _ O
that -X- _ O
describe -X- _ O
the -X- _ O
statements -X- _ O
about -X- _ O
the -X- _ O
claim, -X- _ O
i.e., -X- _ O
S -X- _ O
D -X- _ O
(q); -X- _ O
(2) -X- _ O
infer -X- _ O
the -X- _ O
relationship -X- _ O
between -X- _ O
the -X- _ O
sources -X- _ O
and -X- _ O
the -X- _ O
statements, -X- _ O
i.e., -X- _ O
determine -X- _ O
the -X- _ O
labeled -X- _ O
edges -X- _ O
of -X- _ O
the -X- _ O
provenance -X- _ O
graph. -X- _ O

Evaluation -X- _ O
Metric -X- _ O
For -X- _ O
the -X- _ O
perplexity -X- _ B-MetricName
metric -X- _ O
to -X- _ O
evaluate -X- _ O
language -X- _ O
gaps, -X- _ O
we -X- _ O
fine-tune -X- _ O
a -X- _ O
GPT-2 -X- _ B-MethodName
language -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
paraphrased -X- _ O
canonical -X- _ O
data -X- _ O
D -X- _ O
par -X- _ O
for -X- _ O
1, -X- _ B-HyperparameterValue
500 -X- _ I-HyperparameterValue
steps -X- _ B-HyperparameterName
(150 -X- _ B-HyperparameterValue
steps -X- _ B-HyperparameterName
for -X- _ O
warm-up) -X- _ O
with -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
64 -X- _ B-HyperparameterValue
and -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
1e -X- _ B-HyperparameterValue
− -X- _ I-HyperparameterValue
5. -X- _ I-HyperparameterValue

In -X- _ O
order -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
claims -X- _ O
and -X- _ O
labels, -X- _ O
three -X- _ O
native -X- _ O
English -X- _ O
speakers -X- _ O
were -X- _ O
given -X- _ O
300 -X- _ B-HyperparameterValue
random -X- _ O
samples -X- _ O
from -X- _ O
FAVIQ, -X- _ B-DatasetName
and -X- _ O
were -X- _ O
asked -X- _ O
to: -X- _ O
(1) -X- _ O
verify -X- _ O
whether -X- _ O
the -X- _ O
claim -X- _ O
is -X- _ O
as -X- _ O
natural -X- _ B-MetricName
as -X- _ O
a -X- _ O
human-written -X- _ O
claim, -X- _ O
with -X- _ O
three -X- _ O
possible -X- _ O
ratings -X- _ O
(perfect, -X- _ O
minor -X- _ O
issues -X- _ O
but -X- _ O
comprehensible, -X- _ O
incomprehensible), -X- _ O
and -X- _ O
(2) -X- _ O
predict -X- _ O
the -X- _ O
label -X- _ O
of -X- _ O
the -X- _ O
claim -X- _ O
(support -X- _ O
or -X- _ O
refute). -X- _ O

Prior -X- _ O
work -X- _ O
has -X- _ O
already -X- _ O
used -X- _ O
computational -X- _ O
methods -X- _ O
to -X- _ O
predict -X- _ O
symptom -X- _ O
severity -X- _ O
(Howes -X- _ O
et -X- _ O
al, -X- _ O
2014), -X- _ O
measure -X- _ O
counseling -X- _ O
quality -X- _ O
(Pérez-Rosas -X- _ O
et -X- _ O
al, -X- _ O
2018, -X- _ O
and -X- _ O
used -X- _ O
topic -X- _ O
models -X- _ O
to -X- _ O
support -X- _ O
counselors -X- _ O
during -X- _ O
conversations -X- _ O
(Dinakar -X- _ O
et -X- _ O
al, -X- _ O
2015). -X- _ O

We -X- _ O
tuned -X- _ O
this -X- _ O
parameter -X- _ O
on -X- _ O
the -X- _ O
dev -X- _ O
set -X- _ O
of -X- _ O
the -X- _ O
Arguments -X- _ O
dataset, -X- _ O
and -X- _ O
selected -X- _ O
the -X- _ O
threshold -X- _ O
that -X- _ O
maximized -X- _ O
the -X- _ O
F1, -X- _ B-MetricValue
using -X- _ O
the -X- _ O
BM+TH -X- _ B-MethodName
selection -X- _ O
policy. -X- _ O

The -X- _ O
encoder -X- _ O
is -X- _ O
a -X- _ O
linear -X- _ O
map -X- _ O
to -X- _ O
R -X- _ B-HyperparameterName
512 -X- _ B-HyperparameterValue
with -X- _ O
ReLU -X- _ O
activations, -X- _ O
and -X- _ O
the -X- _ O
decoder -X- _ O
is -X- _ O
a -X- _ O
linear -X- _ O
map -X- _ O
back -X- _ O
to -X- _ O
R -X- _ B-HyperparameterName
90,000 -X- _ B-HyperparameterValue
space -X- _ O
with -X- _ O
pointwise -X- _ O
squaring. -X- _ O

Finally -X- _ O
we -X- _ O
provide -X- _ O
a -X- _ O
qualitative -X- _ O
analysis -X- _ O
which -X- _ O
sheds -X- _ O
light -X- _ O
on -X- _ O
the -X- _ O
suitability -X- _ O
of -X- _ O
AMR -X- _ O
across -X- _ O
languages. -X- _ O

However, -X- _ O
such -X- _ O
approaches -X- _ O
still -X- _ O
require -X- _ O
external -X- _ O
ZP -X- _ O
prediction -X- _ O
models, -X- _ O
which -X- _ O
have -X- _ O
a -X- _ O
low -X- _ O
accuracy -X- _ B-MetricName
of -X- _ O
66%. -X- _ B-MetricValue

As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2, -X- _ O
META -X- _ B-MethodName
is -X- _ O
an -X- _ O
iterative -X- _ O
framework, -X- _ O
generating -X- _ O
pseudo -X- _ O
labels -X- _ O
and -X- _ O
training -X- _ O
the -X- _ O
text -X- _ O
classifier -X- _ O
alternatively, -X- _ O
similar -X- _ O
to -X- _ O
many -X- _ O
other -X- _ O
weakly -X- _ O
supervised -X- _ B-TaskName
text -X- _ I-TaskName
classification -X- _ I-TaskName
methods -X- _ O
(Kuipers -X- _ O
et -X- _ O
al, -X- _ O
2006;Tao -X- _ O
et -X- _ O
al, -X- _ O
2015;. -X- _ O
One -X- _ O
iteration -X- _ O
in -X- _ O
META -X- _ B-MethodName
consists -X- _ O
of -X- _ O
the -X- _ O
following -X- _ O
steps: -X- _ O
• -X- _ O
Generate -X- _ O
pseudo -X- _ O
labels -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
seeds; -X- _ O
• -X- _ O
Train -X- _ O
a -X- _ O
text -X- _ O
classifier -X- _ O
based -X- _ O
on -X- _ O
pseudo -X- _ O
labels; -X- _ O
• -X- _ O
Rank -X- _ O
and -X- _ O
select -X- _ O
words -X- _ O
and -X- _ O
motif -X- _ O
instances -X- _ O
to -X- _ O
expand -X- _ O
the -X- _ O
seeds. -X- _ O

The -X- _ O
zero-shot -X- _ O
performance -X- _ O
is -X- _ O
barely -X- _ O
better -X- _ O
than -X- _ O
random -X- _ O
guessing, -X- _ O
indicating -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
trained -X- _ O
on -X- _ B-DatasetName
FEVER -X- _ I-DatasetName
is -X- _ O
not -X- _ O
able -X- _ O
to -X- _ O
generalize -X- _ O
to -X- _ O
our -X- _ O
more -X- _ O
challenging -X- _ O
data. -X- _ O

For -X- _ O
different -X- _ O
candidate -X- _ B-HyperparameterName
database -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
(from -X- _ O
one -X- _ O
million -X- _ O
to -X- _ O
ten -X- _ O
million), -X- _ O
we -X- _ O
compare -X- _ O
the -X- _ O
Coverage@500 -X- _ B-MetricName
metric -X- _ O
of -X- _ O
BM25-QS, -X- _ B-MetricName
BE-QS, -X- _ B-MetricName
and -X- _ O
CFC-QS -X- _ B-MetricName
on -X- _ O
the -X- _ O
MC -X- _ B-DatasetName
test -X- _ I-DatasetName
set -X- _ I-DatasetName
of -X- _ I-DatasetName
Reddit -X- _ I-DatasetName
(Figure -X- _ O
3). -X- _ O

We -X- _ O
propose -X- _ O
specifying -X- _ O
instead -X- _ O
a -X- _ O
parameter -X- _ O
β -X- _ B-HyperparameterName
skip -X- _ O
which -X- _ O
defines -X- _ O
the -X- _ O
skip -X- _ B-HyperparameterName
cost -X- _ I-HyperparameterName
in -X- _ O
terms -X- _ O
of -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
1-1 -X- _ O
alignment -X- _ O
costs -X- _ O
at -X- _ O
alignment -X- _ O
time: -X- _ O
c -X- _ O
skip -X- _ O
= -X- _ O
CDF -X- _ O
−1 -X- _ O
(β -X- _ O
skip -X- _ O
). -X- _ O

The -X- _ O
relatively -X- _ O
low -X- _ O
SuccF1 -X- _ B-MetricName
is -X- _ O
due -X- _ O
to -X- _ O
that -X- _ O
in -X- _ O
LABES-S2S, -X- _ B-MethodName
we -X- _ O
do -X- _ O
not -X- _ O
apply -X- _ O
additional -X- _ O
dialog -X- _ O
act -X- _ O
modeling -X- _ O
and -X- _ O
reinforcement -X- _ O
fine-tuning -X- _ O
to -X- _ O
encourage -X- _ O
slot -X- _ O
token -X- _ O
generation -X- _ O
as -X- _ O
in -X- _ O
other -X- _ O
E2E -X- _ O
models. -X- _ O

Our -X- _ O
pre-training -X- _ O
procedure -X- _ O
is -X- _ O
efficient -X- _ O
and -X- _ O
outperforms -X- _ O
BERT-based -X- _ O
models -X- _ O
with -X- _ O
at -X- _ O
least -X- _ O
0.09, -X- _ B-MetricValue
0.16, -X- _ B-MetricValue
0.35 -X- _ B-MetricValue
absolute -X- _ O
increase -X- _ O
in -X- _ O
F1 -X- _ B-MetricName
(exact -X- _ O
match) -X- _ O
for -X- _ O
the -X- _ O
three -X- _ O
datasets. -X- _ O

Among -X- _ O
the -X- _ O
57.96% -X- _ O
cases -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
exactly -X- _ O
match -X- _ O
ground -X- _ O
truth -X- _ O
utterances, -X- _ O
only -X- _ O
6.3% -X- _ O
are -X- _ O
not -X- _ O
complete, -X- _ O
which -X- _ O
still -X- _ O
contains -X- _ O
unresolved -X- _ O
el-lipsis -X- _ O
or -X- _ O
co-reference, -X- _ O
while -X- _ O
93.7% -X- _ O
of -X- _ O
these -X- _ O
cases -X- _ O
are -X- _ O
complete -X- _ O
with -X- _ O
GECOR-generated -X- _ B-MethodName
words -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
match -X- _ O
ground -X- _ O
truth -X- _ O
words. -X- _ O

We -X- _ O
build -X- _ O
SentiBERT -X- _ B-MethodName
on -X- _ O
the -X- _ O
HuggingFace -X- _ O
library -X- _ O
1 -X- _ O
and -X- _ O
initialize -X- _ O
the -X- _ O
model -X- _ O
parameters -X- _ O
using -X- _ O
pre-trained -X- _ O
BERT-base -X- _ B-MethodName
and -X- _ O
RoBERTa-base -X- _ B-MethodName
models -X- _ O
whose -X- _ O
maximum -X- _ B-HyperparameterName
length -X- _ I-HyperparameterName
is -X- _ O
128, -X- _ B-HyperparameterValue
layer -X- _ B-HyperparameterName
number -X- _ I-HyperparameterName
is -X- _ O
12, -X- _ B-HyperparameterValue
and -X- _ O
embedding -X- _ B-HyperparameterName
dimension -X- _ I-HyperparameterName
is -X- _ O
768. -X- _ B-HyperparameterValue

We -X- _ O
tuned -X- _ O
confidence -X- _ B-HyperparameterName
thresholds -X- _ I-HyperparameterName
on -X- _ O
WMT18 -X- _ B-DatasetName
Metrics -X- _ O
task -X- _ O
data -X- _ O
using -X- _ O
a -X- _ O
grid -X- _ O
of -X- _ O
16 -X- _ B-MetricValue
log-probability -X- _ O
points -X- _ O
in -X- _ O
[−3, -X- _ B-MetricValue
0], -X- _ B-MetricValue
which -X- _ O
yielded -X- _ O
optimal -X- _ O
thresholds -X- _ O
(−1, -X- _ B-MetricValue
−0.6). -X- _ B-MetricValue

We -X- _ O
set -X- _ O
the -X- _ O
margin -X- _ B-HyperparameterName
m -X- _ I-HyperparameterName
as -X- _ O
0.2 -X- _ B-HyperparameterValue
for -X- _ O
fast -X- _ O
model -X- _ O
and -X- _ O
0.6 -X- _ B-HyperparameterValue
for -X- _ O
base -X- _ O
and -X- _ O
inflated -X- _ O
models. -X- _ O

The -X- _ O
other -X- _ O
standard -X- _ O
baseline -X- _ O
for -X- _ O
domain -X- _ B-TaskName
adaptation -X- _ I-TaskName
(PoolDomain) -X- _ B-DatasetName
obtains -X- _ O
a -X- _ O
similar -X- _ O
performance -X- _ O
(−2.19 -X- _ B-MetricValue
compared -X- _ O
to -X- _ O
our -X- _ O
method) -X- _ O
to -X- _ O
the -X- _ O
in-domain -X- _ O
approach, -X- _ O
which -X- _ O
shows -X- _ O
the -X- _ O
benefits -X- _ O
of -X- _ O
multidomain -X- _ B-TaskName
adaptation. -X- _ I-TaskName

The -X- _ O
embedding -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
d -X- _ O
is -X- _ O
set -X- _ O
to -X- _ O
100 -X- _ B-HyperparameterValue
and -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
negative -X- _ I-HyperparameterName
samples -X- _ I-HyperparameterName
is -X- _ O
fixed -X- _ O
to -X- _ O
50. -X- _ B-HyperparameterValue

The -X- _ O
task -X- _ O
of -X- _ O
Difficulty-Controllable -X- _ B-TaskName
Question -X- _ I-TaskName
Generation -X- _ I-TaskName
(DCQG) -X- _ B-TaskName
aims -X- _ O
at -X- _ O
generating -X- _ O
questions -X- _ O
with -X- _ O
required -X- _ O
difficulty -X- _ O
levels -X- _ O
and -X- _ O
has -X- _ O
recently -X- _ O
attracted -X- _ O
researchers' -X- _ O
attention -X- _ O
due -X- _ O
to -X- _ O
its -X- _ O
wide -X- _ O
application, -X- _ O
such -X- _ O
as -X- _ O
facilitating -X- _ O
certain -X- _ O
curriculum-learningbased -X- _ O
methods -X- _ O
for -X- _ O
QA -X- _ O
systems -X- _ O
(Sachan -X- _ O
and -X- _ O
Xing, -X- _ O
2016) -X- _ O
and -X- _ O
designing -X- _ O
exams -X- _ O
of -X- _ O
various -X- _ O
difficulty -X- _ O
levels -X- _ O
for -X- _ O
educational -X- _ O
purpose -X- _ O
(Kurdi -X- _ O
et -X- _ O
al, -X- _ O
2020). -X- _ O

We -X- _ O
present -X- _ O
results -X- _ O
for -X- _ O
masking -X- _ O
BERT, -X- _ B-MethodName
RoBERTa, -X- _ B-MethodName
and -X- _ O
DistilBERT -X- _ B-MethodName
in -X- _ O
part-of-speech -X- _ B-TaskName
tagging, -X- _ I-TaskName
named-entity -X- _ B-TaskName
recognition, -X- _ I-TaskName
sequence -X- _ B-TaskName
classification, -X- _ I-TaskName
and -X- _ O
reading -X- _ B-TaskName
comprehension. -X- _ I-TaskName

We -X- _ O
intentionally -X- _ O
sabotage -X- _ O
low-capacity -X- _ O
LSTM -X- _ B-MethodName
models -X- _ O
by -X- _ O
only -X- _ O
training -X- _ O
them -X- _ O
using -X- _ O
25% -X- _ B-HyperparameterValue
of -X- _ O
the -X- _ O
seed -X- _ O
data -X- _ O
to -X- _ O
generate -X- _ O
synthetic -X- _ O
responses. -X- _ O

KBP -X- _ B-MethodName
(Ling -X- _ O
and -X- _ O
Weld, -X- _ O
2012) -X- _ O
uses -X- _ O
Wikipedia -X- _ O
articles -X- _ O
annotated -X- _ O
with -X- _ O
Freebase -X- _ O
entries -X- _ O
as -X- _ O
the -X- _ O
training -X- _ O
set, -X- _ O
and -X- _ O
employs -X- _ O
manually-annotated -X- _ O
sentences -X- _ O
from -X- _ O
2013 -X- _ O
KBP -X- _ O
slot -X- _ O
filling -X- _ O
assessment -X- _ O
results -X- _ O
(Ellis -X- _ O
et -X- _ O
al, -X- _ O
2012) -X- _ O
as -X- _ O
the -X- _ O
extra -X- _ O
test -X- _ O
set. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
we -X- _ O
take -X- _ O
a -X- _ O
deeper -X- _ O
look -X- _ O
at -X- _ O
the -X- _ O
efficacy -X- _ O
of -X- _ O
strong -X- _ O
few-shot -X- _ O
classification -X- _ O
models -X- _ O
in -X- _ O
the -X- _ O
more -X- _ O
common -X- _ B-TaskName
relation -X- _ I-TaskName
extraction -X- _ I-TaskName
setting, -X- _ O
and -X- _ O
show -X- _ O
that -X- _ O
typical -X- _ O
few-shot -X- _ O
evaluation -X- _ O
metrics -X- _ O
obscure -X- _ O
a -X- _ O
wide -X- _ O
variability -X- _ O
in -X- _ O
performance -X- _ O
across -X- _ O
relations. -X- _ O

EReader -X- _ B-MethodName
consistently -X- _ O
achieves -X- _ O
higher -X- _ O
performance -X- _ O
using -X- _ O
the -X- _ O
knowledge -X- _ O
retrieved -X- _ O
from -X- _ O
complete -X- _ O
corpus, -X- _ O
where -X- _ O
the -X- _ O
biggest -X- _ O
gain -X- _ O
of -X- _ O
7.86% -X- _ B-MetricValue
is -X- _ O
achieved -X- _ O
when -X- _ O
using -X- _ O
five -X- _ O
knowledge. -X- _ O

Key -X- _ B-TaskName
information -X- _ I-TaskName
extraction -X- _ I-TaskName
from -X- _ O
form-like -X- _ O
documents -X- _ O
is -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
fundamental -X- _ O
tasks -X- _ O
of -X- _ O
document -X- _ B-TaskName
understanding -X- _ I-TaskName
that -X- _ O
has -X- _ O
many -X- _ O
real-world -X- _ O
applications. -X- _ O

We -X- _ O
initialize -X- _ O
our -X- _ O
context-aware -X- _ B-MethodName
ST -X- _ I-MethodName
with -X- _ O
the -X- _ O
sentence-level -X- _ O
Baseline, -X- _ O
i.e. -X- _ O
ST+AFS, -X- _ B-MethodName
and -X- _ O
then -X- _ O
finetune -X- _ O
the -X- _ O
model -X- _ O
for -X- _ O
20K -X- _ B-HyperparameterValue
steps -X- _ B-HyperparameterName
based -X- _ O
on -X- _ O
the -X- _ O
concatenation -X- _ O
method -X- _ O
with -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
around -X- _ O
40K -X- _ B-HyperparameterValue
subwords. -X- _ O

We -X- _ O
attribute -X- _ O
LCAMs -X- _ B-MethodName
superior -X- _ O
performance -X- _ O
to -X- _ O
(1) -X- _ O
Using -X- _ O
a -X- _ O
domain-specific -X- _ O
(biomedical) -X- _ O
language -X- _ O
representation -X- _ O
model -X- _ O
(BioBERT) -X- _ B-MethodName
at -X- _ O
its -X- _ O
encoding -X- _ O
layer, -X- _ O
(2) -X- _ O
Applying -X- _ O
label-specific -X- _ O
attention -X- _ O
prior -X- _ O
to -X- _ O
classifying -X- _ O
a -X- _ O
token -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
before -X- _ O
classifying -X- _ O
the -X- _ O
mean -X- _ O
pooled -X- _ O
representation -X- _ O
of -X- _ O
an -X- _ O
Example -X- _ O
Input -X- _ O
sentence -X- _ O
Predicted -X- _ O
labels -X- _ O
Predicted -X- _ O
labels -X- _ O
P@1 -X- _ O
P@2 -X- _ O

For -X- _ O
IEMOCAP, -X- _ B-DatasetName
our -X- _ O
model -X- _ O
obtained -X- _ O
a -X- _ O
weighted -X- _ B-MetricName
average -X- _ I-MetricName
F1 -X- _ I-MetricName
score -X- _ O
of -X- _ O
65.22%, -X- _ B-MetricValue
outperforming -X- _ O
Di-alogueGCN -X- _ B-MethodName
by -X- _ O
more -X- _ O
than -X- _ O
1 -X- _ B-MetricValue
point. -X- _ I-MetricValue

Given -X- _ O
that -X- _ O
BERT -X- _ B-MethodName
remains -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
most -X- _ O
effective -X- _ O
models -X- _ O
in -X- _ O
varieties -X- _ O
of -X- _ O
NLP -X- _ O
tasks, -X- _ O
and -X- _ O
especially -X- _ O
that -X- _ O
handcrafted -X- _ B-MethodName
features -X- _ I-MethodName
have -X- _ O
relatively -X- _ O
low -X- _ O
dimensionality -X- _ O
compared -X- _ O
to -X- _ O
BERT, -X- _ B-MethodName
we -X- _ O
believe -X- _ O
that -X- _ O
the -X- _ O
performance -X- _ O
gain -X- _ O
equivalent -X- _ O
to -X- _ O
20% -X- _ B-MetricValue
of -X- _ O
the -X- _ O
performance -X- _ O
gain -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
is -X- _ O
substantial -X- _ O
for -X- _ O
this -X- _ O
completely -X- _ O
new -X- _ O
application -X- _ O
domain. -X- _ O

More -X- _ O
recently, -X- _ O
it -X- _ O
has -X- _ O
been -X- _ O
successfully -X- _ O
used -X- _ O
to -X- _ O
reduce -X- _ O
partial -X- _ O
input -X- _ O
biases -X- _ O
in -X- _ O
different -X- _ O
fields -X- _ O
of -X- _ O
NLP, -X- _ O
such -X- _ O
as -X- _ B-TaskName
natural -X- _ I-TaskName
language -X- _ I-TaskName
inference -X- _ I-TaskName
(NLI) -X- _ B-TaskName
(Belinkov -X- _ O
et -X- _ O
al, -X- _ O
2019;Stacey -X- _ O
et -X- _ O
al, -X- _ O
2020) -X- _ O
and -X- _ O
visual -X- _ B-TaskName
question -X- _ I-TaskName
answering -X- _ I-TaskName
(VQA) -X- _ B-TaskName
(Ramakrishnan -X- _ O
et -X- _ O
al, -X- _ O
2018). -X- _ O

Held-Out -X- _ O
Performance -X- _ O
Micro/macro -X- _ B-MetricName
F1 -X- _ I-MetricName
scores -X- _ I-MetricName
on -X- _ O
the -X- _ O
held-out -X- _ O
test -X- _ O
sets -X- _ O
corresponding -X- _ O
to -X- _ O
their -X- _ O
training -X- _ O
data -X- _ O
are -X- _ O
91.5/70.8 -X- _ B-MetricValue
for -X- _ O
B-D -X- _ B-MethodName
and -X- _ O
92.9/70.3 -X- _ B-MetricValue
for -X- _ O
B-F -X- _ B-MethodName
(Founta -X- _ O
et -X- _ O
al, -X- _ O
2018). -X- _ O

The -X- _ O
size -X- _ O
of -X- _ B-DatasetName
S2ORC -X- _ I-DatasetName
makes -X- _ O
it -X- _ O
more -X- _ O
than -X- _ O
sufficient -X- _ O
for -X- _ O
pretraining -X- _ O
large -X- _ O
language -X- _ O
models -X- _ O
such -X- _ O
as -X- _ O
ELMO, -X- _ B-MethodName
BERT, -X- _ B-MethodName
ROBERTA, -X- _ B-MethodName
GPT2, -X- _ B-MethodName
and -X- _ O
others, -X- _ O
whose -X- _ O
reported -X- _ O
training -X- _ O
data -X- _ O
sizes -X- _ O
are -X- _ O
given -X- _ O
in -X- _ O
Table -X- _ O
9 -X- _ O
for -X- _ O
comparison. -X- _ O

More -X- _ O
closely -X- _ O
related -X- _ O
to -X- _ O
our -X- _ O
task -X- _ O
is -X- _ O
the -X- _ O
context -X- _ O
dependent -X- _ B-TaskName
semantic -X- _ I-TaskName
parsing -X- _ I-TaskName
task -X- _ O
on -X- _ O
the -X- _ B-DatasetName
ATIS -X- _ I-DatasetName
dataset -X- _ O
(Zettlemoyer -X- _ O
and -X- _ O
Collins, -X- _ O
2009;Suhr -X- _ O
et -X- _ O
al, -X- _ O
2018) -X- _ O
for -X- _ O
mapping -X- _ O
NL -X- _ O
to -X- _ O
database -X- _ O
queries -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
prior -X- _ O
history -X- _ O
of -X- _ O
NL -X- _ O
and -X- _ O
query -X- _ O
pairs. -X- _ O

We -X- _ O
further -X- _ O
trained -X- _ O
an -X- _ O
XLnet -X- _ B-MethodName
models -X- _ O
with -X- _ O
similar -X- _ O
training -X- _ O
hyperparameters -X- _ O
and -X- _ O
achieved -X- _ O
an -X- _ O
accuracy -X- _ B-MetricName
of -X- _ O
0.983. -X- _ B-MetricValue

Since -X- _ O
our -X- _ O
UmlsBERT -X- _ B-MethodName
model -X- _ O
is -X- _ O
focused -X- _ O
on -X- _ O
augmenting -X- _ O
the -X- _ O
Masked -X- _ B-TaskName
LM -X- _ I-TaskName
task -X- _ O
with -X- _ O
clinical -X- _ O
information -X- _ O
from -X- _ O
the -X- _ B-DatasetName
UMLS -X- _ I-DatasetName
Metathesaurus, -X- _ O
we -X- _ O
omit -X- _ O
the -X- _ O
description -X- _ O
of -X- _ O
the -X- _ O
Next -X- _ O
Sentence -X- _ O
Prediction -X- _ O
task -X- _ O
and -X- _ O
only -X- _ O
describe -X- _ O
the -X- _ O
details -X- _ O
of -X- _ O
the -X- _ O
Masked -X- _ O
LM -X- _ O
task -X- _ O
herein. -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
publicly-provided -X- _ O
train -X- _ O
and -X- _ O
test -X- _ O
splits -X- _ O
for -X- _ O
the -X- _ O
sst2 -X- _ B-DatasetName
and -X- _ O
20news -X- _ B-DatasetName
datasets -X- _ O
and -X- _ O
further -X- _ O
derive -X- _ O
a -X- _ O
validation -X- _ B-HyperparameterName
split -X- _ I-HyperparameterName
consisting -X- _ O
of -X- _ O
20% -X- _ B-HyperparameterValue
(v -X- _ B-HyperparameterName
= -X- _ O
0.2) -X- _ B-HyperparameterValue
of -X- _ O
the -X- _ O
train -X- _ O
split -X- _ O
(D -X- _ O
t -X- _ O
), -X- _ O
with -X- _ O
uniform -X- _ O
class -X- _ O
distribution. -X- _ O

Lastly, -X- _ O
to -X- _ O
better -X- _ O
understand -X- _ O
how -X- _ O
well -X- _ O
the -X- _ O
email -X- _ B-TaskName
thread -X- _ I-TaskName
summarization -X- _ I-TaskName
models -X- _ O
perform -X- _ O
and -X- _ O
investigate -X- _ O
the -X- _ O
correlation -X- _ O
between -X- _ O
automatic -X- _ O
metrics -X- _ O
and -X- _ O
human -X- _ O
judgment, -X- _ O
we -X- _ O
ask -X- _ O
humans -X- _ B-MethodName
to -X- _ O
rate -X- _ O
the -X- _ O
"salience" -X- _ B-MetricName
(how -X- _ O
well -X- _ O
the -X- _ O
model -X- _ O
summarizes -X- _ O
salient -X- _ O
points) -X- _ O
and -X- _ O
"faithfulness" -X- _ B-MetricName
(how -X- _ O
well -X- _ O
the -X- _ O
model -X- _ O
stays -X- _ O
true -X- _ O
to -X- _ O
the -X- _ O
email -X- _ O
thread) -X- _ O
of -X- _ O
model-generated -X- _ O
summaries, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
to -X- _ O
perform -X- _ O
a -X- _ O
pairwise -X- _ O
comparison -X- _ O
between -X- _ O
our -X- _ O
best -X- _ O
and -X- _ O
base -X- _ O
models. -X- _ O

Baselines. -X- _ O
(1) -X- _ O
Ebner's -X- _ B-MethodName
(Ebner -X- _ O
et -X- _ O
al, -X- _ O
2020) -X- _ O
is -X- _ O
a -X- _ O
semantic -X- _ O
role -X- _ O
labeling-based -X- _ O
method -X- _ O
with -X- _ O
greedy -X- _ O
decoding. -X- _ O
(2) -X- _ O
Zhang's -X- _ B-MethodName
(Zhang -X- _ O
et -X- _ O
al, -X- _ O
2020b) -X- _ O
is -X- _ O
a -X- _ O
two-step -X- _ O
head-based -X- _ O
model -X- _ O
that -X- _ O
first -X- _ O
predicts -X- _ O
headwords -X- _ O
of -X- _ O
an -X- _ O
argument -X- _ O
and -X- _ O
then -X- _ O
expands -X- _ O
to -X- _ O
the -X- _ O
full -X- _ O
span. -X- _ O

As -X- _ O
seen, -X- _ O
the -X- _ O
BLEU -X- _ B-MetricName
score -X- _ O
of -X- _ O
best -X- _ O
"External -X- _ O
ZP -X- _ O
prediction" -X- _ O
model -X- _ O
dramatically -X- _ O
drops -X- _ O
by -X- _ O
-1.06 -X- _ B-MetricValue
points, -X- _ O
showing -X- _ O
that -X- _ O
this -X- _ O
approach -X- _ O
is -X- _ O
heavily -X- _ O
dependent -X- _ O
on -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
external -X- _ O
ZP -X- _ O
annotations. -X- _ O

TARA -X- _ B-DatasetName
is -X- _ O
collected -X- _ O
via -X- _ O
a -X- _ O
rigorous -X- _ O
process -X- _ O
that -X- _ O
involves -X- _ O
rule-based -X- _ O
distant -X- _ O
supervision -X- _ O
extraction -X- _ O
from -X- _ O
news-images -X- _ O
data -X- _ O
which -X- _ O
results -X- _ O
in -X- _ O
16k -X- _ O
image -X- _ O
examples. -X- _ O

For -X- _ O
instance, -X- _ O
Reformer -X- _ B-MethodName
(Kitaev -X- _ O
et -X- _ O
al, -X- _ O
2020) -X- _ O
is -X- _ O
tested -X- _ O
on -X- _ O
the -X- _ O
64k-chunk -X- _ B-DatasetName
en-wik8 -X- _ I-DatasetName
dataset -X- _ O
for -X- _ O
unidirectional -X- _ O
language -X- _ O
modeling; -X- _ O
Performer -X- _ B-MethodName
(Choromanski -X- _ O
et -X- _ O
al, -X- _ O
2021) -X- _ O
reports -X- _ O
masked -X- _ B-MethodName
language -X- _ I-MethodName
modeling -X- _ I-MethodName
(MLM) -X- _ B-MethodName
perplexity -X- _ B-MetricName
on -X- _ O
the -X- _ O
PG-19 -X- _ B-DatasetName
book -X- _ I-DatasetName
corpus -X- _ O
and -X- _ O
protein -X- _ O
sequences; -X- _ O
Linformer -X- _ B-MethodName
reports -X- _ O
MLP -X- _ O
perplexity -X- _ B-MetricName
with -X- _ O
various -X- _ O
input -X- _ O
length, -X- _ O
while -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
documents -X- _ O
in -X- _ O
their -X- _ O
pretrain -X- _ O
corpus -X- _ O
are -X- _ O
short -X- _ O
documents. -X- _ O

Document -X- _ B-TaskName
summarization -X- _ I-TaskName
is -X- _ O
a -X- _ O
task -X- _ O
of -X- _ O
creating -X- _ O
a -X- _ O
concise -X- _ O
summary -X- _ O
from -X- _ O
a -X- _ O
given -X- _ O
document -X- _ O
while -X- _ O
keeping -X- _ O
the -X- _ O
original -X- _ O
content. -X- _ O

In -X- _ O
Case -X- _ O
3, -X- _ O
even -X- _ O
if -X- _ O
PinyinGPT-Concat -X- _ B-MethodName
ranks -X- _ O
the -X- _ O
ground -X- _ O
truth -X- _ O
as -X- _ O
the -X- _ O
second -X- _ O
best, -X- _ O
the -X- _ O
top -X- _ O
1 -X- _ O
prediction -X- _ O
still -X- _ O
makes -X- _ O
much -X- _ O
sense -X- _ O
and -X- _ O
fit -X- _ O
well -X- _ O
with -X- _ O
the -X- _ O
context. -X- _ O

The -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
is -X- _ O
5e-5 -X- _ B-HyperparameterValue
and -X- _ O
the -X- _ O
training -X- _ B-HyperparameterName
steps -X- _ I-HyperparameterName
are -X- _ O
5000 -X- _ B-HyperparameterValue
for -X- _ O
both -X- _ O
base -X- _ O
and -X- _ O
large -X- _ O
models. -X- _ O

For -X- _ O
the -X- _ O
second -X- _ O
approach, -X- _ O
instead, -X- _ O
i.e., -X- _ O
GOLDAMR-SILVERTRNS, -X- _ B-DatasetName
we -X- _ O
choose -X- _ O
AMR -X- _ B-DatasetName
2.0 -X- _ I-DatasetName
as -X- _ O
gold -X- _ O
dataset -X- _ O
and -X- _ O
translate -X- _ O
the -X- _ O
sentences -X- _ O
into -X- _ O
Chinese, -X- _ O
German, -X- _ O
Italian -X- _ O
and -X- _ O
Spanish. -X- _ O

On -X- _ O
OpenSQuAD -X- _ O
dataset, -X- _ O
our -X- _ O
DUREPA -X- _ B-MethodName
model -X- _ O
using -X- _ O
hybrid -X- _ O
evidences -X- _ O
achieves -X- _ O
a -X- _ O
new -X- _ O
state-ofthe-art -X- _ O
EM -X- _ B-MetricName
score -X- _ I-MetricName
of -X- _ O
57.0. -X- _ B-MetricValue

In -X- _ O
multilingual -X- _ O
settings, -X- _ O
we -X- _ O
tested -X- _ O
Babylon -X- _ B-MethodName
multilingual -X- _ I-MethodName
word -X- _ I-MethodName
embeddings -X- _ I-MethodName
and -X- _ O
MUSE -X- _ B-MethodName
(Lample -X- _ O
et -X- _ O
al, -X- _ O
2017) -X- _ O
on -X- _ O
the -X- _ O
different -X- _ O
tasks. -X- _ O

XQuAD -X- _ B-DatasetName
(Artetxe -X- _ O
et -X- _ O
al, -X- _ O
2020) -X- _ O
is -X- _ O
a -X- _ O
human -X- _ O
translation -X- _ O
of -X- _ O
the -X- _ B-DatasetName
SQuAD -X- _ I-DatasetName
en -X- _ O
development -X- _ O
set -X- _ O
in -X- _ O
10 -X- _ O
languages -X- _ O
(Arabic, -X- _ O
Chinese, -X- _ O
German, -X- _ O
Greek, -X- _ O
Hindi, -X- _ O
Russian, -X- _ O
Spanish, -X- _ O
Thai, -X- _ O
Turkish, -X- _ O
and -X- _ O
Vietnamese), -X- _ O
providing -X- _ O
1k -X- _ O
QA -X- _ O
pairs -X- _ O
for -X- _ O
each -X- _ O
language. -X- _ O

Figure -X- _ O
3 -X- _ O
shows -X- _ O
the -X- _ O
confusion -X- _ B-MetricName
matrices -X- _ I-MetricName
of -X- _ O
PDTB -X- _ B-MethodName
3.0 -X- _ I-MethodName
L2 -X- _ O
classification -X- _ O
predictions, -X- _ O
again -X- _ O
from -X- _ O
XLNet-large -X- _ B-MethodName
and -X- _ O
BERT-large -X- _ B-MethodName
models -X- _ O
(we -X- _ O
did -X- _ O
not -X- _ O
observe -X- _ O
immediate -X- _ O
qualitative -X- _ O
differences -X- _ O
between -X- _ O
XLNet -X- _ B-MethodName
and -X- _ O
BERT, -X- _ B-MethodName
or -X- _ O
between -X- _ O
large -X- _ O
and -X- _ O
base -X- _ O
models). -X- _ O

That -X- _ O
is, -X- _ O
EPT-X -X- _ B-MethodName
generates -X- _ O
different -X- _ O
solution -X- _ O
equations -X- _ O
when -X- _ O
it -X- _ O
only -X- _ O
receives -X- _ O
the -X- _ O
generated -X- _ O
explanation -X- _ O
as -X- _ O
input -X- _ O
in -X- _ O
Phase -X- _ O
2. -X- _ O

To -X- _ O
investigate -X- _ O
whether -X- _ O
language -X- _ O
generation -X- _ O
models -X- _ O
can -X- _ O
serve -X- _ O
as -X- _ O
behavioral -X- _ O
priors -X- _ O
for -X- _ O
systems -X- _ O
deployed -X- _ O
in -X- _ O
social -X- _ O
settings, -X- _ O
we -X- _ O
evaluate -X- _ O
their -X- _ O
ability -X- _ O
to -X- _ O
generate -X- _ O
action -X- _ O
descriptions -X- _ O
that -X- _ O
achieve -X- _ O
predefined -X- _ O
goals -X- _ O
under -X- _ O
normative -X- _ O
constraints. -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
3, -X- _ O
the -X- _ O
performance -X- _ O
gap -X- _ O
be- -X- _ O
tween -X- _ O
our -X- _ O
approach -X- _ O
and -X- _ O
the -X- _ O
baseline -X- _ O
goes -X- _ O
widest -X- _ O
for -X- _ O
AMR -X- _ O
graphs -X- _ O
with -X- _ O
more -X- _ O
than -X- _ O
5 -X- _ O
reentrancies, -X- _ O
on -X- _ O
which -X- _ O
our -X- _ O
approach -X- _ O
outperforms -X- _ O
the -X- _ O
baseline -X- _ O
by -X- _ O
6.61 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
scores. -X- _ O

We -X- _ O
also -X- _ O
evaluate -X- _ O
the -X- _ O
transfer -X- _ O
performance -X- _ O
of -X- _ O
multilingual -X- _ B-TaskName
sentence -X- _ I-TaskName
embeddings -X- _ I-TaskName
on -X- _ O
downstream -X- _ O
classification -X- _ O
tasks -X- _ O
from -X- _ O
the -X- _ B-DatasetName
SentEval -X- _ I-DatasetName
benchmark -X- _ O
(Conneau -X- _ O
and -X- _ O
Kiela, -X- _ O
2018). -X- _ O

Regardless -X- _ O
of -X- _ O
the -X- _ O
initialization -X- _ O
method, -X- _ O
the -X- _ O
VECO -X- _ B-MethodName
initialized -X- _ O
model -X- _ O
can -X- _ O
gain -X- _ O
consistent -X- _ O
1∼2 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
improvement -X- _ O
over -X- _ O
the -X- _ O
randomly -X- _ O
initialized -X- _ O
model. -X- _ O

To -X- _ O
alleviate -X- _ O
the -X- _ O
issue, -X- _ O
we -X- _ O
train -X- _ O
a -X- _ O
binary -X- _ O
classifier -X- _ O
on -X- _ O
the -X- _ B-MetricValue
CoLA -X- _ I-MetricValue
corpus -X- _ O
(Warstadt -X- _ O
et -X- _ O
al, -X- _ O
2019) -X- _ O
to -X- _ O
learn -X- _ O
to -X- _ O
judge -X- _ O
the -X- _ O
grammaticality, -X- _ O
and -X- _ O
then -X- _ O
filter -X- _ O
out -X- _ O
those -X- _ O
examples -X- _ O
that -X- _ O
are -X- _ O
classified -X- _ O
as -X- _ O
ungrammatical -X- _ O
(the -X- _ O
classifier -X- _ O
score -X- _ O
less -X- _ O
than -X- _ O
0.5). -X- _ B-MetricValue

In -X- _ O
our -X- _ O
experiments, -X- _ O
we -X- _ O
keep -X- _ O
K -X- _ B-HyperparameterName
= -X- _ O
96 -X- _ B-HyperparameterValue
(out -X- _ O
of -X- _ O
12 -X- _ O
× -X- _ O
12 -X- _ O
= -X- _ O
144) -X- _ O
heads -X- _ O
in -X- _ O
GPT-2 -X- _ B-MethodName
and -X- _ O
we -X- _ O
report -X- _ O
the -X- _ O
average -X- _ O
of -X- _ O
5 -X- _ O
runs -X- _ O
with -X- _ O
different -X- _ O
random -X- _ O
seeds. -X- _ O

We -X- _ O
empirically -X- _ O
compare -X- _ O
a -X- _ O
wider -X- _ O
range -X- _ O
of -X- _ O
model -X- _ O
depths -X- _ O
for -X- _ O
Transformer+DS-Init+MAtt -X- _ B-MethodName
with -X- _ O
up -X- _ O
to -X- _ O
30 -X- _ B-HyperparameterValue
layers. -X- _ B-HyperparameterName

Importantly, -X- _ O
we -X- _ O
create -X- _ O
pseudo-pretrained -X- _ O
embeddings -X- _ O
for -X- _ O
these -X- _ O
new -X- _ O
OA-NER-based -X- _ O
tokens -X- _ O
by -X- _ O
adding -X- _ O
a -X- _ O
small -X- _ O
amount -X- _ O
of -X- _ O
random -X- _ O
Gaussian -X- _ O
noise -X- _ O
(mean -X- _ O
0 -X- _ O
and -X- _ O
variance -X- _ O
of -X- _ O
0.1) -X- _ O
to -X- _ O
pre-trained -X- _ O
embeddings -X- _ O
(Pennington -X- _ O
et -X- _ O
al, -X- _ O
2014) -X- _ O
of -X- _ O
the -X- _ O
root -X- _ O
word -X- _ O
corresponding -X- _ O
to -X- _ O
the -X- _ O
category -X- _ O
(e.g., -X- _ O
person). -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
Adam -X- _ B-MethodName
optimizer -X- _ O
with -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
2e-5 -X- _ B-HyperparameterValue
with -X- _ O
warm-up. -X- _ O

Then, -X- _ O
we -X- _ O
apply -X- _ O
SummaReranker -X- _ B-MethodName
on -X- _ B-DatasetName
XSum -X- _ I-DatasetName
and -X- _ B-DatasetName
Reddit -X- _ I-DatasetName
TIFU, -X- _ I-DatasetName
as -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
6. -X- _ O

In -X- _ O
this -X- _ O
paper, -X- _ O
we -X- _ O
train -X- _ O
grammatical -X- _ O
role -X- _ O
probes -X- _ O
on -X- _ O
the -X- _ O
embedding -X- _ O
spaces -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
GPT-2 -X- _ B-MethodName
1 -X- _ O
, -X- _ O
and -X- _ O
evaluate -X- _ O
them -X- _ O
on -X- _ O
these -X- _ O
rare -X- _ O
non-prototypical -X- _ O
examples, -X- _ O
where -X- _ O
the -X- _ O
meaning -X- _ O
of -X- _ O
words -X- _ O
in -X- _ O
context -X- _ O
is -X- _ O
different -X- _ O
from -X- _ O
what -X- _ O
we -X- _ O
would -X- _ O
expect -X- _ O
from -X- _ O
looking -X- _ O
at -X- _ O
the -X- _ O
words -X- _ O
alone. -X- _ O

Paraphraser -X- _ O
We -X- _ O
finetune -X- _ O
the -X- _ O
paraphraser -X- _ O
using -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
1, -X- _ B-HyperparameterValue
024 -X- _ I-HyperparameterValue
tokens -X- _ B-HyperparameterName
for -X- _ O
5, -X- _ B-HyperparameterValue
000 -X- _ I-HyperparameterValue
iterations -X- _ B-HyperparameterName
(500 -X- _ B-HyperparameterValue
for -X- _ O
warm-up), -X- _ O
with -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
3e -X- _ B-HyperparameterValue
− -X- _ I-HyperparameterValue
5 -X- _ I-HyperparameterValue
using -X- _ O
ADAM. -X- _ B-MethodName

Models -X- _ O
from -X- _ O
Related -X- _ O
Tasks -X- _ O
EM-DM -X- _ B-MethodName
achieves -X- _ O
very -X- _ O
high -X- _ O
precision -X- _ B-MetricName
(P -X- _ O
, -X- _ O
P -X- _ O
w -X- _ O
) -X- _ O
for -X- _ O
the -X- _ O
minority -X- _ O
classes, -X- _ O
showing -X- _ O
a -X- _ O
clear -X- _ O
link -X- _ O
between -X- _ O
the -X- _ O
tasks -X- _ O
of -X- _ O
emotion -X- _ B-TaskName
recognition -X- _ I-TaskName
and -X- _ O
detecting -X- _ B-TaskName
changes -X- _ I-TaskName
in -X- _ I-TaskName
a -X- _ I-TaskName
user's -X- _ I-TaskName
mood -X- _ I-TaskName
-indeed, -X- _ I-TaskName
emotionally -X- _ O
informed -X- _ O
mod-els -X- _ O
have -X- _ O
been -X- _ O
successfully -X- _ O
applied -X- _ O
to -X- _ O
post-level -X- _ O
classification -X- _ O
tasks -X- _ O
in -X- _ O
mental -X- _ O
health -X- _ O
(Sawhney -X- _ O
et -X- _ O
al, -X- _ O
2020a); -X- _ O
however, -X- _ O
both -X- _ O
EM -X- _ O
models -X- _ O
achieve -X- _ O
low -X- _ O
recall -X- _ B-MetricName
(R, -X- _ O
R -X- _ O
w -X- _ O
) -X- _ O
for -X- _ O
IE/IS -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
rest. -X- _ O

Experiments -X- _ O
on -X- _ O
the -X- _ O
publicly -X- _ O
available -X- _ O
data -X- _ O
sets, -X- _ O
i.e., -X- _ O
WMT-5 -X- _ B-DatasetName
and -X- _ O
OPUS-100, -X- _ B-DatasetName
show -X- _ O
that -X- _ O
the -X- _ O
proposed -X- _ O
method -X- _ O
achieves -X- _ O
substantial -X- _ O
improvements -X- _ O
over -X- _ O
strong -X- _ O
baselines. -X- _ O

We -X- _ O
found -X- _ O
that -X- _ O
the -X- _ O
annotators -X- _ O
disagree -X- _ O
substantially -X- _ O
more -X- _ O
as -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
humanwritten -X- _ O
answers, -X- _ O
with -X- _ O
a -X- _ O
Fleiss -X- _ B-MetricName
kappa -X- _ I-MetricName
of -X- _ O
0.31 -X- _ B-MetricValue
(vs. -X- _ O
0.45 -X- _ B-MetricValue
for -X- _ O
human-written -X- _ B-MethodName
answers), -X- _ O
suggesting -X- _ O
that -X- _ O
the -X- _ O
discourse -X- _ O
structure -X- _ O
of -X- _ O
model-generated -X- _ O
answers -X- _ O
are -X- _ O
less -X- _ O
clear, -X- _ O
even -X- _ O
to -X- _ O
our -X- _ O
trained -X- _ O
annotators. -X- _ O

